// ignore_for_file: always_specify_types
// ignore_for_file: camel_case_types
// ignore_for_file: non_constant_identifier_names

// AUTO GENERATED FILE, DO NOT EDIT.
//
// Generated by `package:ffigen`.
import 'dart:ffi' as ffi;

/// Bindings for `src/flutter_tflite_ffi.h`.
///
/// Regenerate bindings with `flutter pub run ffigen --config ffigen.yaml`.
///
class FlutterTfliteFfiBindings {
  /// Holds the symbol lookup function.
  final ffi.Pointer<T> Function<T extends ffi.NativeType>(String symbolName)
      _lookup;

  /// The symbols are looked up in [dynamicLibrary].
  FlutterTfliteFfiBindings(ffi.DynamicLibrary dynamicLibrary)
      : _lookup = dynamicLibrary.lookup;

  /// The symbols are looked up with [lookup].
  FlutterTfliteFfiBindings.fromLookup(
      ffi.Pointer<T> Function<T extends ffi.NativeType>(String symbolName)
          lookup)
      : _lookup = lookup;

  /// For historical reasons; programs expect signal's return value to be
  /// defined by <sys/signal.h>.
  ffi.Pointer<ffi.NativeFunction<ffi.Void Function(ffi.Int)>> signal(
    int arg0,
    ffi.Pointer<ffi.NativeFunction<ffi.Void Function(ffi.Int)>> arg1,
  ) {
    return _signal(
      arg0,
      arg1,
    );
  }

  late final _signalPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.NativeFunction<ffi.Void Function(ffi.Int)>> Function(
              ffi.Int,
              ffi.Pointer<
                  ffi.NativeFunction<ffi.Void Function(ffi.Int)>>)>>('signal');
  late final _signal = _signalPtr.asFunction<
      ffi.Pointer<ffi.NativeFunction<ffi.Void Function(ffi.Int)>> Function(
          int, ffi.Pointer<ffi.NativeFunction<ffi.Void Function(ffi.Int)>>)>();

  int getpriority(
    int arg0,
    int arg1,
  ) {
    return _getpriority(
      arg0,
      arg1,
    );
  }

  late final _getpriorityPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Int, id_t)>>(
          'getpriority');
  late final _getpriority =
      _getpriorityPtr.asFunction<int Function(int, int)>();

  int getiopolicy_np(
    int arg0,
    int arg1,
  ) {
    return _getiopolicy_np(
      arg0,
      arg1,
    );
  }

  late final _getiopolicy_npPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Int, ffi.Int)>>(
          'getiopolicy_np');
  late final _getiopolicy_np =
      _getiopolicy_npPtr.asFunction<int Function(int, int)>();

  int getrlimit(
    int arg0,
    ffi.Pointer<rlimit> arg1,
  ) {
    return _getrlimit(
      arg0,
      arg1,
    );
  }

  late final _getrlimitPtr = _lookup<
          ffi.NativeFunction<ffi.Int Function(ffi.Int, ffi.Pointer<rlimit>)>>(
      'getrlimit');
  late final _getrlimit =
      _getrlimitPtr.asFunction<int Function(int, ffi.Pointer<rlimit>)>();

  int getrusage(
    int arg0,
    ffi.Pointer<rusage> arg1,
  ) {
    return _getrusage(
      arg0,
      arg1,
    );
  }

  late final _getrusagePtr = _lookup<
          ffi.NativeFunction<ffi.Int Function(ffi.Int, ffi.Pointer<rusage>)>>(
      'getrusage');
  late final _getrusage =
      _getrusagePtr.asFunction<int Function(int, ffi.Pointer<rusage>)>();

  int setpriority(
    int arg0,
    int arg1,
    int arg2,
  ) {
    return _setpriority(
      arg0,
      arg1,
      arg2,
    );
  }

  late final _setpriorityPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Int, id_t, ffi.Int)>>(
          'setpriority');
  late final _setpriority =
      _setpriorityPtr.asFunction<int Function(int, int, int)>();

  int setiopolicy_np(
    int arg0,
    int arg1,
    int arg2,
  ) {
    return _setiopolicy_np(
      arg0,
      arg1,
      arg2,
    );
  }

  late final _setiopolicy_npPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Int, ffi.Int, ffi.Int)>>(
          'setiopolicy_np');
  late final _setiopolicy_np =
      _setiopolicy_npPtr.asFunction<int Function(int, int, int)>();

  int setrlimit(
    int arg0,
    ffi.Pointer<rlimit> arg1,
  ) {
    return _setrlimit(
      arg0,
      arg1,
    );
  }

  late final _setrlimitPtr = _lookup<
          ffi.NativeFunction<ffi.Int Function(ffi.Int, ffi.Pointer<rlimit>)>>(
      'setrlimit');
  late final _setrlimit =
      _setrlimitPtr.asFunction<int Function(int, ffi.Pointer<rlimit>)>();

  int wait1(
    ffi.Pointer<ffi.Int> arg0,
  ) {
    return _wait1(
      arg0,
    );
  }

  late final _wait1Ptr =
      _lookup<ffi.NativeFunction<pid_t Function(ffi.Pointer<ffi.Int>)>>('wait');
  late final _wait1 =
      _wait1Ptr.asFunction<int Function(ffi.Pointer<ffi.Int>)>();

  int waitpid(
    int arg0,
    ffi.Pointer<ffi.Int> arg1,
    int arg2,
  ) {
    return _waitpid(
      arg0,
      arg1,
      arg2,
    );
  }

  late final _waitpidPtr = _lookup<
      ffi.NativeFunction<
          pid_t Function(pid_t, ffi.Pointer<ffi.Int>, ffi.Int)>>('waitpid');
  late final _waitpid =
      _waitpidPtr.asFunction<int Function(int, ffi.Pointer<ffi.Int>, int)>();

  int waitid(
    int arg0,
    int arg1,
    ffi.Pointer<siginfo_t> arg2,
    int arg3,
  ) {
    return _waitid(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final _waitidPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(
              ffi.Int32, id_t, ffi.Pointer<siginfo_t>, ffi.Int)>>('waitid');
  late final _waitid = _waitidPtr
      .asFunction<int Function(int, int, ffi.Pointer<siginfo_t>, int)>();

  int wait3(
    ffi.Pointer<ffi.Int> arg0,
    int arg1,
    ffi.Pointer<rusage> arg2,
  ) {
    return _wait3(
      arg0,
      arg1,
      arg2,
    );
  }

  late final _wait3Ptr = _lookup<
      ffi.NativeFunction<
          pid_t Function(
              ffi.Pointer<ffi.Int>, ffi.Int, ffi.Pointer<rusage>)>>('wait3');
  late final _wait3 = _wait3Ptr.asFunction<
      int Function(ffi.Pointer<ffi.Int>, int, ffi.Pointer<rusage>)>();

  int wait4(
    int arg0,
    ffi.Pointer<ffi.Int> arg1,
    int arg2,
    ffi.Pointer<rusage> arg3,
  ) {
    return _wait4(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final _wait4Ptr = _lookup<
      ffi.NativeFunction<
          pid_t Function(pid_t, ffi.Pointer<ffi.Int>, ffi.Int,
              ffi.Pointer<rusage>)>>('wait4');
  late final _wait4 = _wait4Ptr.asFunction<
      int Function(int, ffi.Pointer<ffi.Int>, int, ffi.Pointer<rusage>)>();

  ffi.Pointer<ffi.Void> alloca(
    int arg0,
  ) {
    return _alloca(
      arg0,
    );
  }

  late final _allocaPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Void> Function(ffi.Size)>>(
          'alloca');
  late final _alloca =
      _allocaPtr.asFunction<ffi.Pointer<ffi.Void> Function(int)>();

  late final ffi.Pointer<ffi.Int> ___mb_cur_max =
      _lookup<ffi.Int>('__mb_cur_max');

  int get __mb_cur_max => ___mb_cur_max.value;

  set __mb_cur_max(int value) => ___mb_cur_max.value = value;

  ffi.Pointer<ffi.Void> malloc(
    int __size,
  ) {
    return _malloc(
      __size,
    );
  }

  late final _mallocPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Void> Function(ffi.Size)>>(
          'malloc');
  late final _malloc =
      _mallocPtr.asFunction<ffi.Pointer<ffi.Void> Function(int)>();

  ffi.Pointer<ffi.Void> calloc(
    int __count,
    int __size,
  ) {
    return _calloc(
      __count,
      __size,
    );
  }

  late final _callocPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Void> Function(ffi.Size, ffi.Size)>>('calloc');
  late final _calloc =
      _callocPtr.asFunction<ffi.Pointer<ffi.Void> Function(int, int)>();

  void free(
    ffi.Pointer<ffi.Void> arg0,
  ) {
    return _free(
      arg0,
    );
  }

  late final _freePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ffi.Void>)>>(
          'free');
  late final _free =
      _freePtr.asFunction<void Function(ffi.Pointer<ffi.Void>)>();

  ffi.Pointer<ffi.Void> realloc(
    ffi.Pointer<ffi.Void> __ptr,
    int __size,
  ) {
    return _realloc(
      __ptr,
      __size,
    );
  }

  late final _reallocPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Void> Function(
              ffi.Pointer<ffi.Void>, ffi.Size)>>('realloc');
  late final _realloc = _reallocPtr
      .asFunction<ffi.Pointer<ffi.Void> Function(ffi.Pointer<ffi.Void>, int)>();

  ffi.Pointer<ffi.Void> valloc(
    int arg0,
  ) {
    return _valloc(
      arg0,
    );
  }

  late final _vallocPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Void> Function(ffi.Size)>>(
          'valloc');
  late final _valloc =
      _vallocPtr.asFunction<ffi.Pointer<ffi.Void> Function(int)>();

  ffi.Pointer<ffi.Void> aligned_alloc(
    int __alignment,
    int __size,
  ) {
    return _aligned_alloc(
      __alignment,
      __size,
    );
  }

  late final _aligned_allocPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Void> Function(ffi.Size, ffi.Size)>>('aligned_alloc');
  late final _aligned_alloc =
      _aligned_allocPtr.asFunction<ffi.Pointer<ffi.Void> Function(int, int)>();

  int posix_memalign(
    ffi.Pointer<ffi.Pointer<ffi.Void>> __memptr,
    int __alignment,
    int __size,
  ) {
    return _posix_memalign(
      __memptr,
      __alignment,
      __size,
    );
  }

  late final _posix_memalignPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<ffi.Pointer<ffi.Void>>, ffi.Size,
              ffi.Size)>>('posix_memalign');
  late final _posix_memalign = _posix_memalignPtr
      .asFunction<int Function(ffi.Pointer<ffi.Pointer<ffi.Void>>, int, int)>();

  void abort() {
    return _abort();
  }

  late final _abortPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('abort');
  late final _abort = _abortPtr.asFunction<void Function()>();

  int abs(
    int arg0,
  ) {
    return _abs(
      arg0,
    );
  }

  late final _absPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Int)>>('abs');
  late final _abs = _absPtr.asFunction<int Function(int)>();

  int atexit(
    ffi.Pointer<ffi.NativeFunction<ffi.Void Function()>> arg0,
  ) {
    return _atexit(
      arg0,
    );
  }

  late final _atexitPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(
              ffi.Pointer<ffi.NativeFunction<ffi.Void Function()>>)>>('atexit');
  late final _atexit = _atexitPtr.asFunction<
      int Function(ffi.Pointer<ffi.NativeFunction<ffi.Void Function()>>)>();

  double atof(
    ffi.Pointer<ffi.Char> arg0,
  ) {
    return _atof(
      arg0,
    );
  }

  late final _atofPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Pointer<ffi.Char>)>>(
          'atof');
  late final _atof =
      _atofPtr.asFunction<double Function(ffi.Pointer<ffi.Char>)>();

  int atoi(
    ffi.Pointer<ffi.Char> arg0,
  ) {
    return _atoi(
      arg0,
    );
  }

  late final _atoiPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<ffi.Char>)>>(
          'atoi');
  late final _atoi = _atoiPtr.asFunction<int Function(ffi.Pointer<ffi.Char>)>();

  int atol(
    ffi.Pointer<ffi.Char> arg0,
  ) {
    return _atol(
      arg0,
    );
  }

  late final _atolPtr =
      _lookup<ffi.NativeFunction<ffi.Long Function(ffi.Pointer<ffi.Char>)>>(
          'atol');
  late final _atol = _atolPtr.asFunction<int Function(ffi.Pointer<ffi.Char>)>();

  int atoll(
    ffi.Pointer<ffi.Char> arg0,
  ) {
    return _atoll(
      arg0,
    );
  }

  late final _atollPtr =
      _lookup<ffi.NativeFunction<ffi.LongLong Function(ffi.Pointer<ffi.Char>)>>(
          'atoll');
  late final _atoll =
      _atollPtr.asFunction<int Function(ffi.Pointer<ffi.Char>)>();

  ffi.Pointer<ffi.Void> bsearch(
    ffi.Pointer<ffi.Void> __key,
    ffi.Pointer<ffi.Void> __base,
    int __nel,
    int __width,
    ffi.Pointer<
            ffi.NativeFunction<
                ffi.Int Function(ffi.Pointer<ffi.Void>, ffi.Pointer<ffi.Void>)>>
        __compar,
  ) {
    return _bsearch(
      __key,
      __base,
      __nel,
      __width,
      __compar,
    );
  }

  late final _bsearchPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Void> Function(
              ffi.Pointer<ffi.Void>,
              ffi.Pointer<ffi.Void>,
              ffi.Size,
              ffi.Size,
              ffi.Pointer<
                  ffi.NativeFunction<
                      ffi.Int Function(ffi.Pointer<ffi.Void>,
                          ffi.Pointer<ffi.Void>)>>)>>('bsearch');
  late final _bsearch = _bsearchPtr.asFunction<
      ffi.Pointer<ffi.Void> Function(
          ffi.Pointer<ffi.Void>,
          ffi.Pointer<ffi.Void>,
          int,
          int,
          ffi.Pointer<
              ffi.NativeFunction<
                  ffi.Int Function(
                      ffi.Pointer<ffi.Void>, ffi.Pointer<ffi.Void>)>>)>();

  /// calloc is now declared in _malloc.h
  div_t div(
    int arg0,
    int arg1,
  ) {
    return _div(
      arg0,
      arg1,
    );
  }

  late final _divPtr =
      _lookup<ffi.NativeFunction<div_t Function(ffi.Int, ffi.Int)>>('div');
  late final _div = _divPtr.asFunction<div_t Function(int, int)>();

  void exit(
    int arg0,
  ) {
    return _exit(
      arg0,
    );
  }

  late final _exitPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Int)>>('exit');
  late final _exit = _exitPtr.asFunction<void Function(int)>();

  /// free is now declared in _malloc.h
  ffi.Pointer<ffi.Char> getenv(
    ffi.Pointer<ffi.Char> arg0,
  ) {
    return _getenv(
      arg0,
    );
  }

  late final _getenvPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Char> Function(ffi.Pointer<ffi.Char>)>>('getenv');
  late final _getenv = _getenvPtr
      .asFunction<ffi.Pointer<ffi.Char> Function(ffi.Pointer<ffi.Char>)>();

  int labs(
    int arg0,
  ) {
    return _labs(
      arg0,
    );
  }

  late final _labsPtr =
      _lookup<ffi.NativeFunction<ffi.Long Function(ffi.Long)>>('labs');
  late final _labs = _labsPtr.asFunction<int Function(int)>();

  ldiv_t ldiv(
    int arg0,
    int arg1,
  ) {
    return _ldiv(
      arg0,
      arg1,
    );
  }

  late final _ldivPtr =
      _lookup<ffi.NativeFunction<ldiv_t Function(ffi.Long, ffi.Long)>>('ldiv');
  late final _ldiv = _ldivPtr.asFunction<ldiv_t Function(int, int)>();

  int llabs(
    int arg0,
  ) {
    return _llabs(
      arg0,
    );
  }

  late final _llabsPtr =
      _lookup<ffi.NativeFunction<ffi.LongLong Function(ffi.LongLong)>>('llabs');
  late final _llabs = _llabsPtr.asFunction<int Function(int)>();

  lldiv_t lldiv(
    int arg0,
    int arg1,
  ) {
    return _lldiv(
      arg0,
      arg1,
    );
  }

  late final _lldivPtr =
      _lookup<ffi.NativeFunction<lldiv_t Function(ffi.LongLong, ffi.LongLong)>>(
          'lldiv');
  late final _lldiv = _lldivPtr.asFunction<lldiv_t Function(int, int)>();

  /// malloc is now declared in _malloc.h
  int mblen(
    ffi.Pointer<ffi.Char> __s,
    int __n,
  ) {
    return _mblen(
      __s,
      __n,
    );
  }

  late final _mblenPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<ffi.Char>, ffi.Size)>>('mblen');
  late final _mblen =
      _mblenPtr.asFunction<int Function(ffi.Pointer<ffi.Char>, int)>();

  int mbstowcs(
    ffi.Pointer<ffi.WChar> arg0,
    ffi.Pointer<ffi.Char> arg1,
    int arg2,
  ) {
    return _mbstowcs(
      arg0,
      arg1,
      arg2,
    );
  }

  late final _mbstowcsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Size Function(ffi.Pointer<ffi.WChar>, ffi.Pointer<ffi.Char>,
              ffi.Size)>>('mbstowcs');
  late final _mbstowcs = _mbstowcsPtr.asFunction<
      int Function(ffi.Pointer<ffi.WChar>, ffi.Pointer<ffi.Char>, int)>();

  int mbtowc(
    ffi.Pointer<ffi.WChar> arg0,
    ffi.Pointer<ffi.Char> arg1,
    int arg2,
  ) {
    return _mbtowc(
      arg0,
      arg1,
      arg2,
    );
  }

  late final _mbtowcPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<ffi.WChar>, ffi.Pointer<ffi.Char>,
              ffi.Size)>>('mbtowc');
  late final _mbtowc = _mbtowcPtr.asFunction<
      int Function(ffi.Pointer<ffi.WChar>, ffi.Pointer<ffi.Char>, int)>();

  /// posix_memalign is now declared in _malloc.h
  void qsort(
    ffi.Pointer<ffi.Void> __base,
    int __nel,
    int __width,
    ffi.Pointer<
            ffi.NativeFunction<
                ffi.Int Function(ffi.Pointer<ffi.Void>, ffi.Pointer<ffi.Void>)>>
        __compar,
  ) {
    return _qsort(
      __base,
      __nel,
      __width,
      __compar,
    );
  }

  late final _qsortPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<ffi.Void>,
              ffi.Size,
              ffi.Size,
              ffi.Pointer<
                  ffi.NativeFunction<
                      ffi.Int Function(ffi.Pointer<ffi.Void>,
                          ffi.Pointer<ffi.Void>)>>)>>('qsort');
  late final _qsort = _qsortPtr.asFunction<
      void Function(
          ffi.Pointer<ffi.Void>,
          int,
          int,
          ffi.Pointer<
              ffi.NativeFunction<
                  ffi.Int Function(
                      ffi.Pointer<ffi.Void>, ffi.Pointer<ffi.Void>)>>)>();

  int rand() {
    return _rand();
  }

  late final _randPtr = _lookup<ffi.NativeFunction<ffi.Int Function()>>('rand');
  late final _rand = _randPtr.asFunction<int Function()>();

  /// realloc is now declared in _malloc.h
  void srand(
    int arg0,
  ) {
    return _srand(
      arg0,
    );
  }

  late final _srandPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.UnsignedInt)>>('srand');
  late final _srand = _srandPtr.asFunction<void Function(int)>();

  double strtod(
    ffi.Pointer<ffi.Char> arg0,
    ffi.Pointer<ffi.Pointer<ffi.Char>> arg1,
  ) {
    return _strtod(
      arg0,
      arg1,
    );
  }

  late final _strtodPtr = _lookup<
      ffi.NativeFunction<
          ffi.Double Function(ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Pointer<ffi.Char>>)>>('strtod');
  late final _strtod = _strtodPtr.asFunction<
      double Function(
          ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Pointer<ffi.Char>>)>();

  double strtof(
    ffi.Pointer<ffi.Char> arg0,
    ffi.Pointer<ffi.Pointer<ffi.Char>> arg1,
  ) {
    return _strtof(
      arg0,
      arg1,
    );
  }

  late final _strtofPtr = _lookup<
      ffi.NativeFunction<
          ffi.Float Function(ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Pointer<ffi.Char>>)>>('strtof');
  late final _strtof = _strtofPtr.asFunction<
      double Function(
          ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Pointer<ffi.Char>>)>();

  int strtol(
    ffi.Pointer<ffi.Char> __str,
    ffi.Pointer<ffi.Pointer<ffi.Char>> __endptr,
    int __base,
  ) {
    return _strtol(
      __str,
      __endptr,
      __base,
    );
  }

  late final _strtolPtr = _lookup<
      ffi.NativeFunction<
          ffi.Long Function(ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Pointer<ffi.Char>>, ffi.Int)>>('strtol');
  late final _strtol = _strtolPtr.asFunction<
      int Function(
          ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Pointer<ffi.Char>>, int)>();

  int strtoll(
    ffi.Pointer<ffi.Char> __str,
    ffi.Pointer<ffi.Pointer<ffi.Char>> __endptr,
    int __base,
  ) {
    return _strtoll(
      __str,
      __endptr,
      __base,
    );
  }

  late final _strtollPtr = _lookup<
      ffi.NativeFunction<
          ffi.LongLong Function(ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Pointer<ffi.Char>>, ffi.Int)>>('strtoll');
  late final _strtoll = _strtollPtr.asFunction<
      int Function(
          ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Pointer<ffi.Char>>, int)>();

  int strtoul(
    ffi.Pointer<ffi.Char> __str,
    ffi.Pointer<ffi.Pointer<ffi.Char>> __endptr,
    int __base,
  ) {
    return _strtoul(
      __str,
      __endptr,
      __base,
    );
  }

  late final _strtoulPtr = _lookup<
      ffi.NativeFunction<
          ffi.UnsignedLong Function(ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Pointer<ffi.Char>>, ffi.Int)>>('strtoul');
  late final _strtoul = _strtoulPtr.asFunction<
      int Function(
          ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Pointer<ffi.Char>>, int)>();

  int strtoull(
    ffi.Pointer<ffi.Char> __str,
    ffi.Pointer<ffi.Pointer<ffi.Char>> __endptr,
    int __base,
  ) {
    return _strtoull(
      __str,
      __endptr,
      __base,
    );
  }

  late final _strtoullPtr = _lookup<
      ffi.NativeFunction<
          ffi.UnsignedLongLong Function(ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Pointer<ffi.Char>>, ffi.Int)>>('strtoull');
  late final _strtoull = _strtoullPtr.asFunction<
      int Function(
          ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Pointer<ffi.Char>>, int)>();

  int system(
    ffi.Pointer<ffi.Char> arg0,
  ) {
    return _system(
      arg0,
    );
  }

  late final _systemPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<ffi.Char>)>>(
          'system');
  late final _system =
      _systemPtr.asFunction<int Function(ffi.Pointer<ffi.Char>)>();

  int wcstombs(
    ffi.Pointer<ffi.Char> arg0,
    ffi.Pointer<ffi.WChar> arg1,
    int arg2,
  ) {
    return _wcstombs(
      arg0,
      arg1,
      arg2,
    );
  }

  late final _wcstombsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Size Function(ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.WChar>,
              ffi.Size)>>('wcstombs');
  late final _wcstombs = _wcstombsPtr.asFunction<
      int Function(ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.WChar>, int)>();

  int wctomb(
    ffi.Pointer<ffi.Char> arg0,
    int arg1,
  ) {
    return _wctomb(
      arg0,
      arg1,
    );
  }

  late final _wctombPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<ffi.Char>, ffi.WChar)>>('wctomb');
  late final _wctomb =
      _wctombPtr.asFunction<int Function(ffi.Pointer<ffi.Char>, int)>();

  void _Exit(
    int arg0,
  ) {
    return __Exit(
      arg0,
    );
  }

  late final __ExitPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Int)>>('_Exit');
  late final __Exit = __ExitPtr.asFunction<void Function(int)>();

  int a64l(
    ffi.Pointer<ffi.Char> arg0,
  ) {
    return _a64l(
      arg0,
    );
  }

  late final _a64lPtr =
      _lookup<ffi.NativeFunction<ffi.Long Function(ffi.Pointer<ffi.Char>)>>(
          'a64l');
  late final _a64l = _a64lPtr.asFunction<int Function(ffi.Pointer<ffi.Char>)>();

  double drand48() {
    return _drand48();
  }

  late final _drand48Ptr =
      _lookup<ffi.NativeFunction<ffi.Double Function()>>('drand48');
  late final _drand48 = _drand48Ptr.asFunction<double Function()>();

  ffi.Pointer<ffi.Char> ecvt(
    double arg0,
    int arg1,
    ffi.Pointer<ffi.Int> arg2,
    ffi.Pointer<ffi.Int> arg3,
  ) {
    return _ecvt(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final _ecvtPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Char> Function(ffi.Double, ffi.Int,
              ffi.Pointer<ffi.Int>, ffi.Pointer<ffi.Int>)>>('ecvt');
  late final _ecvt = _ecvtPtr.asFunction<
      ffi.Pointer<ffi.Char> Function(
          double, int, ffi.Pointer<ffi.Int>, ffi.Pointer<ffi.Int>)>();

  double erand48(
    ffi.Pointer<ffi.UnsignedShort> arg0,
  ) {
    return _erand48(
      arg0,
    );
  }

  late final _erand48Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Double Function(ffi.Pointer<ffi.UnsignedShort>)>>('erand48');
  late final _erand48 =
      _erand48Ptr.asFunction<double Function(ffi.Pointer<ffi.UnsignedShort>)>();

  ffi.Pointer<ffi.Char> fcvt(
    double arg0,
    int arg1,
    ffi.Pointer<ffi.Int> arg2,
    ffi.Pointer<ffi.Int> arg3,
  ) {
    return _fcvt(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final _fcvtPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Char> Function(ffi.Double, ffi.Int,
              ffi.Pointer<ffi.Int>, ffi.Pointer<ffi.Int>)>>('fcvt');
  late final _fcvt = _fcvtPtr.asFunction<
      ffi.Pointer<ffi.Char> Function(
          double, int, ffi.Pointer<ffi.Int>, ffi.Pointer<ffi.Int>)>();

  ffi.Pointer<ffi.Char> gcvt(
    double arg0,
    int arg1,
    ffi.Pointer<ffi.Char> arg2,
  ) {
    return _gcvt(
      arg0,
      arg1,
      arg2,
    );
  }

  late final _gcvtPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Char> Function(
              ffi.Double, ffi.Int, ffi.Pointer<ffi.Char>)>>('gcvt');
  late final _gcvt = _gcvtPtr.asFunction<
      ffi.Pointer<ffi.Char> Function(double, int, ffi.Pointer<ffi.Char>)>();

  int getsubopt(
    ffi.Pointer<ffi.Pointer<ffi.Char>> arg0,
    ffi.Pointer<ffi.Pointer<ffi.Char>> arg1,
    ffi.Pointer<ffi.Pointer<ffi.Char>> arg2,
  ) {
    return _getsubopt(
      arg0,
      arg1,
      arg2,
    );
  }

  late final _getsuboptPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(
              ffi.Pointer<ffi.Pointer<ffi.Char>>,
              ffi.Pointer<ffi.Pointer<ffi.Char>>,
              ffi.Pointer<ffi.Pointer<ffi.Char>>)>>('getsubopt');
  late final _getsubopt = _getsuboptPtr.asFunction<
      int Function(
          ffi.Pointer<ffi.Pointer<ffi.Char>>,
          ffi.Pointer<ffi.Pointer<ffi.Char>>,
          ffi.Pointer<ffi.Pointer<ffi.Char>>)>();

  int grantpt(
    int arg0,
  ) {
    return _grantpt(
      arg0,
    );
  }

  late final _grantptPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Int)>>('grantpt');
  late final _grantpt = _grantptPtr.asFunction<int Function(int)>();

  ffi.Pointer<ffi.Char> initstate(
    int arg0,
    ffi.Pointer<ffi.Char> arg1,
    int arg2,
  ) {
    return _initstate(
      arg0,
      arg1,
      arg2,
    );
  }

  late final _initstatePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Char> Function(
              ffi.UnsignedInt, ffi.Pointer<ffi.Char>, ffi.Size)>>('initstate');
  late final _initstate = _initstatePtr.asFunction<
      ffi.Pointer<ffi.Char> Function(int, ffi.Pointer<ffi.Char>, int)>();

  int jrand48(
    ffi.Pointer<ffi.UnsignedShort> arg0,
  ) {
    return _jrand48(
      arg0,
    );
  }

  late final _jrand48Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Long Function(ffi.Pointer<ffi.UnsignedShort>)>>('jrand48');
  late final _jrand48 =
      _jrand48Ptr.asFunction<int Function(ffi.Pointer<ffi.UnsignedShort>)>();

  ffi.Pointer<ffi.Char> l64a(
    int arg0,
  ) {
    return _l64a(
      arg0,
    );
  }

  late final _l64aPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Char> Function(ffi.Long)>>(
          'l64a');
  late final _l64a = _l64aPtr.asFunction<ffi.Pointer<ffi.Char> Function(int)>();

  void lcong48(
    ffi.Pointer<ffi.UnsignedShort> arg0,
  ) {
    return _lcong48(
      arg0,
    );
  }

  late final _lcong48Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.UnsignedShort>)>>('lcong48');
  late final _lcong48 =
      _lcong48Ptr.asFunction<void Function(ffi.Pointer<ffi.UnsignedShort>)>();

  int lrand48() {
    return _lrand48();
  }

  late final _lrand48Ptr =
      _lookup<ffi.NativeFunction<ffi.Long Function()>>('lrand48');
  late final _lrand48 = _lrand48Ptr.asFunction<int Function()>();

  ffi.Pointer<ffi.Char> mktemp(
    ffi.Pointer<ffi.Char> arg0,
  ) {
    return _mktemp(
      arg0,
    );
  }

  late final _mktempPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Char> Function(ffi.Pointer<ffi.Char>)>>('mktemp');
  late final _mktemp = _mktempPtr
      .asFunction<ffi.Pointer<ffi.Char> Function(ffi.Pointer<ffi.Char>)>();

  int mkstemp(
    ffi.Pointer<ffi.Char> arg0,
  ) {
    return _mkstemp(
      arg0,
    );
  }

  late final _mkstempPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<ffi.Char>)>>(
          'mkstemp');
  late final _mkstemp =
      _mkstempPtr.asFunction<int Function(ffi.Pointer<ffi.Char>)>();

  int mrand48() {
    return _mrand48();
  }

  late final _mrand48Ptr =
      _lookup<ffi.NativeFunction<ffi.Long Function()>>('mrand48');
  late final _mrand48 = _mrand48Ptr.asFunction<int Function()>();

  int nrand48(
    ffi.Pointer<ffi.UnsignedShort> arg0,
  ) {
    return _nrand48(
      arg0,
    );
  }

  late final _nrand48Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Long Function(ffi.Pointer<ffi.UnsignedShort>)>>('nrand48');
  late final _nrand48 =
      _nrand48Ptr.asFunction<int Function(ffi.Pointer<ffi.UnsignedShort>)>();

  int posix_openpt(
    int arg0,
  ) {
    return _posix_openpt(
      arg0,
    );
  }

  late final _posix_openptPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Int)>>('posix_openpt');
  late final _posix_openpt = _posix_openptPtr.asFunction<int Function(int)>();

  ffi.Pointer<ffi.Char> ptsname(
    int arg0,
  ) {
    return _ptsname(
      arg0,
    );
  }

  late final _ptsnamePtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Char> Function(ffi.Int)>>(
          'ptsname');
  late final _ptsname =
      _ptsnamePtr.asFunction<ffi.Pointer<ffi.Char> Function(int)>();

  int ptsname_r(
    int fildes,
    ffi.Pointer<ffi.Char> buffer,
    int buflen,
  ) {
    return _ptsname_r(
      fildes,
      buffer,
      buflen,
    );
  }

  late final _ptsname_rPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(
              ffi.Int, ffi.Pointer<ffi.Char>, ffi.Size)>>('ptsname_r');
  late final _ptsname_r =
      _ptsname_rPtr.asFunction<int Function(int, ffi.Pointer<ffi.Char>, int)>();

  int putenv(
    ffi.Pointer<ffi.Char> arg0,
  ) {
    return _putenv(
      arg0,
    );
  }

  late final _putenvPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<ffi.Char>)>>(
          'putenv');
  late final _putenv =
      _putenvPtr.asFunction<int Function(ffi.Pointer<ffi.Char>)>();

  int random() {
    return _random();
  }

  late final _randomPtr =
      _lookup<ffi.NativeFunction<ffi.Long Function()>>('random');
  late final _random = _randomPtr.asFunction<int Function()>();

  int rand_r(
    ffi.Pointer<ffi.UnsignedInt> arg0,
  ) {
    return _rand_r(
      arg0,
    );
  }

  late final _rand_rPtr = _lookup<
          ffi.NativeFunction<ffi.Int Function(ffi.Pointer<ffi.UnsignedInt>)>>(
      'rand_r');
  late final _rand_r =
      _rand_rPtr.asFunction<int Function(ffi.Pointer<ffi.UnsignedInt>)>();

  ffi.Pointer<ffi.Char> realpath(
    ffi.Pointer<ffi.Char> arg0,
    ffi.Pointer<ffi.Char> arg1,
  ) {
    return _realpath(
      arg0,
      arg1,
    );
  }

  late final _realpathPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Char> Function(
              ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>)>>('realpath');
  late final _realpath = _realpathPtr.asFunction<
      ffi.Pointer<ffi.Char> Function(
          ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>)>();

  ffi.Pointer<ffi.UnsignedShort> seed48(
    ffi.Pointer<ffi.UnsignedShort> arg0,
  ) {
    return _seed48(
      arg0,
    );
  }

  late final _seed48Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.UnsignedShort> Function(
              ffi.Pointer<ffi.UnsignedShort>)>>('seed48');
  late final _seed48 = _seed48Ptr.asFunction<
      ffi.Pointer<ffi.UnsignedShort> Function(
          ffi.Pointer<ffi.UnsignedShort>)>();

  int setenv(
    ffi.Pointer<ffi.Char> __name,
    ffi.Pointer<ffi.Char> __value,
    int __overwrite,
  ) {
    return _setenv(
      __name,
      __value,
      __overwrite,
    );
  }

  late final _setenvPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>,
              ffi.Int)>>('setenv');
  late final _setenv = _setenvPtr.asFunction<
      int Function(ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>, int)>();

  void setkey(
    ffi.Pointer<ffi.Char> arg0,
  ) {
    return _setkey(
      arg0,
    );
  }

  late final _setkeyPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ffi.Char>)>>(
          'setkey');
  late final _setkey =
      _setkeyPtr.asFunction<void Function(ffi.Pointer<ffi.Char>)>();

  ffi.Pointer<ffi.Char> setstate(
    ffi.Pointer<ffi.Char> arg0,
  ) {
    return _setstate(
      arg0,
    );
  }

  late final _setstatePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Char> Function(ffi.Pointer<ffi.Char>)>>('setstate');
  late final _setstate = _setstatePtr
      .asFunction<ffi.Pointer<ffi.Char> Function(ffi.Pointer<ffi.Char>)>();

  void srand48(
    int arg0,
  ) {
    return _srand48(
      arg0,
    );
  }

  late final _srand48Ptr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Long)>>('srand48');
  late final _srand48 = _srand48Ptr.asFunction<void Function(int)>();

  void srandom(
    int arg0,
  ) {
    return _srandom(
      arg0,
    );
  }

  late final _srandomPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.UnsignedInt)>>(
          'srandom');
  late final _srandom = _srandomPtr.asFunction<void Function(int)>();

  int unlockpt(
    int arg0,
  ) {
    return _unlockpt(
      arg0,
    );
  }

  late final _unlockptPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Int)>>('unlockpt');
  late final _unlockpt = _unlockptPtr.asFunction<int Function(int)>();

  int unsetenv(
    ffi.Pointer<ffi.Char> arg0,
  ) {
    return _unsetenv(
      arg0,
    );
  }

  late final _unsetenvPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<ffi.Char>)>>(
          'unsetenv');
  late final _unsetenv =
      _unsetenvPtr.asFunction<int Function(ffi.Pointer<ffi.Char>)>();

  int arc4random() {
    return _arc4random();
  }

  late final _arc4randomPtr =
      _lookup<ffi.NativeFunction<ffi.Uint32 Function()>>('arc4random');
  late final _arc4random = _arc4randomPtr.asFunction<int Function()>();

  void arc4random_addrandom(
    ffi.Pointer<ffi.UnsignedChar> arg0,
    int arg1,
  ) {
    return _arc4random_addrandom(
      arg0,
      arg1,
    );
  }

  late final _arc4random_addrandomPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<ffi.UnsignedChar>, ffi.Int)>>('arc4random_addrandom');
  late final _arc4random_addrandom = _arc4random_addrandomPtr
      .asFunction<void Function(ffi.Pointer<ffi.UnsignedChar>, int)>();

  void arc4random_buf(
    ffi.Pointer<ffi.Void> __buf,
    int __nbytes,
  ) {
    return _arc4random_buf(
      __buf,
      __nbytes,
    );
  }

  late final _arc4random_bufPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<ffi.Void>, ffi.Size)>>('arc4random_buf');
  late final _arc4random_buf = _arc4random_bufPtr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, int)>();

  void arc4random_stir() {
    return _arc4random_stir();
  }

  late final _arc4random_stirPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('arc4random_stir');
  late final _arc4random_stir =
      _arc4random_stirPtr.asFunction<void Function()>();

  int arc4random_uniform(
    int __upper_bound,
  ) {
    return _arc4random_uniform(
      __upper_bound,
    );
  }

  late final _arc4random_uniformPtr =
      _lookup<ffi.NativeFunction<ffi.Uint32 Function(ffi.Uint32)>>(
          'arc4random_uniform');
  late final _arc4random_uniform =
      _arc4random_uniformPtr.asFunction<int Function(int)>();

  /// getcap(3) functions
  ffi.Pointer<ffi.Char> cgetcap(
    ffi.Pointer<ffi.Char> arg0,
    ffi.Pointer<ffi.Char> arg1,
    int arg2,
  ) {
    return _cgetcap(
      arg0,
      arg1,
      arg2,
    );
  }

  late final _cgetcapPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Char> Function(ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Char>, ffi.Int)>>('cgetcap');
  late final _cgetcap = _cgetcapPtr.asFunction<
      ffi.Pointer<ffi.Char> Function(
          ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>, int)>();

  int cgetclose() {
    return _cgetclose();
  }

  late final _cgetclosePtr =
      _lookup<ffi.NativeFunction<ffi.Int Function()>>('cgetclose');
  late final _cgetclose = _cgetclosePtr.asFunction<int Function()>();

  int cgetent(
    ffi.Pointer<ffi.Pointer<ffi.Char>> arg0,
    ffi.Pointer<ffi.Pointer<ffi.Char>> arg1,
    ffi.Pointer<ffi.Char> arg2,
  ) {
    return _cgetent(
      arg0,
      arg1,
      arg2,
    );
  }

  late final _cgetentPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(
              ffi.Pointer<ffi.Pointer<ffi.Char>>,
              ffi.Pointer<ffi.Pointer<ffi.Char>>,
              ffi.Pointer<ffi.Char>)>>('cgetent');
  late final _cgetent = _cgetentPtr.asFunction<
      int Function(ffi.Pointer<ffi.Pointer<ffi.Char>>,
          ffi.Pointer<ffi.Pointer<ffi.Char>>, ffi.Pointer<ffi.Char>)>();

  int cgetfirst(
    ffi.Pointer<ffi.Pointer<ffi.Char>> arg0,
    ffi.Pointer<ffi.Pointer<ffi.Char>> arg1,
  ) {
    return _cgetfirst(
      arg0,
      arg1,
    );
  }

  late final _cgetfirstPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<ffi.Pointer<ffi.Char>>,
              ffi.Pointer<ffi.Pointer<ffi.Char>>)>>('cgetfirst');
  late final _cgetfirst = _cgetfirstPtr.asFunction<
      int Function(ffi.Pointer<ffi.Pointer<ffi.Char>>,
          ffi.Pointer<ffi.Pointer<ffi.Char>>)>();

  int cgetmatch(
    ffi.Pointer<ffi.Char> arg0,
    ffi.Pointer<ffi.Char> arg1,
  ) {
    return _cgetmatch(
      arg0,
      arg1,
    );
  }

  late final _cgetmatchPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(
              ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>)>>('cgetmatch');
  late final _cgetmatch = _cgetmatchPtr
      .asFunction<int Function(ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>)>();

  int cgetnext(
    ffi.Pointer<ffi.Pointer<ffi.Char>> arg0,
    ffi.Pointer<ffi.Pointer<ffi.Char>> arg1,
  ) {
    return _cgetnext(
      arg0,
      arg1,
    );
  }

  late final _cgetnextPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<ffi.Pointer<ffi.Char>>,
              ffi.Pointer<ffi.Pointer<ffi.Char>>)>>('cgetnext');
  late final _cgetnext = _cgetnextPtr.asFunction<
      int Function(ffi.Pointer<ffi.Pointer<ffi.Char>>,
          ffi.Pointer<ffi.Pointer<ffi.Char>>)>();

  int cgetnum(
    ffi.Pointer<ffi.Char> arg0,
    ffi.Pointer<ffi.Char> arg1,
    ffi.Pointer<ffi.Long> arg2,
  ) {
    return _cgetnum(
      arg0,
      arg1,
      arg2,
    );
  }

  late final _cgetnumPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Long>)>>('cgetnum');
  late final _cgetnum = _cgetnumPtr.asFunction<
      int Function(ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>,
          ffi.Pointer<ffi.Long>)>();

  int cgetset(
    ffi.Pointer<ffi.Char> arg0,
  ) {
    return _cgetset(
      arg0,
    );
  }

  late final _cgetsetPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<ffi.Char>)>>(
          'cgetset');
  late final _cgetset =
      _cgetsetPtr.asFunction<int Function(ffi.Pointer<ffi.Char>)>();

  int cgetstr(
    ffi.Pointer<ffi.Char> arg0,
    ffi.Pointer<ffi.Char> arg1,
    ffi.Pointer<ffi.Pointer<ffi.Char>> arg2,
  ) {
    return _cgetstr(
      arg0,
      arg1,
      arg2,
    );
  }

  late final _cgetstrPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Pointer<ffi.Char>>)>>('cgetstr');
  late final _cgetstr = _cgetstrPtr.asFunction<
      int Function(ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>,
          ffi.Pointer<ffi.Pointer<ffi.Char>>)>();

  int cgetustr(
    ffi.Pointer<ffi.Char> arg0,
    ffi.Pointer<ffi.Char> arg1,
    ffi.Pointer<ffi.Pointer<ffi.Char>> arg2,
  ) {
    return _cgetustr(
      arg0,
      arg1,
      arg2,
    );
  }

  late final _cgetustrPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Pointer<ffi.Char>>)>>('cgetustr');
  late final _cgetustr = _cgetustrPtr.asFunction<
      int Function(ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>,
          ffi.Pointer<ffi.Pointer<ffi.Char>>)>();

  int daemon(
    int arg0,
    int arg1,
  ) {
    return _daemon(
      arg0,
      arg1,
    );
  }

  late final _daemonPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Int, ffi.Int)>>('daemon');
  late final _daemon = _daemonPtr.asFunction<int Function(int, int)>();

  ffi.Pointer<ffi.Char> devname(
    int arg0,
    int arg1,
  ) {
    return _devname(
      arg0,
      arg1,
    );
  }

  late final _devnamePtr = _lookup<
          ffi.NativeFunction<ffi.Pointer<ffi.Char> Function(dev_t, mode_t)>>(
      'devname');
  late final _devname =
      _devnamePtr.asFunction<ffi.Pointer<ffi.Char> Function(int, int)>();

  ffi.Pointer<ffi.Char> devname_r(
    int arg0,
    int arg1,
    ffi.Pointer<ffi.Char> buf,
    int len,
  ) {
    return _devname_r(
      arg0,
      arg1,
      buf,
      len,
    );
  }

  late final _devname_rPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Char> Function(
              dev_t, mode_t, ffi.Pointer<ffi.Char>, ffi.Int)>>('devname_r');
  late final _devname_r = _devname_rPtr.asFunction<
      ffi.Pointer<ffi.Char> Function(int, int, ffi.Pointer<ffi.Char>, int)>();

  ffi.Pointer<ffi.Char> getbsize(
    ffi.Pointer<ffi.Int> arg0,
    ffi.Pointer<ffi.Long> arg1,
  ) {
    return _getbsize(
      arg0,
      arg1,
    );
  }

  late final _getbsizePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Char> Function(
              ffi.Pointer<ffi.Int>, ffi.Pointer<ffi.Long>)>>('getbsize');
  late final _getbsize = _getbsizePtr.asFunction<
      ffi.Pointer<ffi.Char> Function(
          ffi.Pointer<ffi.Int>, ffi.Pointer<ffi.Long>)>();

  int getloadavg(
    ffi.Pointer<ffi.Double> arg0,
    int arg1,
  ) {
    return _getloadavg(
      arg0,
      arg1,
    );
  }

  late final _getloadavgPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<ffi.Double>, ffi.Int)>>('getloadavg');
  late final _getloadavg =
      _getloadavgPtr.asFunction<int Function(ffi.Pointer<ffi.Double>, int)>();

  ffi.Pointer<ffi.Char> getprogname() {
    return _getprogname();
  }

  late final _getprognamePtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Char> Function()>>(
          'getprogname');
  late final _getprogname =
      _getprognamePtr.asFunction<ffi.Pointer<ffi.Char> Function()>();

  void setprogname(
    ffi.Pointer<ffi.Char> arg0,
  ) {
    return _setprogname(
      arg0,
    );
  }

  late final _setprognamePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ffi.Char>)>>(
          'setprogname');
  late final _setprogname =
      _setprognamePtr.asFunction<void Function(ffi.Pointer<ffi.Char>)>();

  int heapsort(
    ffi.Pointer<ffi.Void> __base,
    int __nel,
    int __width,
    ffi.Pointer<
            ffi.NativeFunction<
                ffi.Int Function(ffi.Pointer<ffi.Void>, ffi.Pointer<ffi.Void>)>>
        __compar,
  ) {
    return _heapsort(
      __base,
      __nel,
      __width,
      __compar,
    );
  }

  late final _heapsortPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(
              ffi.Pointer<ffi.Void>,
              ffi.Size,
              ffi.Size,
              ffi.Pointer<
                  ffi.NativeFunction<
                      ffi.Int Function(ffi.Pointer<ffi.Void>,
                          ffi.Pointer<ffi.Void>)>>)>>('heapsort');
  late final _heapsort = _heapsortPtr.asFunction<
      int Function(
          ffi.Pointer<ffi.Void>,
          int,
          int,
          ffi.Pointer<
              ffi.NativeFunction<
                  ffi.Int Function(
                      ffi.Pointer<ffi.Void>, ffi.Pointer<ffi.Void>)>>)>();

  int mergesort(
    ffi.Pointer<ffi.Void> __base,
    int __nel,
    int __width,
    ffi.Pointer<
            ffi.NativeFunction<
                ffi.Int Function(ffi.Pointer<ffi.Void>, ffi.Pointer<ffi.Void>)>>
        __compar,
  ) {
    return _mergesort(
      __base,
      __nel,
      __width,
      __compar,
    );
  }

  late final _mergesortPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(
              ffi.Pointer<ffi.Void>,
              ffi.Size,
              ffi.Size,
              ffi.Pointer<
                  ffi.NativeFunction<
                      ffi.Int Function(ffi.Pointer<ffi.Void>,
                          ffi.Pointer<ffi.Void>)>>)>>('mergesort');
  late final _mergesort = _mergesortPtr.asFunction<
      int Function(
          ffi.Pointer<ffi.Void>,
          int,
          int,
          ffi.Pointer<
              ffi.NativeFunction<
                  ffi.Int Function(
                      ffi.Pointer<ffi.Void>, ffi.Pointer<ffi.Void>)>>)>();

  void psort(
    ffi.Pointer<ffi.Void> __base,
    int __nel,
    int __width,
    ffi.Pointer<
            ffi.NativeFunction<
                ffi.Int Function(ffi.Pointer<ffi.Void>, ffi.Pointer<ffi.Void>)>>
        __compar,
  ) {
    return _psort(
      __base,
      __nel,
      __width,
      __compar,
    );
  }

  late final _psortPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<ffi.Void>,
              ffi.Size,
              ffi.Size,
              ffi.Pointer<
                  ffi.NativeFunction<
                      ffi.Int Function(ffi.Pointer<ffi.Void>,
                          ffi.Pointer<ffi.Void>)>>)>>('psort');
  late final _psort = _psortPtr.asFunction<
      void Function(
          ffi.Pointer<ffi.Void>,
          int,
          int,
          ffi.Pointer<
              ffi.NativeFunction<
                  ffi.Int Function(
                      ffi.Pointer<ffi.Void>, ffi.Pointer<ffi.Void>)>>)>();

  void psort_r(
    ffi.Pointer<ffi.Void> __base,
    int __nel,
    int __width,
    ffi.Pointer<ffi.Void> arg3,
    ffi.Pointer<
            ffi.NativeFunction<
                ffi.Int Function(ffi.Pointer<ffi.Void>, ffi.Pointer<ffi.Void>,
                    ffi.Pointer<ffi.Void>)>>
        __compar,
  ) {
    return _psort_r(
      __base,
      __nel,
      __width,
      arg3,
      __compar,
    );
  }

  late final _psort_rPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<ffi.Void>,
              ffi.Size,
              ffi.Size,
              ffi.Pointer<ffi.Void>,
              ffi.Pointer<
                  ffi.NativeFunction<
                      ffi.Int Function(
                          ffi.Pointer<ffi.Void>,
                          ffi.Pointer<ffi.Void>,
                          ffi.Pointer<ffi.Void>)>>)>>('psort_r');
  late final _psort_r = _psort_rPtr.asFunction<
      void Function(
          ffi.Pointer<ffi.Void>,
          int,
          int,
          ffi.Pointer<ffi.Void>,
          ffi.Pointer<
              ffi.NativeFunction<
                  ffi.Int Function(ffi.Pointer<ffi.Void>, ffi.Pointer<ffi.Void>,
                      ffi.Pointer<ffi.Void>)>>)>();

  void qsort_r(
    ffi.Pointer<ffi.Void> __base,
    int __nel,
    int __width,
    ffi.Pointer<ffi.Void> arg3,
    ffi.Pointer<
            ffi.NativeFunction<
                ffi.Int Function(ffi.Pointer<ffi.Void>, ffi.Pointer<ffi.Void>,
                    ffi.Pointer<ffi.Void>)>>
        __compar,
  ) {
    return _qsort_r(
      __base,
      __nel,
      __width,
      arg3,
      __compar,
    );
  }

  late final _qsort_rPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<ffi.Void>,
              ffi.Size,
              ffi.Size,
              ffi.Pointer<ffi.Void>,
              ffi.Pointer<
                  ffi.NativeFunction<
                      ffi.Int Function(
                          ffi.Pointer<ffi.Void>,
                          ffi.Pointer<ffi.Void>,
                          ffi.Pointer<ffi.Void>)>>)>>('qsort_r');
  late final _qsort_r = _qsort_rPtr.asFunction<
      void Function(
          ffi.Pointer<ffi.Void>,
          int,
          int,
          ffi.Pointer<ffi.Void>,
          ffi.Pointer<
              ffi.NativeFunction<
                  ffi.Int Function(ffi.Pointer<ffi.Void>, ffi.Pointer<ffi.Void>,
                      ffi.Pointer<ffi.Void>)>>)>();

  int radixsort(
    ffi.Pointer<ffi.Pointer<ffi.UnsignedChar>> __base,
    int __nel,
    ffi.Pointer<ffi.UnsignedChar> __table,
    int __endbyte,
  ) {
    return _radixsort(
      __base,
      __nel,
      __table,
      __endbyte,
    );
  }

  late final _radixsortPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<ffi.Pointer<ffi.UnsignedChar>>, ffi.Int,
              ffi.Pointer<ffi.UnsignedChar>, ffi.UnsignedInt)>>('radixsort');
  late final _radixsort = _radixsortPtr.asFunction<
      int Function(ffi.Pointer<ffi.Pointer<ffi.UnsignedChar>>, int,
          ffi.Pointer<ffi.UnsignedChar>, int)>();

  int rpmatch(
    ffi.Pointer<ffi.Char> arg0,
  ) {
    return _rpmatch(
      arg0,
    );
  }

  late final _rpmatchPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<ffi.Char>)>>(
          'rpmatch');
  late final _rpmatch =
      _rpmatchPtr.asFunction<int Function(ffi.Pointer<ffi.Char>)>();

  int sradixsort(
    ffi.Pointer<ffi.Pointer<ffi.UnsignedChar>> __base,
    int __nel,
    ffi.Pointer<ffi.UnsignedChar> __table,
    int __endbyte,
  ) {
    return _sradixsort(
      __base,
      __nel,
      __table,
      __endbyte,
    );
  }

  late final _sradixsortPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<ffi.Pointer<ffi.UnsignedChar>>, ffi.Int,
              ffi.Pointer<ffi.UnsignedChar>, ffi.UnsignedInt)>>('sradixsort');
  late final _sradixsort = _sradixsortPtr.asFunction<
      int Function(ffi.Pointer<ffi.Pointer<ffi.UnsignedChar>>, int,
          ffi.Pointer<ffi.UnsignedChar>, int)>();

  void sranddev() {
    return _sranddev();
  }

  late final _sranddevPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('sranddev');
  late final _sranddev = _sranddevPtr.asFunction<void Function()>();

  void srandomdev() {
    return _srandomdev();
  }

  late final _srandomdevPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('srandomdev');
  late final _srandomdev = _srandomdevPtr.asFunction<void Function()>();

  ffi.Pointer<ffi.Void> reallocf(
    ffi.Pointer<ffi.Void> __ptr,
    int __size,
  ) {
    return _reallocf(
      __ptr,
      __size,
    );
  }

  late final _reallocfPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Void> Function(
              ffi.Pointer<ffi.Void>, ffi.Size)>>('reallocf');
  late final _reallocf = _reallocfPtr
      .asFunction<ffi.Pointer<ffi.Void> Function(ffi.Pointer<ffi.Void>, int)>();

  int strtonum(
    ffi.Pointer<ffi.Char> __numstr,
    int __minval,
    int __maxval,
    ffi.Pointer<ffi.Pointer<ffi.Char>> __errstrp,
  ) {
    return _strtonum(
      __numstr,
      __minval,
      __maxval,
      __errstrp,
    );
  }

  late final _strtonumPtr = _lookup<
      ffi.NativeFunction<
          ffi.LongLong Function(ffi.Pointer<ffi.Char>, ffi.LongLong,
              ffi.LongLong, ffi.Pointer<ffi.Pointer<ffi.Char>>)>>('strtonum');
  late final _strtonum = _strtonumPtr.asFunction<
      int Function(ffi.Pointer<ffi.Char>, int, int,
          ffi.Pointer<ffi.Pointer<ffi.Char>>)>();

  int strtoq(
    ffi.Pointer<ffi.Char> __str,
    ffi.Pointer<ffi.Pointer<ffi.Char>> __endptr,
    int __base,
  ) {
    return _strtoq(
      __str,
      __endptr,
      __base,
    );
  }

  late final _strtoqPtr = _lookup<
      ffi.NativeFunction<
          ffi.LongLong Function(ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Pointer<ffi.Char>>, ffi.Int)>>('strtoq');
  late final _strtoq = _strtoqPtr.asFunction<
      int Function(
          ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Pointer<ffi.Char>>, int)>();

  int strtouq(
    ffi.Pointer<ffi.Char> __str,
    ffi.Pointer<ffi.Pointer<ffi.Char>> __endptr,
    int __base,
  ) {
    return _strtouq(
      __str,
      __endptr,
      __base,
    );
  }

  late final _strtouqPtr = _lookup<
      ffi.NativeFunction<
          ffi.UnsignedLongLong Function(ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Pointer<ffi.Char>>, ffi.Int)>>('strtouq');
  late final _strtouq = _strtouqPtr.asFunction<
      int Function(
          ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Pointer<ffi.Char>>, int)>();

  /// getsubopt(3) external variable
  late final ffi.Pointer<ffi.Pointer<ffi.Char>> _suboptarg =
      _lookup<ffi.Pointer<ffi.Char>>('suboptarg');

  ffi.Pointer<ffi.Char> get suboptarg => _suboptarg.value;

  set suboptarg(ffi.Pointer<ffi.Char> value) => _suboptarg.value = value;

  /// --------------------------------------------------------------------------
  /// The TensorFlow Lite Runtime version.
  ///
  /// Returns a pointer to a statically allocated string that is the version
  /// number of the (potentially dynamically loaded) TF Lite Runtime library.
  /// TensorFlow Lite uses semantic versioning, and the return value should be
  /// in semver 2 format <http://semver.org>, starting with MAJOR.MINOR.PATCH,
  /// e.g. "2.12.0" or "2.13.0-rc2".
  ffi.Pointer<ffi.Char> TfLiteVersion() {
    return _TfLiteVersion();
  }

  late final _TfLiteVersionPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Char> Function()>>(
          'TfLiteVersion');
  late final _TfLiteVersion =
      _TfLiteVersionPtr.asFunction<ffi.Pointer<ffi.Char> Function()>();

  /// The supported TensorFlow Lite model file Schema version.
  ///
  /// Returns the (major) version number of the Schema used for model
  /// files that is supported by the (potentially dynamically loaded)
  /// TensorFlow Lite Runtime.
  ///
  /// Model files using schema versions different to this may not be supported by
  /// the current version of the TF Lite Runtime.
  int TfLiteSchemaVersion() {
    return _TfLiteSchemaVersion();
  }

  late final _TfLiteSchemaVersionPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function()>>('TfLiteSchemaVersion');
  late final _TfLiteSchemaVersion =
      _TfLiteSchemaVersionPtr.asFunction<int Function()>();

  /// Returns a model from the provided buffer, or null on failure.
  ///
  /// NOTE: The caller retains ownership of the `model_data` buffer and should
  /// ensure that the lifetime of the `model_data` buffer must be at least as long
  /// as the lifetime of the `TfLiteModel` and of any `TfLiteInterpreter` objects
  /// created from that `TfLiteModel`, and furthermore the contents of the
  /// `model_data` buffer must not be modified during that time."
  ffi.Pointer<TfLiteModel> TfLiteModelCreate(
    ffi.Pointer<ffi.Void> model_data,
    int model_size,
  ) {
    return _TfLiteModelCreate(
      model_data,
      model_size,
    );
  }

  late final _TfLiteModelCreatePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<TfLiteModel> Function(
              ffi.Pointer<ffi.Void>, ffi.Size)>>('TfLiteModelCreate');
  late final _TfLiteModelCreate = _TfLiteModelCreatePtr.asFunction<
      ffi.Pointer<TfLiteModel> Function(ffi.Pointer<ffi.Void>, int)>();

  /// Same as `TfLiteModelCreate` with customizble error reporter.
  /// * `reporter` takes the provided `user_data` object, as well as a C-style
  /// format string and arg list (see also vprintf).
  /// * `user_data` is optional. If non-null, it is owned by the client and must
  /// remain valid for the duration of the interpreter lifetime.
  ffi.Pointer<TfLiteModel> TfLiteModelCreateWithErrorReporter(
    ffi.Pointer<ffi.Void> model_data,
    int model_size,
    ffi.Pointer<
            ffi.NativeFunction<
                ffi.Void Function(
                    ffi.Pointer<ffi.Void>, ffi.Pointer<ffi.Char>, va_list)>>
        reporter,
    ffi.Pointer<ffi.Void> user_data,
  ) {
    return _TfLiteModelCreateWithErrorReporter(
      model_data,
      model_size,
      reporter,
      user_data,
    );
  }

  late final _TfLiteModelCreateWithErrorReporterPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<TfLiteModel> Function(
              ffi.Pointer<ffi.Void>,
              ffi.Size,
              ffi.Pointer<
                  ffi.NativeFunction<
                      ffi.Void Function(ffi.Pointer<ffi.Void>,
                          ffi.Pointer<ffi.Char>, va_list)>>,
              ffi.Pointer<ffi.Void>)>>('TfLiteModelCreateWithErrorReporter');
  late final _TfLiteModelCreateWithErrorReporter =
      _TfLiteModelCreateWithErrorReporterPtr.asFunction<
          ffi.Pointer<TfLiteModel> Function(
              ffi.Pointer<ffi.Void>,
              int,
              ffi.Pointer<
                  ffi.NativeFunction<
                      ffi.Void Function(ffi.Pointer<ffi.Void>,
                          ffi.Pointer<ffi.Char>, va_list)>>,
              ffi.Pointer<ffi.Void>)>();

  /// Returns a model from the provided file, or null on failure.
  ///
  /// NOTE: The file's contents must not be modified during the lifetime of the
  /// `TfLiteModel` or of any `TfLiteInterpreter` objects created from that
  /// `TfLiteModel`.
  ffi.Pointer<TfLiteModel> TfLiteModelCreateFromFile(
    ffi.Pointer<ffi.Char> model_path,
  ) {
    return _TfLiteModelCreateFromFile(
      model_path,
    );
  }

  late final _TfLiteModelCreateFromFilePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<TfLiteModel> Function(
              ffi.Pointer<ffi.Char>)>>('TfLiteModelCreateFromFile');
  late final _TfLiteModelCreateFromFile = _TfLiteModelCreateFromFilePtr
      .asFunction<ffi.Pointer<TfLiteModel> Function(ffi.Pointer<ffi.Char>)>();

  /// Same as `TfLiteModelCreateFromFile` with customizble error reporter.
  /// * `reporter` takes the provided `user_data` object, as well as a C-style
  /// format string and arg list (see also vprintf).
  /// * `user_data` is optional. If non-null, it is owned by the client and must
  /// remain valid for the duration of the interpreter lifetime.
  ffi.Pointer<TfLiteModel> TfLiteModelCreateFromFileWithErrorReporter(
    ffi.Pointer<ffi.Char> model_path,
    ffi.Pointer<
            ffi.NativeFunction<
                ffi.Void Function(
                    ffi.Pointer<ffi.Void>, ffi.Pointer<ffi.Char>, va_list)>>
        reporter,
    ffi.Pointer<ffi.Void> user_data,
  ) {
    return _TfLiteModelCreateFromFileWithErrorReporter(
      model_path,
      reporter,
      user_data,
    );
  }

  late final _TfLiteModelCreateFromFileWithErrorReporterPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<TfLiteModel> Function(
                  ffi.Pointer<ffi.Char>,
                  ffi.Pointer<
                      ffi.NativeFunction<
                          ffi.Void Function(ffi.Pointer<ffi.Void>,
                              ffi.Pointer<ffi.Char>, va_list)>>,
                  ffi.Pointer<ffi.Void>)>>(
      'TfLiteModelCreateFromFileWithErrorReporter');
  late final _TfLiteModelCreateFromFileWithErrorReporter =
      _TfLiteModelCreateFromFileWithErrorReporterPtr.asFunction<
          ffi.Pointer<TfLiteModel> Function(
              ffi.Pointer<ffi.Char>,
              ffi.Pointer<
                  ffi.NativeFunction<
                      ffi.Void Function(ffi.Pointer<ffi.Void>,
                          ffi.Pointer<ffi.Char>, va_list)>>,
              ffi.Pointer<ffi.Void>)>();

  /// Destroys the model instance.
  void TfLiteModelDelete(
    ffi.Pointer<TfLiteModel> model,
  ) {
    return _TfLiteModelDelete(
      model,
    );
  }

  late final _TfLiteModelDeletePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<TfLiteModel>)>>(
          'TfLiteModelDelete');
  late final _TfLiteModelDelete = _TfLiteModelDeletePtr.asFunction<
      void Function(ffi.Pointer<TfLiteModel>)>();

  /// Returns a new interpreter options instances.
  ffi.Pointer<TfLiteInterpreterOptions> TfLiteInterpreterOptionsCreate() {
    return _TfLiteInterpreterOptionsCreate();
  }

  late final _TfLiteInterpreterOptionsCreatePtr = _lookup<
          ffi.NativeFunction<ffi.Pointer<TfLiteInterpreterOptions> Function()>>(
      'TfLiteInterpreterOptionsCreate');
  late final _TfLiteInterpreterOptionsCreate =
      _TfLiteInterpreterOptionsCreatePtr.asFunction<
          ffi.Pointer<TfLiteInterpreterOptions> Function()>();

  /// Creates and returns a shallow copy of an options object.
  ///
  /// The caller is responsible for calling `TfLiteInterpreterOptionsDelete` to
  /// deallocate the object pointed to by the returned pointer.
  ffi.Pointer<TfLiteInterpreterOptions> TfLiteInterpreterOptionsCopy(
    ffi.Pointer<TfLiteInterpreterOptions> from,
  ) {
    return _TfLiteInterpreterOptionsCopy(
      from,
    );
  }

  late final _TfLiteInterpreterOptionsCopyPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<TfLiteInterpreterOptions> Function(
                  ffi.Pointer<TfLiteInterpreterOptions>)>>(
      'TfLiteInterpreterOptionsCopy');
  late final _TfLiteInterpreterOptionsCopy =
      _TfLiteInterpreterOptionsCopyPtr.asFunction<
          ffi.Pointer<TfLiteInterpreterOptions> Function(
              ffi.Pointer<TfLiteInterpreterOptions>)>();

  /// Destroys the interpreter options instance.
  void TfLiteInterpreterOptionsDelete(
    ffi.Pointer<TfLiteInterpreterOptions> options,
  ) {
    return _TfLiteInterpreterOptionsDelete(
      options,
    );
  }

  late final _TfLiteInterpreterOptionsDeletePtr = _lookup<
          ffi.NativeFunction<
              ffi.Void Function(ffi.Pointer<TfLiteInterpreterOptions>)>>(
      'TfLiteInterpreterOptionsDelete');
  late final _TfLiteInterpreterOptionsDelete =
      _TfLiteInterpreterOptionsDeletePtr.asFunction<
          void Function(ffi.Pointer<TfLiteInterpreterOptions>)>();

  /// Sets the number of CPU threads to use for the interpreter.
  void TfLiteInterpreterOptionsSetNumThreads(
    ffi.Pointer<TfLiteInterpreterOptions> options,
    int num_threads,
  ) {
    return _TfLiteInterpreterOptionsSetNumThreads(
      options,
      num_threads,
    );
  }

  late final _TfLiteInterpreterOptionsSetNumThreadsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<TfLiteInterpreterOptions>,
              ffi.Int32)>>('TfLiteInterpreterOptionsSetNumThreads');
  late final _TfLiteInterpreterOptionsSetNumThreads =
      _TfLiteInterpreterOptionsSetNumThreadsPtr.asFunction<
          void Function(ffi.Pointer<TfLiteInterpreterOptions>, int)>();

  /// Adds a delegate to be applied during `TfLiteInterpreter` creation.
  ///
  /// If delegate application fails, interpreter creation will also fail with an
  /// associated error logged.
  ///
  /// NOTE: The caller retains ownership of the delegate and should ensure that it
  /// remains valid for the duration of any created interpreter's lifetime.
  ///
  /// If you are NOT using "TensorFlow Lite in Play Services", and NOT building
  /// with `TFLITE_WITH_STABLE_ABI` or `TFLITE_USE_OPAQUE_DELEGATE` macros enabled,
  /// it is possible to pass a `TfLiteDelegate*` rather than a
  /// `TfLiteOpaqueDelegate*` to this function, since in those cases,
  /// `TfLiteOpaqueDelegate` is just a typedef alias for `TfLiteDelegate`.
  /// This is for compatibility with existing source code
  /// and existing delegates.  For new delegates, it is recommended to
  /// use `TfLiteOpaqueDelegate` rather than `TfLiteDelegate`.  (See
  /// `TfLiteOpaqueDelegate` in tensorflow/lite/core/c/c_api_types.h.)
  void TfLiteInterpreterOptionsAddDelegate(
    ffi.Pointer<TfLiteInterpreterOptions> options,
    ffi.Pointer<TfLiteOpaqueDelegate> delegate,
  ) {
    return _TfLiteInterpreterOptionsAddDelegate(
      options,
      delegate,
    );
  }

  late final _TfLiteInterpreterOptionsAddDelegatePtr = _lookup<
          ffi.NativeFunction<
              ffi.Void Function(ffi.Pointer<TfLiteInterpreterOptions>,
                  ffi.Pointer<TfLiteOpaqueDelegate>)>>(
      'TfLiteInterpreterOptionsAddDelegate');
  late final _TfLiteInterpreterOptionsAddDelegate =
      _TfLiteInterpreterOptionsAddDelegatePtr.asFunction<
          void Function(ffi.Pointer<TfLiteInterpreterOptions>,
              ffi.Pointer<TfLiteOpaqueDelegate>)>();

  /// Sets a custom error reporter for interpreter execution.
  ///
  /// * `reporter` takes the provided `user_data` object, as well as a C-style
  /// format string and arg list (see also vprintf).
  /// * `user_data` is optional. If non-null, it is owned by the client and must
  /// remain valid for the duration of the interpreter lifetime.
  void TfLiteInterpreterOptionsSetErrorReporter(
    ffi.Pointer<TfLiteInterpreterOptions> options,
    ffi.Pointer<
            ffi.NativeFunction<
                ffi.Void Function(
                    ffi.Pointer<ffi.Void>, ffi.Pointer<ffi.Char>, va_list)>>
        reporter,
    ffi.Pointer<ffi.Void> user_data,
  ) {
    return _TfLiteInterpreterOptionsSetErrorReporter(
      options,
      reporter,
      user_data,
    );
  }

  late final _TfLiteInterpreterOptionsSetErrorReporterPtr = _lookup<
          ffi.NativeFunction<
              ffi.Void Function(
                  ffi.Pointer<TfLiteInterpreterOptions>,
                  ffi.Pointer<
                      ffi.NativeFunction<
                          ffi.Void Function(ffi.Pointer<ffi.Void>,
                              ffi.Pointer<ffi.Char>, va_list)>>,
                  ffi.Pointer<ffi.Void>)>>(
      'TfLiteInterpreterOptionsSetErrorReporter');
  late final _TfLiteInterpreterOptionsSetErrorReporter =
      _TfLiteInterpreterOptionsSetErrorReporterPtr.asFunction<
          void Function(
              ffi.Pointer<TfLiteInterpreterOptions>,
              ffi.Pointer<
                  ffi.NativeFunction<
                      ffi.Void Function(ffi.Pointer<ffi.Void>,
                          ffi.Pointer<ffi.Char>, va_list)>>,
              ffi.Pointer<ffi.Void>)>();

  /// Adds an op registration to be applied during `TfLiteInterpreter` creation.
  ///
  /// The `TfLiteRegistrationExternal` object is needed to implement custom op of
  /// TFLite Interpreter via C API. Calling this function ensures that any
  /// `TfLiteInterpreter` created with the specified `options` can execute models
  /// that use the custom operator specified in `registration`.
  /// Please refer https://www.tensorflow.org/lite/guide/ops_custom for custom op
  /// support.
  /// NOTE: The caller retains ownership of the TfLiteRegistrationExternal object
  /// and should ensure that it remains valid for the duration of any created
  /// interpreter's lifetime.
  /// WARNING: This is an experimental API and subject to change.
  void TfLiteInterpreterOptionsAddRegistrationExternal(
    ffi.Pointer<TfLiteInterpreterOptions> options,
    ffi.Pointer<TfLiteRegistrationExternal> registration,
  ) {
    return _TfLiteInterpreterOptionsAddRegistrationExternal(
      options,
      registration,
    );
  }

  late final _TfLiteInterpreterOptionsAddRegistrationExternalPtr = _lookup<
          ffi.NativeFunction<
              ffi.Void Function(ffi.Pointer<TfLiteInterpreterOptions>,
                  ffi.Pointer<TfLiteRegistrationExternal>)>>(
      'TfLiteInterpreterOptionsAddRegistrationExternal');
  late final _TfLiteInterpreterOptionsAddRegistrationExternal =
      _TfLiteInterpreterOptionsAddRegistrationExternalPtr.asFunction<
          void Function(ffi.Pointer<TfLiteInterpreterOptions>,
              ffi.Pointer<TfLiteRegistrationExternal>)>();

  /// Enables users to cancel in-flight invocations with `TfLiteInterpreterCancel`.
  ///
  /// By default it is disabled and calling to `TfLiteInterpreterCancel` will
  /// return kTfLiteError. See `TfLiteInterpreterCancel`.
  ///
  /// WARNING: This is an experimental API and subject to change.
  int TfLiteInterpreterOptionsEnableCancellation(
    ffi.Pointer<TfLiteInterpreterOptions> options,
    bool enable,
  ) {
    return _TfLiteInterpreterOptionsEnableCancellation(
      options,
      enable,
    );
  }

  late final _TfLiteInterpreterOptionsEnableCancellationPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<TfLiteInterpreterOptions>,
              ffi.Bool)>>('TfLiteInterpreterOptionsEnableCancellation');
  late final _TfLiteInterpreterOptionsEnableCancellation =
      _TfLiteInterpreterOptionsEnableCancellationPtr.asFunction<
          int Function(ffi.Pointer<TfLiteInterpreterOptions>, bool)>();

  /// Returns a new interpreter using the provided model and options, or null on
  /// failure.
  ///
  /// * `model` must be a valid model instance. The caller retains ownership of the
  /// object, and may destroy it (via TfLiteModelDelete) immediately after
  /// creating the interpreter.  However, if the TfLiteModel was allocated with
  /// TfLiteModelCreate, then the `model_data` buffer that was passed to
  /// TfLiteModelCreate must outlive the lifetime of the TfLiteInterpreter object
  /// that this function returns, and must not be modified during that time;
  /// and if the TfLiteModel was allocated with TfLiteModelCreateFromFile, then
  /// the contents of the model file must not be modified during the lifetime of
  /// the TfLiteInterpreter object that this function returns.
  /// * `optional_options` may be null. The caller retains ownership of the object,
  /// and can safely destroy it (via TfLiteInterpreterOptionsDelete) immediately
  /// after creating the interpreter.
  ///
  /// NOTE: The client *must* explicitly allocate tensors before attempting to
  /// access input tensor data or invoke the interpreter.
  ffi.Pointer<TfLiteInterpreter> TfLiteInterpreterCreate(
    ffi.Pointer<TfLiteModel> model,
    ffi.Pointer<TfLiteInterpreterOptions> optional_options,
  ) {
    return _TfLiteInterpreterCreate(
      model,
      optional_options,
    );
  }

  late final _TfLiteInterpreterCreatePtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<TfLiteInterpreter> Function(ffi.Pointer<TfLiteModel>,
                  ffi.Pointer<TfLiteInterpreterOptions>)>>(
      'TfLiteInterpreterCreate');
  late final _TfLiteInterpreterCreate = _TfLiteInterpreterCreatePtr.asFunction<
      ffi.Pointer<TfLiteInterpreter> Function(
          ffi.Pointer<TfLiteModel>, ffi.Pointer<TfLiteInterpreterOptions>)>();

  /// Destroys the interpreter.
  void TfLiteInterpreterDelete(
    ffi.Pointer<TfLiteInterpreter> interpreter,
  ) {
    return _TfLiteInterpreterDelete(
      interpreter,
    );
  }

  late final _TfLiteInterpreterDeletePtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<TfLiteInterpreter>)>>('TfLiteInterpreterDelete');
  late final _TfLiteInterpreterDelete = _TfLiteInterpreterDeletePtr.asFunction<
      void Function(ffi.Pointer<TfLiteInterpreter>)>();

  /// Returns the number of input tensors associated with the model.
  int TfLiteInterpreterGetInputTensorCount(
    ffi.Pointer<TfLiteInterpreter> interpreter,
  ) {
    return _TfLiteInterpreterGetInputTensorCount(
      interpreter,
    );
  }

  late final _TfLiteInterpreterGetInputTensorCountPtr = _lookup<
          ffi.NativeFunction<
              ffi.Int32 Function(ffi.Pointer<TfLiteInterpreter>)>>(
      'TfLiteInterpreterGetInputTensorCount');
  late final _TfLiteInterpreterGetInputTensorCount =
      _TfLiteInterpreterGetInputTensorCountPtr.asFunction<
          int Function(ffi.Pointer<TfLiteInterpreter>)>();

  /// Returns a pointer to an array of input tensor indices.  The length of the
  /// array can be obtained via a call to `TfLiteInterpreterGetInputTensorCount`.
  ///
  /// Typically the input tensors associated with an `interpreter` would be set
  /// during the initialization of the `interpreter`, through a mechanism like the
  /// `InterpreterBuilder`, and remain unchanged throughout the lifetime of the
  /// interpreter.  However, there are some circumstances in which the pointer may
  /// not remain valid throughout the lifetime of the interpreter, because calls
  /// to `SetInputs` on the interpreter invalidate the returned pointer.
  ///
  /// The ownership of the array remains with the TFLite runtime.
  ffi.Pointer<ffi.Int> TfLiteInterpreterInputTensorIndices(
    ffi.Pointer<TfLiteInterpreter> interpreter,
  ) {
    return _TfLiteInterpreterInputTensorIndices(
      interpreter,
    );
  }

  late final _TfLiteInterpreterInputTensorIndicesPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<ffi.Int> Function(ffi.Pointer<TfLiteInterpreter>)>>(
      'TfLiteInterpreterInputTensorIndices');
  late final _TfLiteInterpreterInputTensorIndices =
      _TfLiteInterpreterInputTensorIndicesPtr.asFunction<
          ffi.Pointer<ffi.Int> Function(ffi.Pointer<TfLiteInterpreter>)>();

  /// Returns the tensor associated with the input index.
  /// REQUIRES: 0 <= input_index < TfLiteInterpreterGetInputTensorCount(tensor)
  ffi.Pointer<TfLiteTensor> TfLiteInterpreterGetInputTensor(
    ffi.Pointer<TfLiteInterpreter> interpreter,
    int input_index,
  ) {
    return _TfLiteInterpreterGetInputTensor(
      interpreter,
      input_index,
    );
  }

  late final _TfLiteInterpreterGetInputTensorPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<TfLiteTensor> Function(ffi.Pointer<TfLiteInterpreter>,
              ffi.Int32)>>('TfLiteInterpreterGetInputTensor');
  late final _TfLiteInterpreterGetInputTensor =
      _TfLiteInterpreterGetInputTensorPtr.asFunction<
          ffi.Pointer<TfLiteTensor> Function(
              ffi.Pointer<TfLiteInterpreter>, int)>();

  /// Resizes the specified input tensor.
  ///
  /// NOTE: After a resize, the client *must* explicitly allocate tensors before
  /// attempting to access the resized tensor data or invoke the interpreter.
  ///
  /// REQUIRES: 0 <= input_index < TfLiteInterpreterGetInputTensorCount(tensor)
  ///
  /// This function makes a copy of the input dimensions, so the client can safely
  /// deallocate `input_dims` immediately after this function returns.
  int TfLiteInterpreterResizeInputTensor(
    ffi.Pointer<TfLiteInterpreter> interpreter,
    int input_index,
    ffi.Pointer<ffi.Int> input_dims,
    int input_dims_size,
  ) {
    return _TfLiteInterpreterResizeInputTensor(
      interpreter,
      input_index,
      input_dims,
      input_dims_size,
    );
  }

  late final _TfLiteInterpreterResizeInputTensorPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<TfLiteInterpreter>,
              ffi.Int32,
              ffi.Pointer<ffi.Int>,
              ffi.Int32)>>('TfLiteInterpreterResizeInputTensor');
  late final _TfLiteInterpreterResizeInputTensor =
      _TfLiteInterpreterResizeInputTensorPtr.asFunction<
          int Function(ffi.Pointer<TfLiteInterpreter>, int,
              ffi.Pointer<ffi.Int>, int)>();

  /// Updates allocations for all tensors, resizing dependent tensors using the
  /// specified input tensor dimensionality.
  ///
  /// This is a relatively expensive operation, and need only be called after
  /// creating the graph and/or resizing any inputs.
  int TfLiteInterpreterAllocateTensors(
    ffi.Pointer<TfLiteInterpreter> interpreter,
  ) {
    return _TfLiteInterpreterAllocateTensors(
      interpreter,
    );
  }

  late final _TfLiteInterpreterAllocateTensorsPtr = _lookup<
          ffi.NativeFunction<
              ffi.Int32 Function(ffi.Pointer<TfLiteInterpreter>)>>(
      'TfLiteInterpreterAllocateTensors');
  late final _TfLiteInterpreterAllocateTensors =
      _TfLiteInterpreterAllocateTensorsPtr.asFunction<
          int Function(ffi.Pointer<TfLiteInterpreter>)>();

  /// Runs inference for the loaded graph.
  ///
  /// Before calling this function, the caller should first invoke
  /// TfLiteInterpreterAllocateTensors() and should also set the values for the
  /// input tensors.  After successfully calling this function, the values for the
  /// output tensors will be set.
  ///
  /// NOTE: It is possible that the interpreter is not in a ready state to
  /// evaluate (e.g., if AllocateTensors() hasn't been called, or if a
  /// ResizeInputTensor() has been performed without a subsequent call to
  /// AllocateTensors()).
  ///
  /// If the (experimental!) delegate fallback option was enabled in the
  /// interpreter options, then the interpreter will automatically fall back to
  /// not using any delegates if execution with delegates fails. For details, see
  /// TfLiteInterpreterOptionsSetEnableDelegateFallback in c_api_experimental.h.
  ///
  /// Returns one of the following status codes:
  /// - kTfLiteOk: Success. Output is valid.
  /// - kTfLiteDelegateError: Execution with delegates failed, due to a problem
  /// with the delegate(s). If fallback was not enabled, output is invalid.
  /// If fallback was enabled, this return value indicates that fallback
  /// succeeded, the output is valid, and all delegates previously applied to
  /// the interpreter have been undone.
  /// - kTfLiteApplicationError: Same as for kTfLiteDelegateError, except that
  /// the problem was not with the delegate itself, but rather was
  /// due to an incompatibility between the delegate(s) and the
  /// interpreter or model.
  /// - kTfLiteError: Unexpected/runtime failure. Output is invalid.
  int TfLiteInterpreterInvoke(
    ffi.Pointer<TfLiteInterpreter> interpreter,
  ) {
    return _TfLiteInterpreterInvoke(
      interpreter,
    );
  }

  late final _TfLiteInterpreterInvokePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<TfLiteInterpreter>)>>('TfLiteInterpreterInvoke');
  late final _TfLiteInterpreterInvoke = _TfLiteInterpreterInvokePtr.asFunction<
      int Function(ffi.Pointer<TfLiteInterpreter>)>();

  /// Returns the number of output tensors associated with the model.
  int TfLiteInterpreterGetOutputTensorCount(
    ffi.Pointer<TfLiteInterpreter> interpreter,
  ) {
    return _TfLiteInterpreterGetOutputTensorCount(
      interpreter,
    );
  }

  late final _TfLiteInterpreterGetOutputTensorCountPtr = _lookup<
          ffi.NativeFunction<
              ffi.Int32 Function(ffi.Pointer<TfLiteInterpreter>)>>(
      'TfLiteInterpreterGetOutputTensorCount');
  late final _TfLiteInterpreterGetOutputTensorCount =
      _TfLiteInterpreterGetOutputTensorCountPtr.asFunction<
          int Function(ffi.Pointer<TfLiteInterpreter>)>();

  /// Returns a pointer to an array of output tensor indices.  The length of the
  /// array can be obtained via a call to `TfLiteInterpreterGetOutputTensorCount`.
  ///
  /// Typically the output tensors associated with an `interpreter` would be set
  /// during the initialization of the `interpreter`, through a mechanism like the
  /// `InterpreterBuilder`, and remain unchanged throughout the lifetime of the
  /// interpreter.  However, there are some circumstances in which the pointer may
  /// not remain valid throughout the lifetime of the interpreter, because calls to
  /// `SetOutputs` on the interpreter invalidate the returned pointer.
  ///
  /// The ownership of the array remains with the TFLite runtime.
  ffi.Pointer<ffi.Int> TfLiteInterpreterOutputTensorIndices(
    ffi.Pointer<TfLiteInterpreter> interpreter,
  ) {
    return _TfLiteInterpreterOutputTensorIndices(
      interpreter,
    );
  }

  late final _TfLiteInterpreterOutputTensorIndicesPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<ffi.Int> Function(ffi.Pointer<TfLiteInterpreter>)>>(
      'TfLiteInterpreterOutputTensorIndices');
  late final _TfLiteInterpreterOutputTensorIndices =
      _TfLiteInterpreterOutputTensorIndicesPtr.asFunction<
          ffi.Pointer<ffi.Int> Function(ffi.Pointer<TfLiteInterpreter>)>();

  /// Returns the tensor associated with the output index.
  /// REQUIRES: 0 <= output_index < TfLiteInterpreterGetOutputTensorCount(tensor)
  ///
  /// NOTE: The shape and underlying data buffer for output tensors may be not
  /// be available until after the output tensor has been both sized and allocated.
  /// In general, best practice is to interact with the output tensor *after*
  /// calling TfLiteInterpreterInvoke().
  ffi.Pointer<TfLiteTensor> TfLiteInterpreterGetOutputTensor(
    ffi.Pointer<TfLiteInterpreter> interpreter,
    int output_index,
  ) {
    return _TfLiteInterpreterGetOutputTensor(
      interpreter,
      output_index,
    );
  }

  late final _TfLiteInterpreterGetOutputTensorPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<TfLiteTensor> Function(ffi.Pointer<TfLiteInterpreter>,
              ffi.Int32)>>('TfLiteInterpreterGetOutputTensor');
  late final _TfLiteInterpreterGetOutputTensor =
      _TfLiteInterpreterGetOutputTensorPtr.asFunction<
          ffi.Pointer<TfLiteTensor> Function(
              ffi.Pointer<TfLiteInterpreter>, int)>();

  /// Returns modifiable access to the tensor that corresponds to the
  /// specified `index` and is associated with the provided `interpreter`.
  ///
  /// This requires the `index` to be between 0 and N - 1, where N is the
  /// number of tensors in the model.
  ///
  /// Typically the tensors associated with the `interpreter` would be set during
  /// the `interpreter` initialization, through a mechanism like the
  /// `InterpreterBuilder`, and remain unchanged throughout the lifetime of the
  /// interpreter.  However, there are some circumstances in which the pointer may
  /// not remain valid throughout the lifetime of the interpreter, because calls to
  /// `AddTensors` on the interpreter invalidate the returned pointer.
  ///
  /// Note the difference between this function and
  /// `TfLiteInterpreterGetInputTensor` (or `TfLiteInterpreterGetOutputTensor` for
  /// that matter): `TfLiteInterpreterGetTensor` takes an index into the array of
  /// all tensors associated with the `interpreter`'s model, whereas
  /// `TfLiteInterpreterGetInputTensor` takes an index into the array of input
  /// tensors.
  ///
  /// The ownership of the tensor remains with the TFLite runtime, meaning the
  /// caller should not deallocate the pointer.
  ffi.Pointer<TfLiteTensor> TfLiteInterpreterGetTensor(
    ffi.Pointer<TfLiteInterpreter> interpreter,
    int index,
  ) {
    return _TfLiteInterpreterGetTensor(
      interpreter,
      index,
    );
  }

  late final _TfLiteInterpreterGetTensorPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<TfLiteTensor> Function(ffi.Pointer<TfLiteInterpreter>,
              ffi.Int)>>('TfLiteInterpreterGetTensor');
  late final _TfLiteInterpreterGetTensor =
      _TfLiteInterpreterGetTensorPtr.asFunction<
          ffi.Pointer<TfLiteTensor> Function(
              ffi.Pointer<TfLiteInterpreter>, int)>();

  /// Tries to cancel any in-flight invocation.
  ///
  /// NOTE: This only cancels `TfLiteInterpreterInvoke` calls that happen before
  /// calling this and it does not cancel subsequent invocations.
  /// NOTE: Calling this function will also cancel any in-flight invocations of
  /// SignatureRunners constructed from this interpreter.
  /// Non-blocking and thread safe.
  ///
  /// Returns kTfLiteError if cancellation is not enabled via
  /// `TfLiteInterpreterOptionsEnableCancellation`.
  ///
  /// WARNING: This is an experimental API and subject to change.
  int TfLiteInterpreterCancel(
    ffi.Pointer<TfLiteInterpreter> interpreter,
  ) {
    return _TfLiteInterpreterCancel(
      interpreter,
    );
  }

  late final _TfLiteInterpreterCancelPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<TfLiteInterpreter>)>>('TfLiteInterpreterCancel');
  late final _TfLiteInterpreterCancel = _TfLiteInterpreterCancelPtr.asFunction<
      int Function(ffi.Pointer<TfLiteInterpreter>)>();

  /// Returns the type of a tensor element.
  int TfLiteTensorType(
    ffi.Pointer<TfLiteTensor> tensor,
  ) {
    return _TfLiteTensorType(
      tensor,
    );
  }

  late final _TfLiteTensorTypePtr = _lookup<
          ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<TfLiteTensor>)>>(
      'TfLiteTensorType');
  late final _TfLiteTensorType = _TfLiteTensorTypePtr.asFunction<
      int Function(ffi.Pointer<TfLiteTensor>)>();

  /// Returns the number of dimensions that the tensor has.  Returns -1 in case
  /// the 'opaque_tensor' does not have its dimensions property set.
  int TfLiteTensorNumDims(
    ffi.Pointer<TfLiteTensor> tensor,
  ) {
    return _TfLiteTensorNumDims(
      tensor,
    );
  }

  late final _TfLiteTensorNumDimsPtr = _lookup<
          ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<TfLiteTensor>)>>(
      'TfLiteTensorNumDims');
  late final _TfLiteTensorNumDims = _TfLiteTensorNumDimsPtr.asFunction<
      int Function(ffi.Pointer<TfLiteTensor>)>();

  /// Returns the length of the tensor in the "dim_index" dimension.
  /// REQUIRES: 0 <= dim_index < TFLiteTensorNumDims(tensor)
  int TfLiteTensorDim(
    ffi.Pointer<TfLiteTensor> tensor,
    int dim_index,
  ) {
    return _TfLiteTensorDim(
      tensor,
      dim_index,
    );
  }

  late final _TfLiteTensorDimPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<TfLiteTensor>, ffi.Int32)>>('TfLiteTensorDim');
  late final _TfLiteTensorDim = _TfLiteTensorDimPtr.asFunction<
      int Function(ffi.Pointer<TfLiteTensor>, int)>();

  /// Returns the size of the underlying data in bytes.
  int TfLiteTensorByteSize(
    ffi.Pointer<TfLiteTensor> tensor,
  ) {
    return _TfLiteTensorByteSize(
      tensor,
    );
  }

  late final _TfLiteTensorByteSizePtr =
      _lookup<ffi.NativeFunction<ffi.Size Function(ffi.Pointer<TfLiteTensor>)>>(
          'TfLiteTensorByteSize');
  late final _TfLiteTensorByteSize = _TfLiteTensorByteSizePtr.asFunction<
      int Function(ffi.Pointer<TfLiteTensor>)>();

  /// Returns a pointer to the underlying data buffer.
  ///
  /// NOTE: The result may be null if tensors have not yet been allocated, e.g.,
  /// if the Tensor has just been created or resized and `TfLiteAllocateTensors()`
  /// has yet to be called, or if the output tensor is dynamically sized and the
  /// interpreter hasn't been invoked.
  ffi.Pointer<ffi.Void> TfLiteTensorData(
    ffi.Pointer<TfLiteTensor> tensor,
  ) {
    return _TfLiteTensorData(
      tensor,
    );
  }

  late final _TfLiteTensorDataPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Void> Function(
              ffi.Pointer<TfLiteTensor>)>>('TfLiteTensorData');
  late final _TfLiteTensorData = _TfLiteTensorDataPtr.asFunction<
      ffi.Pointer<ffi.Void> Function(ffi.Pointer<TfLiteTensor>)>();

  /// Returns the (null-terminated) name of the tensor.
  ffi.Pointer<ffi.Char> TfLiteTensorName(
    ffi.Pointer<TfLiteTensor> tensor,
  ) {
    return _TfLiteTensorName(
      tensor,
    );
  }

  late final _TfLiteTensorNamePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Char> Function(
              ffi.Pointer<TfLiteTensor>)>>('TfLiteTensorName');
  late final _TfLiteTensorName = _TfLiteTensorNamePtr.asFunction<
      ffi.Pointer<ffi.Char> Function(ffi.Pointer<TfLiteTensor>)>();

  /// Returns the parameters for asymmetric quantization. The quantization
  /// parameters are only valid when the tensor type is `kTfLiteUInt8` and the
  /// `scale != 0`. Quantized values can be converted back to float using:
  /// real_value = scale * (quantized_value - zero_point);
  TfLiteQuantizationParams TfLiteTensorQuantizationParams(
    ffi.Pointer<TfLiteTensor> tensor,
  ) {
    return _TfLiteTensorQuantizationParams(
      tensor,
    );
  }

  late final _TfLiteTensorQuantizationParamsPtr = _lookup<
      ffi.NativeFunction<
          TfLiteQuantizationParams Function(
              ffi.Pointer<TfLiteTensor>)>>('TfLiteTensorQuantizationParams');
  late final _TfLiteTensorQuantizationParams =
      _TfLiteTensorQuantizationParamsPtr.asFunction<
          TfLiteQuantizationParams Function(ffi.Pointer<TfLiteTensor>)>();

  /// Copies from the provided input buffer into the tensor's buffer.
  /// REQUIRES: input_data_size == TfLiteTensorByteSize(tensor)
  int TfLiteTensorCopyFromBuffer(
    ffi.Pointer<TfLiteTensor> tensor,
    ffi.Pointer<ffi.Void> input_data,
    int input_data_size,
  ) {
    return _TfLiteTensorCopyFromBuffer(
      tensor,
      input_data,
      input_data_size,
    );
  }

  late final _TfLiteTensorCopyFromBufferPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<TfLiteTensor>, ffi.Pointer<ffi.Void>,
              ffi.Size)>>('TfLiteTensorCopyFromBuffer');
  late final _TfLiteTensorCopyFromBuffer =
      _TfLiteTensorCopyFromBufferPtr.asFunction<
          int Function(
              ffi.Pointer<TfLiteTensor>, ffi.Pointer<ffi.Void>, int)>();

  /// Copies to the provided output buffer from the tensor's buffer.
  /// REQUIRES: output_data_size == TfLiteTensorByteSize(tensor)
  int TfLiteTensorCopyToBuffer(
    ffi.Pointer<TfLiteTensor> output_tensor,
    ffi.Pointer<ffi.Void> output_data,
    int output_data_size,
  ) {
    return _TfLiteTensorCopyToBuffer(
      output_tensor,
      output_data,
      output_data_size,
    );
  }

  late final _TfLiteTensorCopyToBufferPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<TfLiteTensor>, ffi.Pointer<ffi.Void>,
              ffi.Size)>>('TfLiteTensorCopyToBuffer');
  late final _TfLiteTensorCopyToBuffer =
      _TfLiteTensorCopyToBufferPtr.asFunction<
          int Function(
              ffi.Pointer<TfLiteTensor>, ffi.Pointer<ffi.Void>, int)>();

  /// Returns a new TfLiteRegistrationExternal instance.
  ///
  /// NOTE: The caller retains ownership and should ensure that
  /// the lifetime of the `TfLiteRegistrationExternal` must be at least as long as
  /// the lifetime of the `TfLiteInterpreter`.
  /// WARNING: This is an experimental API and subject to change.
  ffi.Pointer<TfLiteRegistrationExternal> TfLiteRegistrationExternalCreate(
    int builtin_code,
    ffi.Pointer<ffi.Char> custom_name,
    int version,
  ) {
    return _TfLiteRegistrationExternalCreate(
      builtin_code,
      custom_name,
      version,
    );
  }

  late final _TfLiteRegistrationExternalCreatePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<TfLiteRegistrationExternal> Function(
              ffi.Int32,
              ffi.Pointer<ffi.Char>,
              ffi.Int)>>('TfLiteRegistrationExternalCreate');
  late final _TfLiteRegistrationExternalCreate =
      _TfLiteRegistrationExternalCreatePtr.asFunction<
          ffi.Pointer<TfLiteRegistrationExternal> Function(
              int, ffi.Pointer<ffi.Char>, int)>();

  /// Return the builtin op code of the provided external 'registration'.
  ///
  /// WARNING: This is an experimental API and subject to change.
  int TfLiteRegistrationExternalGetBuiltInCode(
    ffi.Pointer<TfLiteRegistrationExternal> registration,
  ) {
    return _TfLiteRegistrationExternalGetBuiltInCode(
      registration,
    );
  }

  late final _TfLiteRegistrationExternalGetBuiltInCodePtr = _lookup<
          ffi.NativeFunction<
              ffi.Int32 Function(ffi.Pointer<TfLiteRegistrationExternal>)>>(
      'TfLiteRegistrationExternalGetBuiltInCode');
  late final _TfLiteRegistrationExternalGetBuiltInCode =
      _TfLiteRegistrationExternalGetBuiltInCodePtr.asFunction<
          int Function(ffi.Pointer<TfLiteRegistrationExternal>)>();

  /// Returns the custom name of the provided 'registration'.  The returned pointer
  /// will be non-null iff the op is a custom op.
  ///
  /// WARNING: This is an experimental API and subject to change.
  ffi.Pointer<ffi.Char> TfLiteRegistrationExternalGetCustomName(
    ffi.Pointer<TfLiteRegistrationExternal> registration,
  ) {
    return _TfLiteRegistrationExternalGetCustomName(
      registration,
    );
  }

  late final _TfLiteRegistrationExternalGetCustomNamePtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<ffi.Char> Function(
                  ffi.Pointer<TfLiteRegistrationExternal>)>>(
      'TfLiteRegistrationExternalGetCustomName');
  late final _TfLiteRegistrationExternalGetCustomName =
      _TfLiteRegistrationExternalGetCustomNamePtr.asFunction<
          ffi.Pointer<ffi.Char> Function(
              ffi.Pointer<TfLiteRegistrationExternal>)>();

  /// Destroys the TfLiteRegistrationExternal instance.
  /// WARNING: This is an experimental API and subject to change.
  void TfLiteRegistrationExternalDelete(
    ffi.Pointer<TfLiteRegistrationExternal> registration,
  ) {
    return _TfLiteRegistrationExternalDelete(
      registration,
    );
  }

  late final _TfLiteRegistrationExternalDeletePtr = _lookup<
          ffi.NativeFunction<
              ffi.Void Function(ffi.Pointer<TfLiteRegistrationExternal>)>>(
      'TfLiteRegistrationExternalDelete');
  late final _TfLiteRegistrationExternalDelete =
      _TfLiteRegistrationExternalDeletePtr.asFunction<
          void Function(ffi.Pointer<TfLiteRegistrationExternal>)>();

  /// Sets the initialization callback for the registration.
  ///
  /// The callback is called to initialize the op from serialized data.
  /// Please refer `init` of `TfLiteRegistration` for the detail.
  /// WARNING: This is an experimental API and subject to change.
  void TfLiteRegistrationExternalSetInit(
    ffi.Pointer<TfLiteRegistrationExternal> registration,
    ffi.Pointer<
            ffi.NativeFunction<
                ffi.Pointer<ffi.Void> Function(ffi.Pointer<TfLiteOpaqueContext>,
                    ffi.Pointer<ffi.Char>, ffi.Size)>>
        init,
  ) {
    return _TfLiteRegistrationExternalSetInit(
      registration,
      init,
    );
  }

  late final _TfLiteRegistrationExternalSetInitPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<TfLiteRegistrationExternal>,
              ffi.Pointer<
                  ffi.NativeFunction<
                      ffi.Pointer<ffi.Void> Function(
                          ffi.Pointer<TfLiteOpaqueContext>,
                          ffi.Pointer<ffi.Char>,
                          ffi.Size)>>)>>('TfLiteRegistrationExternalSetInit');
  late final _TfLiteRegistrationExternalSetInit =
      _TfLiteRegistrationExternalSetInitPtr.asFunction<
          void Function(
              ffi.Pointer<TfLiteRegistrationExternal>,
              ffi.Pointer<
                  ffi.NativeFunction<
                      ffi.Pointer<ffi.Void> Function(
                          ffi.Pointer<TfLiteOpaqueContext>,
                          ffi.Pointer<ffi.Char>,
                          ffi.Size)>>)>();

  /// Sets the deallocation callback for the registration.
  ///
  /// This callback is called to deallocate the data returned by the init callback.
  /// The value passed in the `data` parameter is the value that was returned by
  /// the `init` callback.
  /// Please refer `free` of `TfLiteRegistration` for the detail.
  /// WARNING: This is an experimental API and subject to change.
  void TfLiteRegistrationExternalSetFree(
    ffi.Pointer<TfLiteRegistrationExternal> registration,
    ffi.Pointer<
            ffi.NativeFunction<
                ffi.Void Function(
                    ffi.Pointer<TfLiteOpaqueContext>, ffi.Pointer<ffi.Void>)>>
        free,
  ) {
    return _TfLiteRegistrationExternalSetFree(
      registration,
      free,
    );
  }

  late final _TfLiteRegistrationExternalSetFreePtr = _lookup<
          ffi.NativeFunction<
              ffi.Void Function(
                  ffi.Pointer<TfLiteRegistrationExternal>,
                  ffi.Pointer<
                      ffi.NativeFunction<
                          ffi.Void Function(ffi.Pointer<TfLiteOpaqueContext>,
                              ffi.Pointer<ffi.Void>)>>)>>(
      'TfLiteRegistrationExternalSetFree');
  late final _TfLiteRegistrationExternalSetFree =
      _TfLiteRegistrationExternalSetFreePtr.asFunction<
          void Function(
              ffi.Pointer<TfLiteRegistrationExternal>,
              ffi.Pointer<
                  ffi.NativeFunction<
                      ffi.Void Function(ffi.Pointer<TfLiteOpaqueContext>,
                          ffi.Pointer<ffi.Void>)>>)>();

  /// Sets the preparation callback for the registration.
  ///
  /// The callback is called when the inputs of operator have been resized.
  /// Please refer `prepare` of `TfLiteRegistration` for the detail.
  /// WARNING: This is an experimental API and subject to change.
  void TfLiteRegistrationExternalSetPrepare(
    ffi.Pointer<TfLiteRegistrationExternal> registration,
    ffi.Pointer<
            ffi.NativeFunction<
                ffi.Int32 Function(ffi.Pointer<TfLiteOpaqueContext>,
                    ffi.Pointer<TfLiteOpaqueNode>)>>
        prepare,
  ) {
    return _TfLiteRegistrationExternalSetPrepare(
      registration,
      prepare,
    );
  }

  late final _TfLiteRegistrationExternalSetPreparePtr = _lookup<
          ffi.NativeFunction<
              ffi.Void Function(
                  ffi.Pointer<TfLiteRegistrationExternal>,
                  ffi.Pointer<
                      ffi.NativeFunction<
                          ffi.Int32 Function(ffi.Pointer<TfLiteOpaqueContext>,
                              ffi.Pointer<TfLiteOpaqueNode>)>>)>>(
      'TfLiteRegistrationExternalSetPrepare');
  late final _TfLiteRegistrationExternalSetPrepare =
      _TfLiteRegistrationExternalSetPreparePtr.asFunction<
          void Function(
              ffi.Pointer<TfLiteRegistrationExternal>,
              ffi.Pointer<
                  ffi.NativeFunction<
                      ffi.Int32 Function(ffi.Pointer<TfLiteOpaqueContext>,
                          ffi.Pointer<TfLiteOpaqueNode>)>>)>();

  /// Sets the invocation callback for the registration.
  ///
  /// The callback is called when the operator is executed.
  /// Please refer `invoke` of `TfLiteRegistration` for the detail.
  /// WARNING: This is an experimental API and subject to change.
  void TfLiteRegistrationExternalSetInvoke(
    ffi.Pointer<TfLiteRegistrationExternal> registration,
    ffi.Pointer<
            ffi.NativeFunction<
                ffi.Int32 Function(ffi.Pointer<TfLiteOpaqueContext>,
                    ffi.Pointer<TfLiteOpaqueNode>)>>
        invoke,
  ) {
    return _TfLiteRegistrationExternalSetInvoke(
      registration,
      invoke,
    );
  }

  late final _TfLiteRegistrationExternalSetInvokePtr = _lookup<
          ffi.NativeFunction<
              ffi.Void Function(
                  ffi.Pointer<TfLiteRegistrationExternal>,
                  ffi.Pointer<
                      ffi.NativeFunction<
                          ffi.Int32 Function(ffi.Pointer<TfLiteOpaqueContext>,
                              ffi.Pointer<TfLiteOpaqueNode>)>>)>>(
      'TfLiteRegistrationExternalSetInvoke');
  late final _TfLiteRegistrationExternalSetInvoke =
      _TfLiteRegistrationExternalSetInvokePtr.asFunction<
          void Function(
              ffi.Pointer<TfLiteRegistrationExternal>,
              ffi.Pointer<
                  ffi.NativeFunction<
                      ffi.Int32 Function(ffi.Pointer<TfLiteOpaqueContext>,
                          ffi.Pointer<TfLiteOpaqueNode>)>>)>();

  /// Given the size (number of elements) in a TfLiteIntArray, calculate its size
  /// in bytes.
  int TfLiteIntArrayGetSizeInBytes(
    int size,
  ) {
    return _TfLiteIntArrayGetSizeInBytes(
      size,
    );
  }

  late final _TfLiteIntArrayGetSizeInBytesPtr =
      _lookup<ffi.NativeFunction<ffi.Size Function(ffi.Int)>>(
          'TfLiteIntArrayGetSizeInBytes');
  late final _TfLiteIntArrayGetSizeInBytes =
      _TfLiteIntArrayGetSizeInBytesPtr.asFunction<int Function(int)>();

  /// Create a array of a given `size` (uninitialized entries).
  /// This returns a pointer, that you must free using TfLiteIntArrayFree().
  ffi.Pointer<TfLiteIntArray> TfLiteIntArrayCreate(
    int size,
  ) {
    return _TfLiteIntArrayCreate(
      size,
    );
  }

  late final _TfLiteIntArrayCreatePtr = _lookup<
          ffi.NativeFunction<ffi.Pointer<TfLiteIntArray> Function(ffi.Int)>>(
      'TfLiteIntArrayCreate');
  late final _TfLiteIntArrayCreate = _TfLiteIntArrayCreatePtr.asFunction<
      ffi.Pointer<TfLiteIntArray> Function(int)>();

  /// Check if two intarrays are equal. Returns 1 if they are equal, 0 otherwise.
  int TfLiteIntArrayEqual(
    ffi.Pointer<TfLiteIntArray> a,
    ffi.Pointer<TfLiteIntArray> b,
  ) {
    return _TfLiteIntArrayEqual(
      a,
      b,
    );
  }

  late final _TfLiteIntArrayEqualPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<TfLiteIntArray>,
              ffi.Pointer<TfLiteIntArray>)>>('TfLiteIntArrayEqual');
  late final _TfLiteIntArrayEqual = _TfLiteIntArrayEqualPtr.asFunction<
      int Function(ffi.Pointer<TfLiteIntArray>, ffi.Pointer<TfLiteIntArray>)>();

  /// Check if an intarray equals an array. Returns 1 if equals, 0 otherwise.
  int TfLiteIntArrayEqualsArray(
    ffi.Pointer<TfLiteIntArray> a,
    int b_size,
    ffi.Pointer<ffi.Int> b_data,
  ) {
    return _TfLiteIntArrayEqualsArray(
      a,
      b_size,
      b_data,
    );
  }

  late final _TfLiteIntArrayEqualsArrayPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<TfLiteIntArray>, ffi.Int,
              ffi.Pointer<ffi.Int>)>>('TfLiteIntArrayEqualsArray');
  late final _TfLiteIntArrayEqualsArray =
      _TfLiteIntArrayEqualsArrayPtr.asFunction<
          int Function(
              ffi.Pointer<TfLiteIntArray>, int, ffi.Pointer<ffi.Int>)>();

  /// Create a copy of an array passed as `src`.
  /// You are expected to free memory with TfLiteIntArrayFree
  ffi.Pointer<TfLiteIntArray> TfLiteIntArrayCopy(
    ffi.Pointer<TfLiteIntArray> src,
  ) {
    return _TfLiteIntArrayCopy(
      src,
    );
  }

  late final _TfLiteIntArrayCopyPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<TfLiteIntArray> Function(
              ffi.Pointer<TfLiteIntArray>)>>('TfLiteIntArrayCopy');
  late final _TfLiteIntArrayCopy = _TfLiteIntArrayCopyPtr.asFunction<
      ffi.Pointer<TfLiteIntArray> Function(ffi.Pointer<TfLiteIntArray>)>();

  /// Free memory of array `a`.
  void TfLiteIntArrayFree(
    ffi.Pointer<TfLiteIntArray> a,
  ) {
    return _TfLiteIntArrayFree(
      a,
    );
  }

  late final _TfLiteIntArrayFreePtr = _lookup<
          ffi.NativeFunction<ffi.Void Function(ffi.Pointer<TfLiteIntArray>)>>(
      'TfLiteIntArrayFree');
  late final _TfLiteIntArrayFree = _TfLiteIntArrayFreePtr.asFunction<
      void Function(ffi.Pointer<TfLiteIntArray>)>();

  /// Given the size (number of elements) in a TfLiteFloatArray, calculate its size
  /// in bytes.
  int TfLiteFloatArrayGetSizeInBytes(
    int size,
  ) {
    return _TfLiteFloatArrayGetSizeInBytes(
      size,
    );
  }

  late final _TfLiteFloatArrayGetSizeInBytesPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Int)>>(
          'TfLiteFloatArrayGetSizeInBytes');
  late final _TfLiteFloatArrayGetSizeInBytes =
      _TfLiteFloatArrayGetSizeInBytesPtr.asFunction<int Function(int)>();

  /// Create a array of a given `size` (uninitialized entries).
  /// This returns a pointer, that you must free using TfLiteFloatArrayFree().
  ffi.Pointer<TfLiteFloatArray> TfLiteFloatArrayCreate(
    int size,
  ) {
    return _TfLiteFloatArrayCreate(
      size,
    );
  }

  late final _TfLiteFloatArrayCreatePtr = _lookup<
          ffi.NativeFunction<ffi.Pointer<TfLiteFloatArray> Function(ffi.Int)>>(
      'TfLiteFloatArrayCreate');
  late final _TfLiteFloatArrayCreate = _TfLiteFloatArrayCreatePtr.asFunction<
      ffi.Pointer<TfLiteFloatArray> Function(int)>();

  /// Free memory of array `a`.
  void TfLiteFloatArrayFree(
    ffi.Pointer<TfLiteFloatArray> a,
  ) {
    return _TfLiteFloatArrayFree(
      a,
    );
  }

  late final _TfLiteFloatArrayFreePtr = _lookup<
          ffi.NativeFunction<ffi.Void Function(ffi.Pointer<TfLiteFloatArray>)>>(
      'TfLiteFloatArrayFree');
  late final _TfLiteFloatArrayFree = _TfLiteFloatArrayFreePtr.asFunction<
      void Function(ffi.Pointer<TfLiteFloatArray>)>();

  /// Return the name of a given type, for error reporting purposes.
  ffi.Pointer<ffi.Char> TfLiteTypeGetName(
    int type,
  ) {
    return _TfLiteTypeGetName(
      type,
    );
  }

  late final _TfLiteTypeGetNamePtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Char> Function(ffi.Int32)>>(
          'TfLiteTypeGetName');
  late final _TfLiteTypeGetName =
      _TfLiteTypeGetNamePtr.asFunction<ffi.Pointer<ffi.Char> Function(int)>();

  /// Free data memory of tensor `t`.
  void TfLiteTensorDataFree(
    ffi.Pointer<TfLiteTensor> t,
  ) {
    return _TfLiteTensorDataFree(
      t,
    );
  }

  late final _TfLiteTensorDataFreePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<TfLiteTensor>)>>(
          'TfLiteTensorDataFree');
  late final _TfLiteTensorDataFree = _TfLiteTensorDataFreePtr.asFunction<
      void Function(ffi.Pointer<TfLiteTensor>)>();

  /// Free quantization data.
  void TfLiteQuantizationFree(
    ffi.Pointer<TfLiteQuantization> quantization,
  ) {
    return _TfLiteQuantizationFree(
      quantization,
    );
  }

  late final _TfLiteQuantizationFreePtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<TfLiteQuantization>)>>('TfLiteQuantizationFree');
  late final _TfLiteQuantizationFree = _TfLiteQuantizationFreePtr.asFunction<
      void Function(ffi.Pointer<TfLiteQuantization>)>();

  /// Free sparsity parameters.
  void TfLiteSparsityFree(
    ffi.Pointer<TfLiteSparsity> sparsity,
  ) {
    return _TfLiteSparsityFree(
      sparsity,
    );
  }

  late final _TfLiteSparsityFreePtr = _lookup<
          ffi.NativeFunction<ffi.Void Function(ffi.Pointer<TfLiteSparsity>)>>(
      'TfLiteSparsityFree');
  late final _TfLiteSparsityFree = _TfLiteSparsityFreePtr.asFunction<
      void Function(ffi.Pointer<TfLiteSparsity>)>();

  /// Free memory of tensor `t`.
  void TfLiteTensorFree(
    ffi.Pointer<TfLiteTensor> t,
  ) {
    return _TfLiteTensorFree(
      t,
    );
  }

  late final _TfLiteTensorFreePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<TfLiteTensor>)>>(
          'TfLiteTensorFree');
  late final _TfLiteTensorFree = _TfLiteTensorFreePtr.asFunction<
      void Function(ffi.Pointer<TfLiteTensor>)>();

  /// Set all of a tensor's fields (and free any previously allocated data).
  void TfLiteTensorReset(
    int type,
    ffi.Pointer<ffi.Char> name,
    ffi.Pointer<TfLiteIntArray> dims,
    TfLiteQuantizationParams quantization,
    ffi.Pointer<ffi.Char> buffer,
    int size,
    int allocation_type,
    ffi.Pointer<ffi.Void> allocation,
    bool is_variable,
    ffi.Pointer<TfLiteTensor> tensor,
  ) {
    return _TfLiteTensorReset(
      type,
      name,
      dims,
      quantization,
      buffer,
      size,
      allocation_type,
      allocation,
      is_variable,
      tensor,
    );
  }

  late final _TfLiteTensorResetPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Int32,
              ffi.Pointer<ffi.Char>,
              ffi.Pointer<TfLiteIntArray>,
              TfLiteQuantizationParams,
              ffi.Pointer<ffi.Char>,
              ffi.Size,
              ffi.Int32,
              ffi.Pointer<ffi.Void>,
              ffi.Bool,
              ffi.Pointer<TfLiteTensor>)>>('TfLiteTensorReset');
  late final _TfLiteTensorReset = _TfLiteTensorResetPtr.asFunction<
      void Function(
          int,
          ffi.Pointer<ffi.Char>,
          ffi.Pointer<TfLiteIntArray>,
          TfLiteQuantizationParams,
          ffi.Pointer<ffi.Char>,
          int,
          int,
          ffi.Pointer<ffi.Void>,
          bool,
          ffi.Pointer<TfLiteTensor>)>();

  /// Copies the contents of 'src' in 'dst'.
  /// Function does nothing if either 'src' or 'dst' is passed as nullptr and
  /// return kTfLiteOk.
  /// Returns kTfLiteError if 'src' and 'dst' doesn't have matching data size.
  /// Note function copies contents, so it won't create new data pointer
  /// or change allocation type.
  /// All Tensor related properties will be copied from 'src' to 'dst' like
  /// quantization, sparsity, ...
  int TfLiteTensorCopy(
    ffi.Pointer<TfLiteTensor> src,
    ffi.Pointer<TfLiteTensor> dst,
  ) {
    return _TfLiteTensorCopy(
      src,
      dst,
    );
  }

  late final _TfLiteTensorCopyPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<TfLiteTensor>,
              ffi.Pointer<TfLiteTensor>)>>('TfLiteTensorCopy');
  late final _TfLiteTensorCopy = _TfLiteTensorCopyPtr.asFunction<
      int Function(ffi.Pointer<TfLiteTensor>, ffi.Pointer<TfLiteTensor>)>();

  /// Change the size of the memory block owned by `tensor` to `num_bytes`.
  /// Tensors with allocation types other than kTfLiteDynamic will be ignored.
  /// `tensor`'s internal data buffer will be assigned a pointer
  /// which can safely be passed to free or realloc if `num_bytes` is zero.
  /// Behaviour is undefined if `tensor` is NULL.
  /// If `preserve_data` is true, tensor data will be unchanged in the range from
  /// the start of the region up to the minimum of the old and new sizes.
  void TfLiteTensorResizeMaybeCopy(
    int num_bytes,
    ffi.Pointer<TfLiteTensor> tensor,
    bool preserve_data,
  ) {
    return _TfLiteTensorResizeMaybeCopy(
      num_bytes,
      tensor,
      preserve_data,
    );
  }

  late final _TfLiteTensorResizeMaybeCopyPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Size, ffi.Pointer<TfLiteTensor>,
              ffi.Bool)>>('TfLiteTensorResizeMaybeCopy');
  late final _TfLiteTensorResizeMaybeCopy = _TfLiteTensorResizeMaybeCopyPtr
      .asFunction<void Function(int, ffi.Pointer<TfLiteTensor>, bool)>();

  /// Change the size of the memory block owned by `tensor` to `num_bytes`.
  /// Tensors with allocation types other than kTfLiteDynamic will be ignored.
  /// `tensor`'s internal data buffer will be assigned a pointer
  /// which can safely be passed to free or realloc if `num_bytes` is zero.
  /// Behaviour is undefined if `tensor` is NULL.
  /// Tensor data will be unchanged in the range from the start of the region up to
  /// the minimum of the old and new sizes.
  void TfLiteTensorRealloc(
    int num_bytes,
    ffi.Pointer<TfLiteTensor> tensor,
  ) {
    return _TfLiteTensorRealloc(
      num_bytes,
      tensor,
    );
  }

  late final _TfLiteTensorReallocPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Size, ffi.Pointer<TfLiteTensor>)>>('TfLiteTensorRealloc');
  late final _TfLiteTensorRealloc = _TfLiteTensorReallocPtr.asFunction<
      void Function(int, ffi.Pointer<TfLiteTensor>)>();

  /// Build a 'null' delegate, with all the fields properly set to their default
  /// values.
  TfLiteDelegate TfLiteDelegateCreate() {
    return _TfLiteDelegateCreate();
  }

  late final _TfLiteDelegateCreatePtr =
      _lookup<ffi.NativeFunction<TfLiteDelegate Function()>>(
          'TfLiteDelegateCreate');
  late final _TfLiteDelegateCreate =
      _TfLiteDelegateCreatePtr.asFunction<TfLiteDelegate Function()>();

  /// Creates an opaque delegate and returns its address.  The opaque delegate will
  /// behave according to the provided 'opaque_delegate_builder'.  The lifetime of
  /// the objects pointed to by any of the fields within the
  /// 'opaque_delegate_builder' must outlive the returned
  /// 'TfLiteOpaqueDelegate' and any 'TfLiteInterpreter',
  /// 'TfLiteInterpreterOptions', 'tflite::Interpreter', or
  /// 'tflite::InterpreterBuilder' that the delegate is added to.  The returned
  /// address should be passed to 'TfLiteOpaqueDelegateDelete' for deletion.  If
  /// 'opaque_delegate_builder' is a null pointer, then a null pointer will be
  /// returned.
  ffi.Pointer<TfLiteOpaqueDelegate> TfLiteOpaqueDelegateCreate(
    ffi.Pointer<TfLiteOpaqueDelegateBuilder> opaque_delegate_builder,
  ) {
    return _TfLiteOpaqueDelegateCreate(
      opaque_delegate_builder,
    );
  }

  late final _TfLiteOpaqueDelegateCreatePtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<TfLiteOpaqueDelegate> Function(
                  ffi.Pointer<TfLiteOpaqueDelegateBuilder>)>>(
      'TfLiteOpaqueDelegateCreate');
  late final _TfLiteOpaqueDelegateCreate =
      _TfLiteOpaqueDelegateCreatePtr.asFunction<
          ffi.Pointer<TfLiteOpaqueDelegate> Function(
              ffi.Pointer<TfLiteOpaqueDelegateBuilder>)>();

  /// Deletes the provided opaque 'delegate'.  This function has no effect if the
  /// 'delegate' is a null pointer.
  void TfLiteOpaqueDelegateDelete(
    ffi.Pointer<TfLiteOpaqueDelegate> delegate,
  ) {
    return _TfLiteOpaqueDelegateDelete(
      delegate,
    );
  }

  late final _TfLiteOpaqueDelegateDeletePtr = _lookup<
          ffi.NativeFunction<
              ffi.Void Function(ffi.Pointer<TfLiteOpaqueDelegate>)>>(
      'TfLiteOpaqueDelegateDelete');
  late final _TfLiteOpaqueDelegateDelete = _TfLiteOpaqueDelegateDeletePtr
      .asFunction<void Function(ffi.Pointer<TfLiteOpaqueDelegate>)>();

  /// Returns a pointer to the data associated with the provided opaque 'delegate'.
  ///
  /// A null pointer will be returned when:
  /// - The 'delegate' is null.
  /// - The 'data' field of the 'TfLiteOpaqueDelegateBuilder' used to construct the
  /// 'delegate' was null.
  /// - Or in case of any other error.
  /// - The 'delegate' has been constructed via a 'TfLiteOpaqueDelegateBuilder',
  /// but the 'data' field of the 'TfLiteOpaqueDelegateBuilder' is null.
  ffi.Pointer<ffi.Void> TfLiteOpaqueDelegateGetData(
    ffi.Pointer<TfLiteOpaqueDelegate> delegate,
  ) {
    return _TfLiteOpaqueDelegateGetData(
      delegate,
    );
  }

  late final _TfLiteOpaqueDelegateGetDataPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<ffi.Void> Function(
                  ffi.Pointer<TfLiteOpaqueDelegate>)>>(
      'TfLiteOpaqueDelegateGetData');
  late final _TfLiteOpaqueDelegateGetData =
      _TfLiteOpaqueDelegateGetDataPtr.asFunction<
          ffi.Pointer<ffi.Void> Function(ffi.Pointer<TfLiteOpaqueDelegate>)>();
}

/// mbstate_t is an opaque object to keep conversion state, during multibyte
/// stream conversions.  The content must not be referenced by user programs.
class __mbstate_t extends ffi.Union {
  @ffi.Array.multi([128])
  external ffi.Array<ffi.Char> __mbstate8;

  /// for alignment
  @ffi.LongLong()
  external int _mbstateL;
}

class __darwin_pthread_handler_rec extends ffi.Struct {
  /// Routine to call
  external ffi
          .Pointer<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ffi.Void>)>>
      __routine;

  /// Argument to pass
  external ffi.Pointer<ffi.Void> __arg;

  external ffi.Pointer<__darwin_pthread_handler_rec> __next;
}

class _opaque_pthread_attr_t extends ffi.Struct {
  @ffi.Long()
  external int __sig;

  @ffi.Array.multi([56])
  external ffi.Array<ffi.Char> __opaque;
}

class _opaque_pthread_cond_t extends ffi.Struct {
  @ffi.Long()
  external int __sig;

  @ffi.Array.multi([40])
  external ffi.Array<ffi.Char> __opaque;
}

class _opaque_pthread_condattr_t extends ffi.Struct {
  @ffi.Long()
  external int __sig;

  @ffi.Array.multi([8])
  external ffi.Array<ffi.Char> __opaque;
}

class _opaque_pthread_mutex_t extends ffi.Struct {
  @ffi.Long()
  external int __sig;

  @ffi.Array.multi([56])
  external ffi.Array<ffi.Char> __opaque;
}

class _opaque_pthread_mutexattr_t extends ffi.Struct {
  @ffi.Long()
  external int __sig;

  @ffi.Array.multi([8])
  external ffi.Array<ffi.Char> __opaque;
}

class _opaque_pthread_once_t extends ffi.Struct {
  @ffi.Long()
  external int __sig;

  @ffi.Array.multi([8])
  external ffi.Array<ffi.Char> __opaque;
}

class _opaque_pthread_rwlock_t extends ffi.Struct {
  @ffi.Long()
  external int __sig;

  @ffi.Array.multi([192])
  external ffi.Array<ffi.Char> __opaque;
}

class _opaque_pthread_rwlockattr_t extends ffi.Struct {
  @ffi.Long()
  external int __sig;

  @ffi.Array.multi([16])
  external ffi.Array<ffi.Char> __opaque;
}

class _opaque_pthread_t extends ffi.Struct {
  @ffi.Long()
  external int __sig;

  external ffi.Pointer<__darwin_pthread_handler_rec> __cleanup_stack;

  @ffi.Array.multi([8176])
  external ffi.Array<ffi.Char> __opaque;
}

/// [XSI] The type idtype_t shall be defined as an enumeration type whose
/// possible values shall include at least P_ALL, P_PID, and P_PGID.
abstract class idtype_t {
  static const int P_ALL = 0;
  static const int P_PID = 1;
  static const int P_PGID = 2;
}

class __darwin_arm_exception_state extends ffi.Struct {
  /// number of arm exception taken
  @__uint32_t()
  external int __exception;

  /// Fault status
  @__uint32_t()
  external int __fsr;

  /// Virtual Fault Address
  @__uint32_t()
  external int __far;
}

typedef __uint32_t = ffi.UnsignedInt;

class __darwin_arm_exception_state64 extends ffi.Struct {
  /// Virtual Fault Address
  @__uint64_t()
  external int __far;

  /// Exception syndrome
  @__uint32_t()
  external int __esr;

  /// number of arm exception taken
  @__uint32_t()
  external int __exception;
}

typedef __uint64_t = ffi.UnsignedLongLong;

class __darwin_arm_thread_state extends ffi.Struct {
  @ffi.Array.multi([13])
  external ffi.Array<__uint32_t> __r;

  /// Stack pointer r13
  @__uint32_t()
  external int __sp;

  /// Link register r14
  @__uint32_t()
  external int __lr;

  /// Program counter r15
  @__uint32_t()
  external int __pc;

  /// Current program status register
  @__uint32_t()
  external int __cpsr;
}

class __darwin_arm_thread_state64 extends ffi.Struct {
  @ffi.Array.multi([29])
  external ffi.Array<__uint64_t> __x;

  /// Frame pointer x29
  @__uint64_t()
  external int __fp;

  /// Link register x30
  @__uint64_t()
  external int __lr;

  /// Stack pointer x31
  @__uint64_t()
  external int __sp;

  /// Program counter
  @__uint64_t()
  external int __pc;

  /// Current program status register
  @__uint32_t()
  external int __cpsr;

  /// Same size for 32-bit or 64-bit clients
  @__uint32_t()
  external int __pad;
}

class __darwin_arm_vfp_state extends ffi.Struct {
  @ffi.Array.multi([64])
  external ffi.Array<__uint32_t> __r;

  @__uint32_t()
  external int __fpscr;
}

class __darwin_arm_neon_state64 extends ffi.Opaque {}

class __darwin_arm_neon_state extends ffi.Opaque {}

class __arm_pagein_state extends ffi.Struct {
  @ffi.Int()
  external int __pagein_error;
}

class __arm_legacy_debug_state extends ffi.Struct {
  @ffi.Array.multi([16])
  external ffi.Array<__uint32_t> __bvr;

  @ffi.Array.multi([16])
  external ffi.Array<__uint32_t> __bcr;

  @ffi.Array.multi([16])
  external ffi.Array<__uint32_t> __wvr;

  @ffi.Array.multi([16])
  external ffi.Array<__uint32_t> __wcr;
}

class __darwin_arm_debug_state32 extends ffi.Struct {
  @ffi.Array.multi([16])
  external ffi.Array<__uint32_t> __bvr;

  @ffi.Array.multi([16])
  external ffi.Array<__uint32_t> __bcr;

  @ffi.Array.multi([16])
  external ffi.Array<__uint32_t> __wvr;

  @ffi.Array.multi([16])
  external ffi.Array<__uint32_t> __wcr;

  /// Bit 0 is SS (Hardware Single Step)
  @__uint64_t()
  external int __mdscr_el1;
}

class __darwin_arm_debug_state64 extends ffi.Struct {
  @ffi.Array.multi([16])
  external ffi.Array<__uint64_t> __bvr;

  @ffi.Array.multi([16])
  external ffi.Array<__uint64_t> __bcr;

  @ffi.Array.multi([16])
  external ffi.Array<__uint64_t> __wvr;

  @ffi.Array.multi([16])
  external ffi.Array<__uint64_t> __wcr;

  /// Bit 0 is SS (Hardware Single Step)
  @__uint64_t()
  external int __mdscr_el1;
}

class __darwin_arm_cpmu_state64 extends ffi.Struct {
  @ffi.Array.multi([16])
  external ffi.Array<__uint64_t> __ctrs;
}

class __darwin_mcontext32 extends ffi.Struct {
  external __darwin_arm_exception_state __es;

  external __darwin_arm_thread_state __ss;

  external __darwin_arm_vfp_state __fs;
}

class __darwin_mcontext64 extends ffi.Opaque {}

class __darwin_sigaltstack extends ffi.Struct {
  /// signal stack base
  external ffi.Pointer<ffi.Void> ss_sp;

  /// signal stack length
  @__darwin_size_t()
  external int ss_size;

  /// SA_DISABLE and/or SA_ONSTACK
  @ffi.Int()
  external int ss_flags;
}

typedef __darwin_size_t = ffi.UnsignedLong;

class __darwin_ucontext extends ffi.Struct {
  @ffi.Int()
  external int uc_onstack;

  /// signal mask used by this context
  @__darwin_sigset_t()
  external int uc_sigmask;

  /// stack used by this context
  external __darwin_sigaltstack uc_stack;

  /// pointer to resuming context
  external ffi.Pointer<__darwin_ucontext> uc_link;

  /// size of the machine context passed in
  @__darwin_size_t()
  external int uc_mcsize;

  /// pointer to machine specific context
  external ffi.Pointer<__darwin_mcontext64> uc_mcontext;
}

typedef __darwin_sigset_t = __uint32_t;

class sigval extends ffi.Union {
  /// Members as suggested by Annex C of POSIX 1003.1b.
  @ffi.Int()
  external int sival_int;

  external ffi.Pointer<ffi.Void> sival_ptr;
}

class sigevent extends ffi.Struct {
  /// Notification type
  @ffi.Int()
  external int sigev_notify;

  /// Signal number
  @ffi.Int()
  external int sigev_signo;

  /// Signal value
  external sigval sigev_value;

  /// Notification function
  external ffi.Pointer<ffi.NativeFunction<ffi.Void Function(sigval)>>
      sigev_notify_function;

  /// Notification attributes
  external ffi.Pointer<pthread_attr_t> sigev_notify_attributes;
}

typedef pthread_attr_t = __darwin_pthread_attr_t;
typedef __darwin_pthread_attr_t = _opaque_pthread_attr_t;

class __siginfo extends ffi.Struct {
  /// signal number
  @ffi.Int()
  external int si_signo;

  /// errno association
  @ffi.Int()
  external int si_errno;

  /// signal code
  @ffi.Int()
  external int si_code;

  /// sending process
  @pid_t()
  external int si_pid;

  /// sender's ruid
  @uid_t()
  external int si_uid;

  /// exit value
  @ffi.Int()
  external int si_status;

  /// faulting instruction
  external ffi.Pointer<ffi.Void> si_addr;

  /// signal value
  external sigval si_value;

  /// band event for SIGPOLL
  @ffi.Long()
  external int si_band;

  @ffi.Array.multi([7])
  external ffi.Array<ffi.UnsignedLong> __pad;
}

typedef pid_t = __darwin_pid_t;
typedef __darwin_pid_t = __int32_t;
typedef __int32_t = ffi.Int;
typedef uid_t = __darwin_uid_t;
typedef __darwin_uid_t = __uint32_t;

/// union for signal handlers
class __sigaction_u extends ffi.Union {
  external ffi.Pointer<ffi.NativeFunction<ffi.Void Function(ffi.Int)>>
      __sa_handler;

  external ffi.Pointer<
          ffi.NativeFunction<
              ffi.Void Function(
                  ffi.Int, ffi.Pointer<__siginfo>, ffi.Pointer<ffi.Void>)>>
      __sa_sigaction;
}

/// Signal vector template for Kernel user boundary
class __sigaction extends ffi.Struct {
  /// signal handler
  external __sigaction_u __sigaction_u1;

  external ffi.Pointer<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, ffi.Int, ffi.Int,
              ffi.Pointer<siginfo_t>, ffi.Pointer<ffi.Void>)>> sa_tramp;

  /// signal mask to apply
  @sigset_t()
  external int sa_mask;

  /// see signal options below
  @ffi.Int()
  external int sa_flags;
}

typedef siginfo_t = __siginfo;
typedef sigset_t = __darwin_sigset_t;

/// Signal vector "template" used in sigaction call.
class sigaction extends ffi.Struct {
  /// signal handler
  external __sigaction_u __sigaction_u1;

  /// signal mask to apply
  @sigset_t()
  external int sa_mask;

  /// see signal options below
  @ffi.Int()
  external int sa_flags;
}

/// 4.3 compatibility:
/// Signal vector "template" used in sigvec call.
class sigvec extends ffi.Struct {
  /// signal handler
  external ffi.Pointer<ffi.NativeFunction<ffi.Void Function(ffi.Int)>>
      sv_handler;

  /// signal mask to apply
  @ffi.Int()
  external int sv_mask;

  /// see signal options below
  @ffi.Int()
  external int sv_flags;
}

/// Structure used in sigstack call.
class sigstack extends ffi.Struct {
  /// signal stack pointer
  external ffi.Pointer<ffi.Char> ss_sp;

  /// current status
  @ffi.Int()
  external int ss_onstack;
}

class timeval extends ffi.Struct {
  /// seconds
  @__darwin_time_t()
  external int tv_sec;

  /// and microseconds
  @__darwin_suseconds_t()
  external int tv_usec;
}

typedef __darwin_time_t = ffi.Long;
typedef __darwin_suseconds_t = __int32_t;

/// A structure representing an accounting of resource utilization.  The
/// address of an instance of this structure is the second parameter to
/// getrusage().
///
/// Note: All values other than ru_utime and ru_stime are implementaiton
/// defined and subject to change in a future release.  Their use
/// is discouraged for standards compliant programs.
class rusage extends ffi.Struct {
  /// user time used (PL)
  external timeval ru_utime;

  /// system time used (PL)
  external timeval ru_stime;

  /// max resident set size (PL)
  @ffi.Long()
  external int ru_maxrss;

  /// integral shared memory size (NU)
  @ffi.Long()
  external int ru_ixrss;

  /// integral unshared data (NU)
  @ffi.Long()
  external int ru_idrss;

  /// integral unshared stack (NU)
  @ffi.Long()
  external int ru_isrss;

  /// page reclaims (NU)
  @ffi.Long()
  external int ru_minflt;

  /// page faults (NU)
  @ffi.Long()
  external int ru_majflt;

  /// swaps (NU)
  @ffi.Long()
  external int ru_nswap;

  /// block input operations (atomic)
  @ffi.Long()
  external int ru_inblock;

  /// block output operations (atomic)
  @ffi.Long()
  external int ru_oublock;

  /// messages sent (atomic)
  @ffi.Long()
  external int ru_msgsnd;

  /// messages received (atomic)
  @ffi.Long()
  external int ru_msgrcv;

  /// signals received (atomic)
  @ffi.Long()
  external int ru_nsignals;

  /// voluntary context switches (atomic)
  @ffi.Long()
  external int ru_nvcsw;

  /// involuntary "
  @ffi.Long()
  external int ru_nivcsw;
}

class rusage_info_v0 extends ffi.Struct {
  @ffi.Array.multi([16])
  external ffi.Array<ffi.Uint8> ri_uuid;

  @ffi.Uint64()
  external int ri_user_time;

  @ffi.Uint64()
  external int ri_system_time;

  @ffi.Uint64()
  external int ri_pkg_idle_wkups;

  @ffi.Uint64()
  external int ri_interrupt_wkups;

  @ffi.Uint64()
  external int ri_pageins;

  @ffi.Uint64()
  external int ri_wired_size;

  @ffi.Uint64()
  external int ri_resident_size;

  @ffi.Uint64()
  external int ri_phys_footprint;

  @ffi.Uint64()
  external int ri_proc_start_abstime;

  @ffi.Uint64()
  external int ri_proc_exit_abstime;
}

class rusage_info_v1 extends ffi.Struct {
  @ffi.Array.multi([16])
  external ffi.Array<ffi.Uint8> ri_uuid;

  @ffi.Uint64()
  external int ri_user_time;

  @ffi.Uint64()
  external int ri_system_time;

  @ffi.Uint64()
  external int ri_pkg_idle_wkups;

  @ffi.Uint64()
  external int ri_interrupt_wkups;

  @ffi.Uint64()
  external int ri_pageins;

  @ffi.Uint64()
  external int ri_wired_size;

  @ffi.Uint64()
  external int ri_resident_size;

  @ffi.Uint64()
  external int ri_phys_footprint;

  @ffi.Uint64()
  external int ri_proc_start_abstime;

  @ffi.Uint64()
  external int ri_proc_exit_abstime;

  @ffi.Uint64()
  external int ri_child_user_time;

  @ffi.Uint64()
  external int ri_child_system_time;

  @ffi.Uint64()
  external int ri_child_pkg_idle_wkups;

  @ffi.Uint64()
  external int ri_child_interrupt_wkups;

  @ffi.Uint64()
  external int ri_child_pageins;

  @ffi.Uint64()
  external int ri_child_elapsed_abstime;
}

class rusage_info_v2 extends ffi.Struct {
  @ffi.Array.multi([16])
  external ffi.Array<ffi.Uint8> ri_uuid;

  @ffi.Uint64()
  external int ri_user_time;

  @ffi.Uint64()
  external int ri_system_time;

  @ffi.Uint64()
  external int ri_pkg_idle_wkups;

  @ffi.Uint64()
  external int ri_interrupt_wkups;

  @ffi.Uint64()
  external int ri_pageins;

  @ffi.Uint64()
  external int ri_wired_size;

  @ffi.Uint64()
  external int ri_resident_size;

  @ffi.Uint64()
  external int ri_phys_footprint;

  @ffi.Uint64()
  external int ri_proc_start_abstime;

  @ffi.Uint64()
  external int ri_proc_exit_abstime;

  @ffi.Uint64()
  external int ri_child_user_time;

  @ffi.Uint64()
  external int ri_child_system_time;

  @ffi.Uint64()
  external int ri_child_pkg_idle_wkups;

  @ffi.Uint64()
  external int ri_child_interrupt_wkups;

  @ffi.Uint64()
  external int ri_child_pageins;

  @ffi.Uint64()
  external int ri_child_elapsed_abstime;

  @ffi.Uint64()
  external int ri_diskio_bytesread;

  @ffi.Uint64()
  external int ri_diskio_byteswritten;
}

class rusage_info_v3 extends ffi.Struct {
  @ffi.Array.multi([16])
  external ffi.Array<ffi.Uint8> ri_uuid;

  @ffi.Uint64()
  external int ri_user_time;

  @ffi.Uint64()
  external int ri_system_time;

  @ffi.Uint64()
  external int ri_pkg_idle_wkups;

  @ffi.Uint64()
  external int ri_interrupt_wkups;

  @ffi.Uint64()
  external int ri_pageins;

  @ffi.Uint64()
  external int ri_wired_size;

  @ffi.Uint64()
  external int ri_resident_size;

  @ffi.Uint64()
  external int ri_phys_footprint;

  @ffi.Uint64()
  external int ri_proc_start_abstime;

  @ffi.Uint64()
  external int ri_proc_exit_abstime;

  @ffi.Uint64()
  external int ri_child_user_time;

  @ffi.Uint64()
  external int ri_child_system_time;

  @ffi.Uint64()
  external int ri_child_pkg_idle_wkups;

  @ffi.Uint64()
  external int ri_child_interrupt_wkups;

  @ffi.Uint64()
  external int ri_child_pageins;

  @ffi.Uint64()
  external int ri_child_elapsed_abstime;

  @ffi.Uint64()
  external int ri_diskio_bytesread;

  @ffi.Uint64()
  external int ri_diskio_byteswritten;

  @ffi.Uint64()
  external int ri_cpu_time_qos_default;

  @ffi.Uint64()
  external int ri_cpu_time_qos_maintenance;

  @ffi.Uint64()
  external int ri_cpu_time_qos_background;

  @ffi.Uint64()
  external int ri_cpu_time_qos_utility;

  @ffi.Uint64()
  external int ri_cpu_time_qos_legacy;

  @ffi.Uint64()
  external int ri_cpu_time_qos_user_initiated;

  @ffi.Uint64()
  external int ri_cpu_time_qos_user_interactive;

  @ffi.Uint64()
  external int ri_billed_system_time;

  @ffi.Uint64()
  external int ri_serviced_system_time;
}

class rusage_info_v4 extends ffi.Struct {
  @ffi.Array.multi([16])
  external ffi.Array<ffi.Uint8> ri_uuid;

  @ffi.Uint64()
  external int ri_user_time;

  @ffi.Uint64()
  external int ri_system_time;

  @ffi.Uint64()
  external int ri_pkg_idle_wkups;

  @ffi.Uint64()
  external int ri_interrupt_wkups;

  @ffi.Uint64()
  external int ri_pageins;

  @ffi.Uint64()
  external int ri_wired_size;

  @ffi.Uint64()
  external int ri_resident_size;

  @ffi.Uint64()
  external int ri_phys_footprint;

  @ffi.Uint64()
  external int ri_proc_start_abstime;

  @ffi.Uint64()
  external int ri_proc_exit_abstime;

  @ffi.Uint64()
  external int ri_child_user_time;

  @ffi.Uint64()
  external int ri_child_system_time;

  @ffi.Uint64()
  external int ri_child_pkg_idle_wkups;

  @ffi.Uint64()
  external int ri_child_interrupt_wkups;

  @ffi.Uint64()
  external int ri_child_pageins;

  @ffi.Uint64()
  external int ri_child_elapsed_abstime;

  @ffi.Uint64()
  external int ri_diskio_bytesread;

  @ffi.Uint64()
  external int ri_diskio_byteswritten;

  @ffi.Uint64()
  external int ri_cpu_time_qos_default;

  @ffi.Uint64()
  external int ri_cpu_time_qos_maintenance;

  @ffi.Uint64()
  external int ri_cpu_time_qos_background;

  @ffi.Uint64()
  external int ri_cpu_time_qos_utility;

  @ffi.Uint64()
  external int ri_cpu_time_qos_legacy;

  @ffi.Uint64()
  external int ri_cpu_time_qos_user_initiated;

  @ffi.Uint64()
  external int ri_cpu_time_qos_user_interactive;

  @ffi.Uint64()
  external int ri_billed_system_time;

  @ffi.Uint64()
  external int ri_serviced_system_time;

  @ffi.Uint64()
  external int ri_logical_writes;

  @ffi.Uint64()
  external int ri_lifetime_max_phys_footprint;

  @ffi.Uint64()
  external int ri_instructions;

  @ffi.Uint64()
  external int ri_cycles;

  @ffi.Uint64()
  external int ri_billed_energy;

  @ffi.Uint64()
  external int ri_serviced_energy;

  @ffi.Uint64()
  external int ri_interval_max_phys_footprint;

  @ffi.Uint64()
  external int ri_runnable_time;
}

class rusage_info_v5 extends ffi.Struct {
  @ffi.Array.multi([16])
  external ffi.Array<ffi.Uint8> ri_uuid;

  @ffi.Uint64()
  external int ri_user_time;

  @ffi.Uint64()
  external int ri_system_time;

  @ffi.Uint64()
  external int ri_pkg_idle_wkups;

  @ffi.Uint64()
  external int ri_interrupt_wkups;

  @ffi.Uint64()
  external int ri_pageins;

  @ffi.Uint64()
  external int ri_wired_size;

  @ffi.Uint64()
  external int ri_resident_size;

  @ffi.Uint64()
  external int ri_phys_footprint;

  @ffi.Uint64()
  external int ri_proc_start_abstime;

  @ffi.Uint64()
  external int ri_proc_exit_abstime;

  @ffi.Uint64()
  external int ri_child_user_time;

  @ffi.Uint64()
  external int ri_child_system_time;

  @ffi.Uint64()
  external int ri_child_pkg_idle_wkups;

  @ffi.Uint64()
  external int ri_child_interrupt_wkups;

  @ffi.Uint64()
  external int ri_child_pageins;

  @ffi.Uint64()
  external int ri_child_elapsed_abstime;

  @ffi.Uint64()
  external int ri_diskio_bytesread;

  @ffi.Uint64()
  external int ri_diskio_byteswritten;

  @ffi.Uint64()
  external int ri_cpu_time_qos_default;

  @ffi.Uint64()
  external int ri_cpu_time_qos_maintenance;

  @ffi.Uint64()
  external int ri_cpu_time_qos_background;

  @ffi.Uint64()
  external int ri_cpu_time_qos_utility;

  @ffi.Uint64()
  external int ri_cpu_time_qos_legacy;

  @ffi.Uint64()
  external int ri_cpu_time_qos_user_initiated;

  @ffi.Uint64()
  external int ri_cpu_time_qos_user_interactive;

  @ffi.Uint64()
  external int ri_billed_system_time;

  @ffi.Uint64()
  external int ri_serviced_system_time;

  @ffi.Uint64()
  external int ri_logical_writes;

  @ffi.Uint64()
  external int ri_lifetime_max_phys_footprint;

  @ffi.Uint64()
  external int ri_instructions;

  @ffi.Uint64()
  external int ri_cycles;

  @ffi.Uint64()
  external int ri_billed_energy;

  @ffi.Uint64()
  external int ri_serviced_energy;

  @ffi.Uint64()
  external int ri_interval_max_phys_footprint;

  @ffi.Uint64()
  external int ri_runnable_time;

  @ffi.Uint64()
  external int ri_flags;
}

class rusage_info_v6 extends ffi.Struct {
  @ffi.Array.multi([16])
  external ffi.Array<ffi.Uint8> ri_uuid;

  @ffi.Uint64()
  external int ri_user_time;

  @ffi.Uint64()
  external int ri_system_time;

  @ffi.Uint64()
  external int ri_pkg_idle_wkups;

  @ffi.Uint64()
  external int ri_interrupt_wkups;

  @ffi.Uint64()
  external int ri_pageins;

  @ffi.Uint64()
  external int ri_wired_size;

  @ffi.Uint64()
  external int ri_resident_size;

  @ffi.Uint64()
  external int ri_phys_footprint;

  @ffi.Uint64()
  external int ri_proc_start_abstime;

  @ffi.Uint64()
  external int ri_proc_exit_abstime;

  @ffi.Uint64()
  external int ri_child_user_time;

  @ffi.Uint64()
  external int ri_child_system_time;

  @ffi.Uint64()
  external int ri_child_pkg_idle_wkups;

  @ffi.Uint64()
  external int ri_child_interrupt_wkups;

  @ffi.Uint64()
  external int ri_child_pageins;

  @ffi.Uint64()
  external int ri_child_elapsed_abstime;

  @ffi.Uint64()
  external int ri_diskio_bytesread;

  @ffi.Uint64()
  external int ri_diskio_byteswritten;

  @ffi.Uint64()
  external int ri_cpu_time_qos_default;

  @ffi.Uint64()
  external int ri_cpu_time_qos_maintenance;

  @ffi.Uint64()
  external int ri_cpu_time_qos_background;

  @ffi.Uint64()
  external int ri_cpu_time_qos_utility;

  @ffi.Uint64()
  external int ri_cpu_time_qos_legacy;

  @ffi.Uint64()
  external int ri_cpu_time_qos_user_initiated;

  @ffi.Uint64()
  external int ri_cpu_time_qos_user_interactive;

  @ffi.Uint64()
  external int ri_billed_system_time;

  @ffi.Uint64()
  external int ri_serviced_system_time;

  @ffi.Uint64()
  external int ri_logical_writes;

  @ffi.Uint64()
  external int ri_lifetime_max_phys_footprint;

  @ffi.Uint64()
  external int ri_instructions;

  @ffi.Uint64()
  external int ri_cycles;

  @ffi.Uint64()
  external int ri_billed_energy;

  @ffi.Uint64()
  external int ri_serviced_energy;

  @ffi.Uint64()
  external int ri_interval_max_phys_footprint;

  @ffi.Uint64()
  external int ri_runnable_time;

  @ffi.Uint64()
  external int ri_flags;

  @ffi.Uint64()
  external int ri_user_ptime;

  @ffi.Uint64()
  external int ri_system_ptime;

  @ffi.Uint64()
  external int ri_pinstructions;

  @ffi.Uint64()
  external int ri_pcycles;

  @ffi.Uint64()
  external int ri_energy_nj;

  @ffi.Uint64()
  external int ri_penergy_nj;

  @ffi.Array.multi([14])
  external ffi.Array<ffi.Uint64> ri_reserved;
}

/// A structure representing a resource limit.  The address of an instance
/// of this structure is the second parameter to getrlimit()/setrlimit().
class rlimit extends ffi.Struct {
  /// current (soft) limit
  @rlim_t()
  external int rlim_cur;

  /// maximum value for rlim_cur
  @rlim_t()
  external int rlim_max;
}

/// Resource limit type (low 63 bits, excluding the sign bit)
typedef rlim_t = __uint64_t;

class proc_rlimit_control_wakeupmon extends ffi.Struct {
  @ffi.Uint32()
  external int wm_flags;

  @ffi.Int32()
  external int wm_rate;
}

typedef id_t = __darwin_id_t;
typedef __darwin_id_t = __uint32_t;

/// Functions for byte reversed loads.
@ffi.Packed(1)
class _OSUnalignedU16 extends ffi.Struct {
  @ffi.Uint16()
  external int __val;
}

@ffi.Packed(1)
class _OSUnalignedU32 extends ffi.Struct {
  @ffi.Uint32()
  external int __val;
}

@ffi.Packed(1)
class _OSUnalignedU64 extends ffi.Struct {
  @ffi.Uint64()
  external int __val;
}

/// Deprecated:
/// Structure of the information in the status word returned by wait4.
/// If w_stopval==_WSTOPPED, then the second structure describes
/// the information returned, else the first.
class wait extends ffi.Opaque {}

class div_t extends ffi.Struct {
  /// quotient
  @ffi.Int()
  external int quot;

  /// remainder
  @ffi.Int()
  external int rem;
}

class ldiv_t extends ffi.Struct {
  /// quotient
  @ffi.Long()
  external int quot;

  /// remainder
  @ffi.Long()
  external int rem;
}

class lldiv_t extends ffi.Struct {
  @ffi.LongLong()
  external int quot;

  @ffi.LongLong()
  external int rem;
}

typedef dev_t = __darwin_dev_t;
typedef __darwin_dev_t = __int32_t;
typedef mode_t = __darwin_mode_t;
typedef __darwin_mode_t = __uint16_t;
typedef __uint16_t = ffi.UnsignedShort;

/// The enum for builtin operators.
/// Note: CUSTOM, DELEGATE, and PLACEHOLDER_FOR_GREATER_OP_CODES are 3 special
/// ops which are not real built-in ops.
abstract class TfLiteBuiltinOperator {
  static const int kTfLiteBuiltinAdd = 0;
  static const int kTfLiteBuiltinAveragePool2d = 1;
  static const int kTfLiteBuiltinConcatenation = 2;
  static const int kTfLiteBuiltinConv2d = 3;
  static const int kTfLiteBuiltinDepthwiseConv2d = 4;
  static const int kTfLiteBuiltinDepthToSpace = 5;
  static const int kTfLiteBuiltinDequantize = 6;
  static const int kTfLiteBuiltinEmbeddingLookup = 7;
  static const int kTfLiteBuiltinFloor = 8;
  static const int kTfLiteBuiltinFullyConnected = 9;
  static const int kTfLiteBuiltinHashtableLookup = 10;
  static const int kTfLiteBuiltinL2Normalization = 11;
  static const int kTfLiteBuiltinL2Pool2d = 12;
  static const int kTfLiteBuiltinLocalResponseNormalization = 13;
  static const int kTfLiteBuiltinLogistic = 14;
  static const int kTfLiteBuiltinLshProjection = 15;
  static const int kTfLiteBuiltinLstm = 16;
  static const int kTfLiteBuiltinMaxPool2d = 17;
  static const int kTfLiteBuiltinMul = 18;
  static const int kTfLiteBuiltinRelu = 19;
  static const int kTfLiteBuiltinReluN1To1 = 20;
  static const int kTfLiteBuiltinRelu6 = 21;
  static const int kTfLiteBuiltinReshape = 22;
  static const int kTfLiteBuiltinResizeBilinear = 23;
  static const int kTfLiteBuiltinRnn = 24;
  static const int kTfLiteBuiltinSoftmax = 25;
  static const int kTfLiteBuiltinSpaceToDepth = 26;
  static const int kTfLiteBuiltinSvdf = 27;
  static const int kTfLiteBuiltinTanh = 28;
  static const int kTfLiteBuiltinConcatEmbeddings = 29;
  static const int kTfLiteBuiltinSkipGram = 30;
  static const int kTfLiteBuiltinCall = 31;
  static const int kTfLiteBuiltinCustom = 32;
  static const int kTfLiteBuiltinEmbeddingLookupSparse = 33;
  static const int kTfLiteBuiltinPad = 34;
  static const int kTfLiteBuiltinUnidirectionalSequenceRnn = 35;
  static const int kTfLiteBuiltinGather = 36;
  static const int kTfLiteBuiltinBatchToSpaceNd = 37;
  static const int kTfLiteBuiltinSpaceToBatchNd = 38;
  static const int kTfLiteBuiltinTranspose = 39;
  static const int kTfLiteBuiltinMean = 40;
  static const int kTfLiteBuiltinSub = 41;
  static const int kTfLiteBuiltinDiv = 42;
  static const int kTfLiteBuiltinSqueeze = 43;
  static const int kTfLiteBuiltinUnidirectionalSequenceLstm = 44;
  static const int kTfLiteBuiltinStridedSlice = 45;
  static const int kTfLiteBuiltinBidirectionalSequenceRnn = 46;
  static const int kTfLiteBuiltinExp = 47;
  static const int kTfLiteBuiltinTopkV2 = 48;
  static const int kTfLiteBuiltinSplit = 49;
  static const int kTfLiteBuiltinLogSoftmax = 50;
  static const int kTfLiteBuiltinDelegate = 51;
  static const int kTfLiteBuiltinBidirectionalSequenceLstm = 52;
  static const int kTfLiteBuiltinCast = 53;
  static const int kTfLiteBuiltinPrelu = 54;
  static const int kTfLiteBuiltinMaximum = 55;
  static const int kTfLiteBuiltinArgMax = 56;
  static const int kTfLiteBuiltinMinimum = 57;
  static const int kTfLiteBuiltinLess = 58;
  static const int kTfLiteBuiltinNeg = 59;
  static const int kTfLiteBuiltinPadv2 = 60;
  static const int kTfLiteBuiltinGreater = 61;
  static const int kTfLiteBuiltinGreaterEqual = 62;
  static const int kTfLiteBuiltinLessEqual = 63;
  static const int kTfLiteBuiltinSelect = 64;
  static const int kTfLiteBuiltinSlice = 65;
  static const int kTfLiteBuiltinSin = 66;
  static const int kTfLiteBuiltinTransposeConv = 67;
  static const int kTfLiteBuiltinSparseToDense = 68;
  static const int kTfLiteBuiltinTile = 69;
  static const int kTfLiteBuiltinExpandDims = 70;
  static const int kTfLiteBuiltinEqual = 71;
  static const int kTfLiteBuiltinNotEqual = 72;
  static const int kTfLiteBuiltinLog = 73;
  static const int kTfLiteBuiltinSum = 74;
  static const int kTfLiteBuiltinSqrt = 75;
  static const int kTfLiteBuiltinRsqrt = 76;
  static const int kTfLiteBuiltinShape = 77;
  static const int kTfLiteBuiltinPow = 78;
  static const int kTfLiteBuiltinArgMin = 79;
  static const int kTfLiteBuiltinFakeQuant = 80;
  static const int kTfLiteBuiltinReduceProd = 81;
  static const int kTfLiteBuiltinReduceMax = 82;
  static const int kTfLiteBuiltinPack = 83;
  static const int kTfLiteBuiltinLogicalOr = 84;
  static const int kTfLiteBuiltinOneHot = 85;
  static const int kTfLiteBuiltinLogicalAnd = 86;
  static const int kTfLiteBuiltinLogicalNot = 87;
  static const int kTfLiteBuiltinUnpack = 88;
  static const int kTfLiteBuiltinReduceMin = 89;
  static const int kTfLiteBuiltinFloorDiv = 90;
  static const int kTfLiteBuiltinReduceAny = 91;
  static const int kTfLiteBuiltinSquare = 92;
  static const int kTfLiteBuiltinZerosLike = 93;
  static const int kTfLiteBuiltinFill = 94;
  static const int kTfLiteBuiltinFloorMod = 95;
  static const int kTfLiteBuiltinRange = 96;
  static const int kTfLiteBuiltinResizeNearestNeighbor = 97;
  static const int kTfLiteBuiltinLeakyRelu = 98;
  static const int kTfLiteBuiltinSquaredDifference = 99;
  static const int kTfLiteBuiltinMirrorPad = 100;
  static const int kTfLiteBuiltinAbs = 101;
  static const int kTfLiteBuiltinSplitV = 102;
  static const int kTfLiteBuiltinUnique = 103;
  static const int kTfLiteBuiltinCeil = 104;
  static const int kTfLiteBuiltinReverseV2 = 105;
  static const int kTfLiteBuiltinAddN = 106;
  static const int kTfLiteBuiltinGatherNd = 107;
  static const int kTfLiteBuiltinCos = 108;
  static const int kTfLiteBuiltinWhere = 109;
  static const int kTfLiteBuiltinRank = 110;
  static const int kTfLiteBuiltinElu = 111;
  static const int kTfLiteBuiltinReverseSequence = 112;
  static const int kTfLiteBuiltinMatrixDiag = 113;
  static const int kTfLiteBuiltinQuantize = 114;
  static const int kTfLiteBuiltinMatrixSetDiag = 115;
  static const int kTfLiteBuiltinRound = 116;
  static const int kTfLiteBuiltinHardSwish = 117;
  static const int kTfLiteBuiltinIf = 118;
  static const int kTfLiteBuiltinWhile = 119;
  static const int kTfLiteBuiltinNonMaxSuppressionV4 = 120;
  static const int kTfLiteBuiltinNonMaxSuppressionV5 = 121;
  static const int kTfLiteBuiltinScatterNd = 122;
  static const int kTfLiteBuiltinSelectV2 = 123;
  static const int kTfLiteBuiltinDensify = 124;
  static const int kTfLiteBuiltinSegmentSum = 125;
  static const int kTfLiteBuiltinBatchMatmul = 126;
  static const int kTfLiteBuiltinPlaceholderForGreaterOpCodes = 127;
  static const int kTfLiteBuiltinCumsum = 128;
  static const int kTfLiteBuiltinCallOnce = 129;
  static const int kTfLiteBuiltinBroadcastTo = 130;
  static const int kTfLiteBuiltinRfft2d = 131;
  static const int kTfLiteBuiltinConv3d = 132;
  static const int kTfLiteBuiltinImag = 133;
  static const int kTfLiteBuiltinReal = 134;
  static const int kTfLiteBuiltinComplexAbs = 135;
  static const int kTfLiteBuiltinHashtable = 136;
  static const int kTfLiteBuiltinHashtableFind = 137;
  static const int kTfLiteBuiltinHashtableImport = 138;
  static const int kTfLiteBuiltinHashtableSize = 139;
  static const int kTfLiteBuiltinReduceAll = 140;
  static const int kTfLiteBuiltinConv3dTranspose = 141;
  static const int kTfLiteBuiltinVarHandle = 142;
  static const int kTfLiteBuiltinReadVariable = 143;
  static const int kTfLiteBuiltinAssignVariable = 144;
  static const int kTfLiteBuiltinBroadcastArgs = 145;
  static const int kTfLiteBuiltinRandomStandardNormal = 146;
  static const int kTfLiteBuiltinBucketize = 147;
  static const int kTfLiteBuiltinRandomUniform = 148;
  static const int kTfLiteBuiltinMultinomial = 149;
  static const int kTfLiteBuiltinGelu = 150;
  static const int kTfLiteBuiltinDynamicUpdateSlice = 151;
  static const int kTfLiteBuiltinRelu0To1 = 152;
  static const int kTfLiteBuiltinUnsortedSegmentProd = 153;
  static const int kTfLiteBuiltinUnsortedSegmentMax = 154;
  static const int kTfLiteBuiltinUnsortedSegmentSum = 155;
  static const int kTfLiteBuiltinAtan2 = 156;
  static const int kTfLiteBuiltinUnsortedSegmentMin = 157;
  static const int kTfLiteBuiltinSign = 158;
}

/// Note that new error status values may be added in future in order to
/// indicate more fine-grained internal states, therefore, applications should
/// not rely on status values being members of the enum.
abstract class TfLiteStatus {
  static const int kTfLiteOk = 0;

  /// Generally referring to an error in the runtime (i.e. interpreter)
  static const int kTfLiteError = 1;

  /// Generally referring to an error from a TfLiteDelegate itself.
  static const int kTfLiteDelegateError = 2;

  /// Generally referring to an error in applying a delegate due to
  /// incompatibility between runtime and delegate, e.g., this error is returned
  /// when trying to apply a TF Lite delegate onto a model graph that's already
  /// immutable.
  static const int kTfLiteApplicationError = 3;

  /// Generally referring to serialized delegate data not being found.
  /// See tflite::delegates::Serialization.
  static const int kTfLiteDelegateDataNotFound = 4;

  /// Generally referring to data-writing issues in delegate serialization.
  /// See tflite::delegates::Serialization.
  static const int kTfLiteDelegateDataWriteError = 5;

  /// Generally referring to data-reading issues in delegate serialization.
  /// See tflite::delegates::Serialization.
  static const int kTfLiteDelegateDataReadError = 6;

  /// Generally referring to issues when the TF Lite model has ops that cannot be
  /// resolved at runtime. This could happen when the specific op is not
  /// registered or built with the TF Lite framework.
  static const int kTfLiteUnresolvedOps = 7;

  /// Generally referring to invocation cancelled by the user.
  /// See `interpreter::Cancel`.
  /// TODO(b/194915839): Implement `interpreter::Cancel`.
  /// TODO(b/250636993): Cancellation triggered by `SetCancellationFunction`
  /// should also return this status code.
  static const int kTfLiteCancelled = 8;
}

/// Types supported by tensor
abstract class TfLiteType {
  static const int kTfLiteNoType = 0;
  static const int kTfLiteFloat32 = 1;
  static const int kTfLiteInt32 = 2;
  static const int kTfLiteUInt8 = 3;
  static const int kTfLiteInt64 = 4;
  static const int kTfLiteString = 5;
  static const int kTfLiteBool = 6;
  static const int kTfLiteInt16 = 7;
  static const int kTfLiteComplex64 = 8;
  static const int kTfLiteInt8 = 9;
  static const int kTfLiteFloat16 = 10;
  static const int kTfLiteFloat64 = 11;
  static const int kTfLiteComplex128 = 12;
  static const int kTfLiteUInt64 = 13;
  static const int kTfLiteResource = 14;
  static const int kTfLiteVariant = 15;
  static const int kTfLiteUInt32 = 16;
  static const int kTfLiteUInt16 = 17;
  static const int kTfLiteInt4 = 18;
}

/// Legacy. Will be deprecated in favor of TfLiteAffineQuantization.
/// If per-layer quantization is specified this field will still be populated in
/// addition to TfLiteAffineQuantization.
/// Parameters for asymmetric quantization. Quantized values can be converted
/// back to float using:
/// real_value = scale * (quantized_value - zero_point)
class TfLiteQuantizationParams extends ffi.Struct {
  @ffi.Float()
  external double scale;

  @ffi.Int32()
  external int zero_point;
}

class TfLiteOpaqueContext extends ffi.Opaque {}

class TfLiteOpaqueNode extends ffi.Opaque {}

class TfLiteOpaqueTensor extends ffi.Opaque {}

/// WARNING: This is an experimental interface that is subject to change.
class TfLiteDelegate extends ffi.Struct {
  /// Data that delegate needs to identify itself. This data is owned by the
  /// delegate. The delegate is owned in the user code, so the delegate is
  /// responsible for deallocating this when it is destroyed.
  external ffi.Pointer<ffi.Void> data_;

  /// Invoked by ModifyGraphWithDelegate. This prepare is called, giving the
  /// delegate a view of the current graph through TfLiteContext*. It typically
  /// will look at the nodes and call ReplaceNodeSubsetsWithDelegateKernels()
  /// to ask the TensorFlow lite runtime to create macro-nodes to represent
  /// delegated subgraphs of the original graph.
  external ffi.Pointer<
          ffi.NativeFunction<
              ffi.Int32 Function(
                  ffi.Pointer<TfLiteContext>, ffi.Pointer<TfLiteDelegate>)>>
      Prepare;

  /// Copy the data from delegate buffer handle into raw memory of the given
  /// 'tensor'. Note that the delegate is allowed to allocate the raw bytes as
  /// long as it follows the rules for kTfLiteDynamic tensors, in which case this
  /// cannot be null.
  external ffi.Pointer<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<TfLiteContext>,
              ffi.Pointer<TfLiteDelegate>,
              TfLiteBufferHandle,
              ffi.Pointer<TfLiteTensor>)>> CopyFromBufferHandle;

  /// Copy the data from raw memory of the given 'tensor' to delegate buffer
  /// handle. This can be null if the delegate doesn't use its own buffer.
  external ffi.Pointer<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<TfLiteContext>,
              ffi.Pointer<TfLiteDelegate>,
              TfLiteBufferHandle,
              ffi.Pointer<TfLiteTensor>)>> CopyToBufferHandle;

  /// Free the Delegate Buffer Handle. Note: This only frees the handle, but
  /// this doesn't release the underlying resource (e.g. textures). The
  /// resources are either owned by application layer or the delegate.
  /// This can be null if the delegate doesn't use its own buffer.
  external ffi.Pointer<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<TfLiteContext>,
              ffi.Pointer<TfLiteDelegate>,
              ffi.Pointer<TfLiteBufferHandle>)>> FreeBufferHandle;

  /// Bitmask flags. See the comments in `TfLiteDelegateFlags`.
  @ffi.Int64()
  external int flags;

  /// The opaque delegate builder associated with this object.  If set then the
  /// TF Lite runtime will give precedence to this field.  E.g. instead of
  /// invoking 'Prepare' via the function pointer inside the 'TfLiteDelegate'
  /// object, the runtime will first check if the corresponding function
  /// pointer inside 'opaque_delegate_builder' is set and if so invoke that.
  ///
  /// If this field is non-null, then the 'Prepare' field (of the
  /// 'TfLiteDelegate') should be null.
  external ffi.Pointer<TfLiteOpaqueDelegateBuilder> opaque_delegate_builder;
}

/// Forward declare so dependent structs and methods can reference these types
/// prior to the struct definitions.
class TfLiteContext extends ffi.Struct {
  /// Number of tensors in the context.
  @ffi.Size()
  external int tensors_size;

  /// The execution plan contains a list of the node indices in execution
  /// order. execution_plan->size is the current number of nodes. And,
  /// execution_plan->data[0] is the first node that needs to be run.
  /// TfLiteDelegates can traverse the current execution plan by iterating
  /// through each member of this array and using GetNodeAndRegistration() to
  /// access details about a node. i.e.
  ///
  /// TfLiteIntArray* execution_plan;
  /// TF_LITE_ENSURE_STATUS(context->GetExecutionPlan(context, &execution_plan));
  /// for (int exec_index = 0; exec_index < execution_plan->size; exec_index++) {
  /// int node_index = execution_plan->data[exec_index];
  /// TfLiteNode* node;
  /// TfLiteRegistration* reg;
  /// context->GetNodeAndRegistration(context, node_index, &node, &reg);
  /// }
  /// Note: the memory pointed by '`*execution_plan` is OWNED by TfLite runtime.
  /// Future calls to GetExecutionPlan invalidates earlier outputs. The following
  /// code snippet shows the issue of such an invocation pattern. After calling
  /// CheckNode, subsequent access to `plan_1st` is undefined.
  ///
  /// void CheckNode(const TfLiteNode* node) {
  /// ...
  /// TfLiteIntArray* plan_2nd;
  /// TF_LITE_ENSURE_STATUS(context->GetExecutionPlan(context, &plan_2nd));
  /// ...
  /// }
  ///
  /// TfLiteIntArray* plan_1st;
  /// TF_LITE_ENSURE_STATUS(context->GetExecutionPlan(context, &plan_1st));
  /// for (int exec_index = 0; exec_index < plan_1st->size; exec_index++) {
  /// int node_index = plan_1st->data[exec_index];
  /// TfLiteNode* node;
  /// TfLiteRegistration* reg;
  /// context->GetNodeAndRegistration(context, node_index, &node, &reg);
  /// CheckNode(node);
  /// }
  ///
  /// WARNING: This is an experimental interface that is subject to change.
  external ffi.Pointer<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<TfLiteContext>,
              ffi.Pointer<ffi.Pointer<TfLiteIntArray>>)>> GetExecutionPlan;

  /// An array of tensors in the interpreter context (of length `tensors_size`)
  external ffi.Pointer<TfLiteTensor> tensors;

  /// opaque full context ptr (an opaque c++ data structure)
  external ffi.Pointer<ffi.Void> impl_;

  /// Request memory pointer be resized. Updates dimensions on the tensor.
  /// NOTE: ResizeTensor takes ownership of newSize.
  external ffi.Pointer<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<TfLiteContext>,
              ffi.Pointer<TfLiteTensor>,
              ffi.Pointer<TfLiteIntArray>)>> ResizeTensor;

  /// Request that an error be reported with format string msg.
  external ffi.Pointer<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<TfLiteContext>, ffi.Pointer<ffi.Char>)>> ReportError;

  /// Add `tensors_to_add` tensors, preserving pre-existing Tensor entries.  If
  /// non-null, the value pointed to by `first_new_tensor_index` will be set to
  /// the index of the first new tensor.
  external ffi.Pointer<
          ffi.NativeFunction<
              ffi.Int32 Function(
                  ffi.Pointer<TfLiteContext>, ffi.Int, ffi.Pointer<ffi.Int>)>>
      AddTensors;

  /// Get a Tensor node by node_index.
  /// WARNING: This is an experimental interface that is subject to change.
  external ffi.Pointer<
          ffi.NativeFunction<
              ffi.Int32 Function(
                  ffi.Pointer<TfLiteContext>,
                  ffi.Int,
                  ffi.Pointer<ffi.Pointer<TfLiteNode>>,
                  ffi.Pointer<ffi.Pointer<TfLiteRegistration>>)>>
      GetNodeAndRegistration;

  /// Replace ops with one or more stub delegate operations. This function
  /// does not take ownership of `nodes_to_replace`.
  external ffi.Pointer<
          ffi.NativeFunction<
              ffi.Int32 Function(ffi.Pointer<TfLiteContext>, TfLiteRegistration,
                  ffi.Pointer<TfLiteIntArray>, ffi.Pointer<TfLiteDelegate>)>>
      ReplaceNodeSubsetsWithDelegateKernels;

  /// Number of threads that are recommended to subsystems like gemmlowp and
  /// eigen.
  @ffi.Int()
  external int recommended_num_threads;

  /// Access external contexts by type.
  /// WARNING: This is an experimental interface that is subject to change.
  external ffi.Pointer<
      ffi.NativeFunction<
          ffi.Pointer<TfLiteExternalContext> Function(
              ffi.Pointer<TfLiteContext>, ffi.Int32)>> GetExternalContext;

  /// Set the value of a external context. Does not take ownership of the
  /// pointer.
  /// WARNING: This is an experimental interface that is subject to change.
  external ffi.Pointer<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<TfLiteContext>, ffi.Int32,
              ffi.Pointer<TfLiteExternalContext>)>> SetExternalContext;

  /// Flag for allowing float16 precision for FP32 calculation.
  /// default: false.
  /// WARNING: This is an experimental API and subject to change.
  @ffi.Bool()
  external bool allow_fp32_relax_to_fp16;

  /// Pointer to the op-level profiler, if set; nullptr otherwise.
  external ffi.Pointer<ffi.Void> profiler;

  /// Allocate persistent buffer which has the same life time as the interpreter.
  /// Returns nullptr on failure.
  /// The memory is allocated from heap for TFL, and from tail in TFLM.
  /// This method is only available in Init or Prepare stage.
  /// WARNING: This is an experimental interface that is subject to change.
  external ffi.Pointer<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Void> Function(
              ffi.Pointer<TfLiteContext>, ffi.Size)>> AllocatePersistentBuffer;

  /// Allocate a buffer which will be deallocated right after invoke phase.
  /// The memory is allocated from heap in TFL, and from volatile arena in TFLM.
  /// This method is only available in invoke stage.
  /// NOTE: If possible use RequestScratchBufferInArena method to avoid memory
  /// allocation during inference time.
  /// WARNING: This is an experimental interface that is subject to change.
  external ffi.Pointer<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<TfLiteContext>, ffi.Size,
              ffi.Pointer<ffi.Pointer<ffi.Void>>)>> AllocateBufferForEval;

  /// Request a scratch buffer in the arena through static memory planning.
  /// This method is only available in Prepare stage and the buffer is allocated
  /// by the interpreter between Prepare and Eval stage. In Eval stage,
  /// GetScratchBuffer API can be used to fetch the address.
  /// WARNING: This is an experimental interface that is subject to change.
  external ffi.Pointer<
          ffi.NativeFunction<
              ffi.Int32 Function(
                  ffi.Pointer<TfLiteContext>, ffi.Size, ffi.Pointer<ffi.Int>)>>
      RequestScratchBufferInArena;

  /// Get the scratch buffer pointer.
  /// This method is only available in Eval stage.
  /// WARNING: This is an experimental interface that is subject to change.
  external ffi.Pointer<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Void> Function(
              ffi.Pointer<TfLiteContext>, ffi.Int)>> GetScratchBuffer;

  /// Resize the memory pointer of the `tensor`. This method behaves the same as
  /// `ResizeTensor`, except that it makes a copy of the shape array internally
  /// so the shape array could be deallocated right afterwards.
  /// WARNING: This is an experimental interface that is subject to change.
  external ffi.Pointer<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<TfLiteContext>,
              ffi.Pointer<TfLiteTensor>,
              ffi.Int,
              ffi.Pointer<ffi.Int>)>> ResizeTensorExplicit;

  /// This method provides a preview of post-delegation partitioning. Each
  /// TfLiteDelegateParams in the referenced array corresponds to one instance of
  /// the delegate kernel.
  /// Example usage:
  ///
  /// TfLiteIntArray* nodes_to_replace = ...;
  /// TfLiteDelegateParams* params_array;
  /// int num_partitions = 0;
  /// TF_LITE_ENSURE_STATUS(context->PreviewDelegatePartitioning(
  /// context, delegate, nodes_to_replace, &params_array, &num_partitions));
  /// for (int idx = 0; idx < num_partitions; idx++) {
  /// const auto& partition_params = params_array[idx];
  /// ...
  /// }
  ///
  /// NOTE: The context owns the memory referenced by partition_params_array. It
  /// will be cleared with another call to PreviewDelegateParitioning, or after
  /// TfLiteDelegateParams::Prepare returns.
  ///
  /// WARNING: This is an experimental interface that is subject to change.
  external ffi.Pointer<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<TfLiteContext>,
              ffi.Pointer<TfLiteIntArray>,
              ffi.Pointer<ffi.Pointer<TfLiteDelegateParams>>,
              ffi.Pointer<ffi.Int>)>> PreviewDelegatePartitioning;

  /// Returns a TfLiteTensor struct for a given index.
  /// WARNING: This is an experimental interface that is subject to change.
  /// WARNING: This method may not be available on all platforms.
  external ffi.Pointer<
      ffi.NativeFunction<
          ffi.Pointer<TfLiteTensor> Function(
              ffi.Pointer<TfLiteContext>, ffi.Int)>> GetTensor;

  /// Returns a TfLiteEvalTensor struct for a given index.
  /// WARNING: This is an experimental interface that is subject to change.
  /// WARNING: This method may not be available on all platforms.
  external ffi.Pointer<
      ffi.NativeFunction<
          ffi.Pointer<TfLiteEvalTensor> Function(
              ffi.Pointer<TfLiteContext>, ffi.Int)>> GetEvalTensor;

  /// Retrieves named metadata buffer from the TFLite model.
  /// Returns kTfLiteOk if metadata is successfully obtained from the flatbuffer
  /// Model: that is, there exists a `metadata` entry with given `name` string.
  /// (see TFLite's schema.fbs).
  /// The corresponding `buffer` information is populated in `ptr` & `bytes`.
  /// The data from `ptr` is valid for the lifetime of the Interpreter.
  ///
  /// WARNING: This is an experimental interface that is subject to change.
  external ffi.Pointer<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<TfLiteContext>,
              ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Pointer<ffi.Char>>,
              ffi.Pointer<ffi.Size>)>> GetModelMetadata;
}

/// Fixed size list of integers. Used for dimensions and inputs/outputs tensor
/// indices
class TfLiteIntArray extends ffi.Opaque {}

class TfLiteTensor extends ffi.Struct {
  /// The data type specification for data stored in `data`. This affects
  /// what member of `data` union should be used.
  @ffi.Int32()
  external int type;

  /// A union of data pointers. The appropriate type should be used for a typed
  /// tensor based on `type`.
  external TfLitePtrUnion data;

  /// A pointer to a structure representing the dimensionality interpretation
  /// that the buffer should have. NOTE: the product of elements of `dims`
  /// and the element datatype size should be equal to `bytes` below.
  external ffi.Pointer<TfLiteIntArray> dims;

  /// Quantization information.
  external TfLiteQuantizationParams params;

  /// How memory is mapped
  /// kTfLiteMmapRo: Memory mapped read only.
  /// i.e. weights
  /// kTfLiteArenaRw: Arena allocated read write memory
  /// (i.e. temporaries, outputs).
  @ffi.Int32()
  external int allocation_type;

  /// The number of bytes required to store the data of this Tensor. I.e.
  /// (bytes of each element) * dims[0] * ... * dims[n-1].  For example, if
  /// type is kTfLiteFloat32 and dims = {3, 2} then
  /// bytes = sizeof(float) * 3 * 2 = 4 * 3 * 2 = 24.
  @ffi.Size()
  external int bytes;

  /// An opaque pointer to a tflite::MMapAllocation
  external ffi.Pointer<ffi.Void> allocation;

  /// Null-terminated name of this tensor.
  external ffi.Pointer<ffi.Char> name;

  /// The delegate which knows how to handle `buffer_handle`.
  /// WARNING: This is an experimental interface that is subject to change.
  external ffi.Pointer<TfLiteDelegate> delegate;

  /// An integer buffer handle that can be handled by `delegate`.
  /// The value is valid only when delegate is not null.
  /// WARNING: This is an experimental interface that is subject to change.
  @TfLiteBufferHandle()
  external int buffer_handle;

  /// If the delegate uses its own buffer (e.g. GPU memory), the delegate is
  /// responsible to set data_is_stale to true.
  /// `delegate->CopyFromBufferHandle` can be called to copy the data from
  /// delegate buffer.
  /// WARNING: This is an // experimental interface that is subject to change.
  @ffi.Bool()
  external bool data_is_stale;

  /// True if the tensor is a variable.
  @ffi.Bool()
  external bool is_variable;

  /// Quantization information. Replaces params field above.
  external TfLiteQuantization quantization;

  /// Parameters used to encode a sparse tensor.
  /// This is optional. The field is NULL if a tensor is dense.
  /// WARNING: This is an experimental interface that is subject to change.
  external ffi.Pointer<TfLiteSparsity> sparsity;

  /// Optional. Encodes shapes with unknown dimensions with -1. This field is
  /// only populated when unknown dimensions exist in a read-write tensor (i.e.
  /// an input or output tensor). (e.g.  `dims` contains [1, 1, 1, 3] and
  /// `dims_signature` contains [1, -1, -1, 3]).  If no unknown dimensions exist
  /// then `dims_signature` is either null, or set to an empty array.  Note that
  /// this field only exists when TF_LITE_STATIC_MEMORY is not defined.
  external ffi.Pointer<TfLiteIntArray> dims_signature;
}

/// A union of pointers that points to memory for a given tensor.
class TfLitePtrUnion extends ffi.Union {
  /// Do not access these members directly, if possible, use
  /// GetTensorData<TYPE>(tensor) instead, otherwise only access .data, as other
  /// members are deprecated.
  external ffi.Pointer<ffi.Int32> i32;

  external ffi.Pointer<ffi.Uint32> u32;

  external ffi.Pointer<ffi.Int64> i64;

  external ffi.Pointer<ffi.Uint64> u64;

  external ffi.Pointer<ffi.Float> f;

  external ffi.Pointer<TfLiteFloat16> f16;

  external ffi.Pointer<ffi.Double> f64;

  external ffi.Pointer<ffi.Char> raw;

  external ffi.Pointer<ffi.Char> raw_const;

  external ffi.Pointer<ffi.Uint8> uint8;

  external ffi.Pointer<ffi.Bool> b;

  external ffi.Pointer<ffi.Int16> i16;

  external ffi.Pointer<ffi.Uint16> ui16;

  external ffi.Pointer<TfLiteComplex64> c64;

  external ffi.Pointer<TfLiteComplex128> c128;

  external ffi.Pointer<ffi.Int8> int8;

  /// Only use this member.
  external ffi.Pointer<ffi.Void> data;
}

/// Half precision data type compatible with the C99 definition.
class TfLiteFloat16 extends ffi.Struct {
  @ffi.Uint16()
  external int data;
}

/// Single-precision complex data type compatible with the C99 definition.
class TfLiteComplex64 extends ffi.Struct {
  /// real and imaginary parts, respectively.
  @ffi.Float()
  external double re;

  @ffi.Float()
  external double im;
}

/// Double-precision complex data type compatible with the C99 definition.
class TfLiteComplex128 extends ffi.Struct {
  /// real and imaginary parts, respectively.
  @ffi.Double()
  external double re;

  @ffi.Double()
  external double im;
}

/// Memory allocation strategies.
/// * kTfLiteMmapRo: Read-only memory-mapped data, or data externally allocated.
/// * kTfLiteArenaRw: Arena allocated with no guarantees about persistence,
/// and available during eval.
/// * kTfLiteArenaRwPersistent: Arena allocated but persistent across eval, and
/// only available during eval.
/// * kTfLiteDynamic: Allocated during eval, or for string tensors.
/// * kTfLitePersistentRo: Allocated and populated during prepare. This is
/// useful for tensors that can be computed during prepare and treated
/// as constant inputs for downstream ops (also in prepare).
/// * kTfLiteCustom: Custom memory allocation provided by the user. See
/// TfLiteCustomAllocation below.
abstract class TfLiteAllocationType {
  static const int kTfLiteMemNone = 0;
  static const int kTfLiteMmapRo = 1;
  static const int kTfLiteArenaRw = 2;
  static const int kTfLiteArenaRwPersistent = 3;
  static const int kTfLiteDynamic = 4;
  static const int kTfLitePersistentRo = 5;
  static const int kTfLiteCustom = 6;
}

/// The delegates should use zero or positive integers to represent handles.
/// -1 is reserved from unallocated status.
typedef TfLiteBufferHandle = ffi.Int;

/// Structure specifying the quantization used by the tensor, if-any.
class TfLiteQuantization extends ffi.Struct {
  /// The type of quantization held by params.
  @ffi.Int32()
  external int type;

  /// Holds an optional reference to a quantization param structure. The actual
  /// type depends on the value of the `type` field (see the comment there for
  /// the values and corresponding types).
  external ffi.Pointer<ffi.Void> params;
}

/// SupportedQuantizationTypes.
abstract class TfLiteQuantizationType {
  /// No quantization.
  static const int kTfLiteNoQuantization = 0;

  /// Affine quantization (with support for per-channel quantization).
  /// Corresponds to TfLiteAffineQuantization.
  static const int kTfLiteAffineQuantization = 1;
}

/// Parameters used to encode a sparse tensor. For detailed explanation of each
/// field please refer to lite/schema/schema.fbs.
class TfLiteSparsity extends ffi.Struct {
  external ffi.Pointer<TfLiteIntArray> traversal_order;

  external ffi.Pointer<TfLiteIntArray> block_map;

  external ffi.Pointer<TfLiteDimensionMetadata> dim_metadata;

  @ffi.Int()
  external int dim_metadata_size;
}

/// Metadata to encode each dimension in a sparse tensor.
class TfLiteDimensionMetadata extends ffi.Struct {
  @ffi.Int32()
  external int format;

  @ffi.Int()
  external int dense_size;

  external ffi.Pointer<TfLiteIntArray> array_segments;

  external ffi.Pointer<TfLiteIntArray> array_indices;
}

/// Storage format of each dimension in a sparse tensor.
abstract class TfLiteDimensionType {
  static const int kTfLiteDimDense = 0;
  static const int kTfLiteDimSparseCSR = 1;
}

/// A structure representing an instance of a node.
/// This structure only exhibits the inputs, outputs, user defined data and some
/// node properties (like statefulness), not other features like the type.
class TfLiteNode extends ffi.Struct {
  /// Inputs to this node expressed as indices into the simulator's tensors.
  external ffi.Pointer<TfLiteIntArray> inputs;

  /// Outputs to this node expressed as indices into the simulator's tensors.
  external ffi.Pointer<TfLiteIntArray> outputs;

  /// intermediate tensors to this node expressed as indices into the simulator's
  /// tensors.
  external ffi.Pointer<TfLiteIntArray> intermediates;

  /// Temporary tensors uses during the computations. This usually contains no
  /// tensors, but ops are allowed to change that if they need scratch space of
  /// any sort.
  external ffi.Pointer<TfLiteIntArray> temporaries;

  /// Opaque data provided by the node implementer through `Registration.init`.
  external ffi.Pointer<ffi.Void> user_data;

  /// Opaque data provided to the node if the node is a builtin. This is usually
  /// a structure defined in builtin_op_data.h
  external ffi.Pointer<ffi.Void> builtin_data;

  /// Custom initial data. This is the opaque data provided in the flatbuffer.
  /// WARNING: This is an experimental interface that is subject to change.
  external ffi.Pointer<ffi.Void> custom_initial_data;

  @ffi.Int()
  external int custom_initial_data_size;

  /// The pointer to the delegate. This is non-null only when the node is
  /// created by calling `interpreter.ModifyGraphWithDelegate`.
  /// WARNING: This is an experimental interface that is subject to change.
  external ffi.Pointer<TfLiteDelegate> delegate;

  /// Whether this op might have side effect (e.g. stateful op).
  @ffi.Bool()
  external bool might_have_side_effect;
}

class TfLiteRegistration extends ffi.Struct {
  /// Initializes the op from serialized data.
  /// Called only *once* for the lifetime of the op, so any one-time allocations
  /// should be made here (unless they depend on tensor sizes).
  ///
  /// If a built-in op:
  /// `buffer` is the op's params data (TfLiteLSTMParams*).
  /// `length` is zero.
  /// If custom op:
  /// `buffer` is the op's `custom_options`.
  /// `length` is the size of the buffer.
  ///
  /// Returns a type-punned (i.e. void*) opaque data (e.g. a primitive pointer
  /// or an instance of a struct).
  ///
  /// The returned pointer will be stored with the node in the `user_data` field,
  /// accessible within prepare and invoke functions below.
  /// NOTE: if the data is already in the desired format, simply implement this
  /// function to return `nullptr` and implement the free function to be a no-op.
  external ffi.Pointer<
          ffi.NativeFunction<
              ffi.Pointer<ffi.Void> Function(
                  ffi.Pointer<TfLiteContext>, ffi.Pointer<ffi.Char>, ffi.Size)>>
      init;

  /// The pointer `buffer` is the data previously returned by an init invocation.
  external ffi.Pointer<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<TfLiteContext>, ffi.Pointer<ffi.Void>)>> free;

  /// prepare is called when the inputs this node depends on have been resized.
  /// context->ResizeTensor() can be called to request output tensors to be
  /// resized.
  /// Can be called multiple times for the lifetime of the op.
  ///
  /// Returns kTfLiteOk on success.
  external ffi.Pointer<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<TfLiteContext>, ffi.Pointer<TfLiteNode>)>> prepare;

  /// Execute the node (should read node->inputs and output to node->outputs).
  /// Returns kTfLiteOk on success.
  external ffi.Pointer<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<TfLiteContext>, ffi.Pointer<TfLiteNode>)>> invoke;

  /// profiling_string is called during summarization of profiling information
  /// in order to group executions together. Providing a value here will cause a
  /// given op to appear multiple times is the profiling report. This is
  /// particularly useful for custom ops that can perform significantly
  /// different calculations depending on their `user-data`.
  external ffi.Pointer<
          ffi.NativeFunction<
              ffi.Pointer<ffi.Char> Function(
                  ffi.Pointer<TfLiteContext>, ffi.Pointer<TfLiteNode>)>>
      profiling_string;

  /// Builtin codes. If this kernel refers to a builtin this is the code
  /// of the builtin. This is so we can do marshaling to other frameworks like
  /// NN API.
  /// Note: It is the responsibility of the registration binder to set this
  /// properly.
  @ffi.Int32()
  external int builtin_code;

  /// Custom op name. If the op is a builtin, this will be null.
  /// Note: It is the responsibility of the registration binder to set this
  /// properly.
  /// WARNING: This is an experimental interface that is subject to change.
  external ffi.Pointer<ffi.Char> custom_name;

  /// The version of the op.
  /// Note: It is the responsibility of the registration binder to set this
  /// properly.
  @ffi.Int()
  external int version;

  /// The external version of `TfLiteRegistration`. Since we can't use internal
  /// types (such as `TfLiteContext`) for C API to maintain ABI stability.
  /// C API user will provide `TfLiteRegistrationExternal` to implement custom
  /// ops. We keep it inside of `TfLiteRegistration` and use it to route
  /// callbacks properly.
  external ffi.Pointer<TfLiteRegistrationExternal> registration_external;
}

class TfLiteRegistrationExternal extends ffi.Opaque {}

/// An external context is a collection of information unrelated to the TF Lite
/// framework, but useful to a subset of the ops. TF Lite knows very little
/// about the actual contexts, but it keeps a list of them, and is able to
/// refresh them if configurations like the number of recommended threads
/// change.
class TfLiteExternalContext extends ffi.Struct {
  @ffi.Int32()
  external int type;

  external ffi.Pointer<
          ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<TfLiteContext>)>>
      Refresh;
}

/// The list of external context types known to TF Lite. This list exists solely
/// to avoid conflicts and to ensure ops can share the external contexts they
/// need. Access to the external contexts is controlled by one of the
/// corresponding support files.
abstract class TfLiteExternalContextType {
  /// include eigen_support.h to use.
  static const int kTfLiteEigenContext = 0;

  /// include gemm_support.h to use.
  static const int kTfLiteGemmLowpContext = 1;

  /// Placeholder for Edge TPU support.
  static const int kTfLiteEdgeTpuContext = 2;

  /// include cpu_backend_context.h to use.
  static const int kTfLiteCpuBackendContext = 3;
  static const int kTfLiteMaxExternalContexts = 4;
}

/// WARNING: This is an experimental interface that is subject to change.
///
/// Currently, TfLiteDelegateParams has to be allocated in a way that it's
/// trivially destructable. It will be stored as `builtin_data` field in
/// `TfLiteNode` of the delegate node.
///
/// See also the `CreateDelegateParams` function in `interpreter.cc` details.
class TfLiteDelegateParams extends ffi.Struct {
  external ffi.Pointer<TfLiteDelegate> delegate;

  external ffi.Pointer<TfLiteIntArray> nodes_to_replace;

  external ffi.Pointer<TfLiteIntArray> input_tensors;

  external ffi.Pointer<TfLiteIntArray> output_tensors;
}

/// Light-weight tensor struct for TF Micro runtime. Provides the minimal amount
/// of information required for a kernel to run during TfLiteRegistration::Eval.
/// TODO(b/160955687): Move this field into TF_LITE_STATIC_MEMORY when TFLM
/// builds with this flag by default internally.
class TfLiteEvalTensor extends ffi.Struct {
  /// A union of data pointers. The appropriate type should be used for a typed
  /// tensor based on `type`.
  external TfLitePtrUnion data;

  /// A pointer to a structure representing the dimensionality interpretation
  /// that the buffer should have.
  external ffi.Pointer<TfLiteIntArray> dims;

  /// The data type specification for data stored in `data`. This affects
  /// what member of `data` union should be used.
  @ffi.Int32()
  external int type;
}

/// `TfLiteOpaqueDelegateBuilder` is used for constructing
/// `TfLiteOpaqueDelegate`, see `TfLiteOpaqueDelegateCreate` below.  Note:
/// This struct is not ABI stable.
///
/// For forward source compatibility `TfLiteOpaqueDelegateBuilder` objects should
/// be brace-initialized, so that all fields (including any that might be added
/// in the future) get zero-initialized.  The purpose of each field is exactly
/// the same as with `TfLiteDelegate`.
///
/// WARNING: This is an experimental interface that is subject to change.
class TfLiteOpaqueDelegateBuilder extends ffi.Struct {
  /// Data that delegate needs to identify itself. This data is owned by the
  /// delegate. The delegate is owned in the user code, so the delegate is
  /// responsible for deallocating this when it is destroyed.
  external ffi.Pointer<ffi.Void> data;

  /// NOLINT
  external ffi.Pointer<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<TfLiteOpaqueContext>,
              ffi.Pointer<TfLiteOpaqueDelegate>,
              ffi.Pointer<ffi.Void>)>> Prepare;

  /// NOLINT
  external ffi.Pointer<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<TfLiteOpaqueContext>,
              ffi.Pointer<TfLiteOpaqueDelegate>,
              ffi.Pointer<ffi.Void>,
              TfLiteBufferHandle,
              ffi.Pointer<TfLiteOpaqueTensor>)>> CopyFromBufferHandle;

  /// NOLINT
  external ffi.Pointer<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<TfLiteOpaqueContext>,
              ffi.Pointer<TfLiteOpaqueDelegate>,
              ffi.Pointer<ffi.Void>,
              TfLiteBufferHandle,
              ffi.Pointer<TfLiteOpaqueTensor>)>> CopyToBufferHandle;

  /// NOLINT
  external ffi.Pointer<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<TfLiteOpaqueContext>,
              ffi.Pointer<TfLiteOpaqueDelegate>,
              ffi.Pointer<ffi.Void>,
              ffi.Pointer<TfLiteBufferHandle>)>> FreeBufferHandle;

  /// Bitmask flags. See the comments in `TfLiteDelegateFlags`.
  @ffi.Int64()
  external int flags;
}

typedef TfLiteOpaqueDelegate = TfLiteDelegate;

class TfLiteOpaqueDelegateStruct extends ffi.Opaque {}

class TfLiteModel extends ffi.Opaque {}

class TfLiteInterpreterOptions extends ffi.Opaque {}

class TfLiteInterpreter extends ffi.Opaque {}

typedef va_list = __builtin_va_list;
typedef __builtin_va_list = ffi.Pointer<ffi.Char>;

/// Fixed size list of floats. Used for per-channel quantization.
class TfLiteFloatArray extends ffi.Opaque {}

/// Parameters for asymmetric quantization across a dimension (i.e per output
/// channel quantization).
/// quantized_dimension specifies which dimension the scales and zero_points
/// correspond to.
/// For a particular value in quantized_dimension, quantized values can be
/// converted back to float using:
/// real_value = scale * (quantized_value - zero_point)
class TfLiteAffineQuantization extends ffi.Struct {
  external ffi.Pointer<TfLiteFloatArray> scale;

  external ffi.Pointer<TfLiteIntArray> zero_point;

  @ffi.Int32()
  external int quantized_dimension;
}

/// Defines a custom memory allocation not owned by the runtime.
/// `data` should be aligned to kDefaultTensorAlignment defined in
/// lite/util.h. (Currently 64 bytes)
/// NOTE: See Interpreter.SetCustomAllocationForTensor for details on usage.
class TfLiteCustomAllocation extends ffi.Struct {
  external ffi.Pointer<ffi.Void> data;

  @ffi.Size()
  external int bytes;
}

/// The flags used in `Interpreter::SetCustomAllocationForTensor`.
/// Note that this is a bitmask, so the values should be 1, 2, 4, 8, ...etc.
abstract class TfLiteCustomAllocationFlags {
  static const int kTfLiteCustomAllocationFlagsNone = 0;

  /// Skips checking whether allocation.data points to an aligned buffer as
  /// expected by the TFLite runtime.
  /// NOTE: Setting this flag can cause crashes when calling Invoke().
  /// Use with caution.
  static const int kTfLiteCustomAllocationFlagsSkipAlignCheck = 1;
}

/// WARNING: This is an experimental interface that is subject to change.
///
/// Currently, TfLiteOpaqueDelegateParams has to be allocated in a way that it's
/// trivially destructable. It will be stored as `builtin_data` field in
/// `TfLiteNode` of the delegate node.
///
/// See also the `CreateOpaqueDelegateParams` function in `subgraph.cc`
/// details.
class TfLiteOpaqueDelegateParams extends ffi.Struct {
  external ffi.Pointer<TfLiteOpaqueDelegate> delegate;

  external ffi.Pointer<ffi.Void> delegate_data;

  external ffi.Pointer<TfLiteIntArray> nodes_to_replace;

  external ffi.Pointer<TfLiteIntArray> input_tensors;

  external ffi.Pointer<TfLiteIntArray> output_tensors;
}

/// Old version of `TfLiteRegistration` to maintain binary backward
/// compatibility.
/// WARNING: This structure is deprecated / not an official part of the API.
/// It should be only used for binary backward compatibility.
class TfLiteRegistration_V1 extends ffi.Struct {
  external ffi.Pointer<
          ffi.NativeFunction<
              ffi.Pointer<ffi.Void> Function(
                  ffi.Pointer<TfLiteContext>, ffi.Pointer<ffi.Char>, ffi.Size)>>
      init;

  external ffi.Pointer<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<TfLiteContext>, ffi.Pointer<ffi.Void>)>> free;

  external ffi.Pointer<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<TfLiteContext>, ffi.Pointer<TfLiteNode>)>> prepare;

  external ffi.Pointer<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<TfLiteContext>, ffi.Pointer<TfLiteNode>)>> invoke;

  external ffi.Pointer<
          ffi.NativeFunction<
              ffi.Pointer<ffi.Char> Function(
                  ffi.Pointer<TfLiteContext>, ffi.Pointer<TfLiteNode>)>>
      profiling_string;

  @ffi.Int32()
  external int builtin_code;

  external ffi.Pointer<ffi.Char> custom_name;

  @ffi.Int()
  external int version;
}

/// The flags used in `TfLiteDelegate`. Note that this is a bitmask, so the
/// values should be 1, 2, 4, 8, ...etc.
abstract class TfLiteDelegateFlags {
  static const int kTfLiteDelegateFlagsNone = 0;

  /// The flag is set if the delegate can handle dynamic sized tensors.
  /// For example, the output shape of a `Resize` op with non-constant shape
  /// can only be inferred when the op is invoked.
  /// In this case, the Delegate is responsible for calling
  /// `SetTensorToDynamic` to mark the tensor as a dynamic tensor, and calling
  /// `ResizeTensor` when invoking the op.
  ///
  /// If the delegate isn't capable to handle dynamic tensors, this flag need
  /// to be set to false.
  static const int kTfLiteDelegateFlagsAllowDynamicTensors = 1;

  /// This flag can be used by delegates (that allow dynamic tensors) to ensure
  /// applicable tensor shapes are automatically propagated in the case of tensor
  /// resizing.
  /// This means that non-dynamic (allocation_type != kTfLiteDynamic) I/O tensors
  /// of a delegate kernel will have correct shapes before its Prepare() method
  /// is called. The runtime leverages TFLite builtin ops in the original
  /// execution plan to propagate shapes.
  ///
  /// A few points to note:
  /// 1. This requires kTfLiteDelegateFlagsAllowDynamicTensors. If that flag is
  /// false, this one is redundant since the delegate kernels are re-initialized
  /// every time tensors are resized.
  /// 2. Enabling this flag adds some overhead to AllocateTensors(), since extra
  /// work is required to prepare the original execution plan.
  /// 3. This flag requires that the original execution plan only have ops with
  /// valid registrations (and not 'dummy' custom ops like with Flex).
  /// WARNING: This feature is experimental and subject to change.
  static const int kTfLiteDelegateFlagsRequirePropagatedShapes = 2;

  /// This flag can be used by delegates to request per-operator profiling. If a
  /// node is a delegate node, this flag will be checked before profiling. If
  /// set, then the node will not be profiled. The delegate will then add per
  /// operator information using Profiler::EventType::OPERATOR_INVOKE_EVENT and
  /// the results will appear in the operator-wise Profiling section and not in
  /// the Delegate internal section.
  static const int kTfLiteDelegateFlagsPerOperatorProfiling = 4;
}

const int kTfLiteNullBufferHandle = -1;

const int __GNUC_VA_LIST = 1;

const int true1 = 1;

const int false1 = 0;

const int __bool_true_false_are_defined = 1;

const int __WORDSIZE = 64;

const int __DARWIN_ONLY_64_BIT_INO_T = 1;

const int __DARWIN_ONLY_UNIX_CONFORMANCE = 1;

const int __DARWIN_ONLY_VERS_1050 = 1;

const int __DARWIN_UNIX03 = 1;

const int __DARWIN_64_BIT_INO_T = 1;

const int __DARWIN_VERS_1050 = 1;

const int __DARWIN_NON_CANCELABLE = 0;

const String __DARWIN_SUF_EXTSN = '\$DARWIN_EXTSN';

const int __DARWIN_C_ANSI = 4096;

const int __DARWIN_C_FULL = 900000;

const int __DARWIN_C_LEVEL = 900000;

const int __STDC_WANT_LIB_EXT1__ = 1;

const int __DARWIN_NO_LONG_LONG = 0;

const int _DARWIN_FEATURE_64_BIT_INODE = 1;

const int _DARWIN_FEATURE_ONLY_64_BIT_INODE = 1;

const int _DARWIN_FEATURE_ONLY_VERS_1050 = 1;

const int _DARWIN_FEATURE_ONLY_UNIX_CONFORMANCE = 1;

const int _DARWIN_FEATURE_UNIX_CONFORMANCE = 3;

const int __has_ptrcheck = 0;

const int __DARWIN_NULL = 0;

const int __PTHREAD_SIZE__ = 8176;

const int __PTHREAD_ATTR_SIZE__ = 56;

const int __PTHREAD_MUTEXATTR_SIZE__ = 8;

const int __PTHREAD_MUTEX_SIZE__ = 56;

const int __PTHREAD_CONDATTR_SIZE__ = 8;

const int __PTHREAD_COND_SIZE__ = 40;

const int __PTHREAD_ONCE_SIZE__ = 8;

const int __PTHREAD_RWLOCK_SIZE__ = 192;

const int __PTHREAD_RWLOCKATTR_SIZE__ = 16;

const int INT8_MAX = 127;

const int INT16_MAX = 32767;

const int INT32_MAX = 2147483647;

const int INT64_MAX = 9223372036854775807;

const int INT8_MIN = -128;

const int INT16_MIN = -32768;

const int INT32_MIN = -2147483648;

const int INT64_MIN = -9223372036854775808;

const int UINT8_MAX = 255;

const int UINT16_MAX = 65535;

const int UINT32_MAX = 4294967295;

const int UINT64_MAX = -1;

const int INT_LEAST8_MIN = -128;

const int INT_LEAST16_MIN = -32768;

const int INT_LEAST32_MIN = -2147483648;

const int INT_LEAST64_MIN = -9223372036854775808;

const int INT_LEAST8_MAX = 127;

const int INT_LEAST16_MAX = 32767;

const int INT_LEAST32_MAX = 2147483647;

const int INT_LEAST64_MAX = 9223372036854775807;

const int UINT_LEAST8_MAX = 255;

const int UINT_LEAST16_MAX = 65535;

const int UINT_LEAST32_MAX = 4294967295;

const int UINT_LEAST64_MAX = -1;

const int INT_FAST8_MIN = -128;

const int INT_FAST16_MIN = -32768;

const int INT_FAST32_MIN = -2147483648;

const int INT_FAST64_MIN = -9223372036854775808;

const int INT_FAST8_MAX = 127;

const int INT_FAST16_MAX = 32767;

const int INT_FAST32_MAX = 2147483647;

const int INT_FAST64_MAX = 9223372036854775807;

const int UINT_FAST8_MAX = 255;

const int UINT_FAST16_MAX = 65535;

const int UINT_FAST32_MAX = 4294967295;

const int UINT_FAST64_MAX = -1;

const int INTPTR_MAX = 9223372036854775807;

const int INTPTR_MIN = -9223372036854775808;

const int UINTPTR_MAX = -1;

const int INTMAX_MAX = 9223372036854775807;

const int UINTMAX_MAX = -1;

const int INTMAX_MIN = -9223372036854775808;

const int PTRDIFF_MIN = -9223372036854775808;

const int PTRDIFF_MAX = 9223372036854775807;

const int SIZE_MAX = -1;

const int RSIZE_MAX = 9223372036854775807;

const int WCHAR_MAX = 2147483647;

const int WCHAR_MIN = -2147483648;

const int WINT_MIN = -2147483648;

const int WINT_MAX = 2147483647;

const int SIG_ATOMIC_MIN = -2147483648;

const int SIG_ATOMIC_MAX = 2147483647;

const int __API_TO_BE_DEPRECATED = 100000;

const int __API_TO_BE_DEPRECATED_MACOS = 100000;

const int __API_TO_BE_DEPRECATED_IOS = 100000;

const int __API_TO_BE_DEPRECATED_TVOS = 100000;

const int __API_TO_BE_DEPRECATED_WATCHOS = 100000;

const int __API_TO_BE_DEPRECATED_MACCATALYST = 100000;

const int __API_TO_BE_DEPRECATED_DRIVERKIT = 100000;

const int __MAC_10_0 = 1000;

const int __MAC_10_1 = 1010;

const int __MAC_10_2 = 1020;

const int __MAC_10_3 = 1030;

const int __MAC_10_4 = 1040;

const int __MAC_10_5 = 1050;

const int __MAC_10_6 = 1060;

const int __MAC_10_7 = 1070;

const int __MAC_10_8 = 1080;

const int __MAC_10_9 = 1090;

const int __MAC_10_10 = 101000;

const int __MAC_10_10_2 = 101002;

const int __MAC_10_10_3 = 101003;

const int __MAC_10_11 = 101100;

const int __MAC_10_11_2 = 101102;

const int __MAC_10_11_3 = 101103;

const int __MAC_10_11_4 = 101104;

const int __MAC_10_12 = 101200;

const int __MAC_10_12_1 = 101201;

const int __MAC_10_12_2 = 101202;

const int __MAC_10_12_4 = 101204;

const int __MAC_10_13 = 101300;

const int __MAC_10_13_1 = 101301;

const int __MAC_10_13_2 = 101302;

const int __MAC_10_13_4 = 101304;

const int __MAC_10_14 = 101400;

const int __MAC_10_14_1 = 101401;

const int __MAC_10_14_4 = 101404;

const int __MAC_10_14_6 = 101406;

const int __MAC_10_15 = 101500;

const int __MAC_10_15_1 = 101501;

const int __MAC_10_15_4 = 101504;

const int __MAC_10_16 = 101600;

const int __MAC_11_0 = 110000;

const int __MAC_11_1 = 110100;

const int __MAC_11_3 = 110300;

const int __MAC_11_4 = 110400;

const int __MAC_11_5 = 110500;

const int __MAC_11_6 = 110600;

const int __MAC_12_0 = 120000;

const int __MAC_12_1 = 120100;

const int __MAC_12_2 = 120200;

const int __MAC_12_3 = 120300;

const int __MAC_13_0 = 130000;

const int __MAC_13_1 = 130100;

const int __IPHONE_2_0 = 20000;

const int __IPHONE_2_1 = 20100;

const int __IPHONE_2_2 = 20200;

const int __IPHONE_3_0 = 30000;

const int __IPHONE_3_1 = 30100;

const int __IPHONE_3_2 = 30200;

const int __IPHONE_4_0 = 40000;

const int __IPHONE_4_1 = 40100;

const int __IPHONE_4_2 = 40200;

const int __IPHONE_4_3 = 40300;

const int __IPHONE_5_0 = 50000;

const int __IPHONE_5_1 = 50100;

const int __IPHONE_6_0 = 60000;

const int __IPHONE_6_1 = 60100;

const int __IPHONE_7_0 = 70000;

const int __IPHONE_7_1 = 70100;

const int __IPHONE_8_0 = 80000;

const int __IPHONE_8_1 = 80100;

const int __IPHONE_8_2 = 80200;

const int __IPHONE_8_3 = 80300;

const int __IPHONE_8_4 = 80400;

const int __IPHONE_9_0 = 90000;

const int __IPHONE_9_1 = 90100;

const int __IPHONE_9_2 = 90200;

const int __IPHONE_9_3 = 90300;

const int __IPHONE_10_0 = 100000;

const int __IPHONE_10_1 = 100100;

const int __IPHONE_10_2 = 100200;

const int __IPHONE_10_3 = 100300;

const int __IPHONE_11_0 = 110000;

const int __IPHONE_11_1 = 110100;

const int __IPHONE_11_2 = 110200;

const int __IPHONE_11_3 = 110300;

const int __IPHONE_11_4 = 110400;

const int __IPHONE_12_0 = 120000;

const int __IPHONE_12_1 = 120100;

const int __IPHONE_12_2 = 120200;

const int __IPHONE_12_3 = 120300;

const int __IPHONE_12_4 = 120400;

const int __IPHONE_13_0 = 130000;

const int __IPHONE_13_1 = 130100;

const int __IPHONE_13_2 = 130200;

const int __IPHONE_13_3 = 130300;

const int __IPHONE_13_4 = 130400;

const int __IPHONE_13_5 = 130500;

const int __IPHONE_13_6 = 130600;

const int __IPHONE_13_7 = 130700;

const int __IPHONE_14_0 = 140000;

const int __IPHONE_14_1 = 140100;

const int __IPHONE_14_2 = 140200;

const int __IPHONE_14_3 = 140300;

const int __IPHONE_14_5 = 140500;

const int __IPHONE_14_6 = 140600;

const int __IPHONE_14_7 = 140700;

const int __IPHONE_14_8 = 140800;

const int __IPHONE_15_0 = 150000;

const int __IPHONE_15_1 = 150100;

const int __IPHONE_15_2 = 150200;

const int __IPHONE_15_3 = 150300;

const int __IPHONE_15_4 = 150400;

const int __IPHONE_16_0 = 160000;

const int __IPHONE_16_1 = 160100;

const int __IPHONE_16_2 = 160200;

const int __TVOS_9_0 = 90000;

const int __TVOS_9_1 = 90100;

const int __TVOS_9_2 = 90200;

const int __TVOS_10_0 = 100000;

const int __TVOS_10_0_1 = 100001;

const int __TVOS_10_1 = 100100;

const int __TVOS_10_2 = 100200;

const int __TVOS_11_0 = 110000;

const int __TVOS_11_1 = 110100;

const int __TVOS_11_2 = 110200;

const int __TVOS_11_3 = 110300;

const int __TVOS_11_4 = 110400;

const int __TVOS_12_0 = 120000;

const int __TVOS_12_1 = 120100;

const int __TVOS_12_2 = 120200;

const int __TVOS_12_3 = 120300;

const int __TVOS_12_4 = 120400;

const int __TVOS_13_0 = 130000;

const int __TVOS_13_2 = 130200;

const int __TVOS_13_3 = 130300;

const int __TVOS_13_4 = 130400;

const int __TVOS_14_0 = 140000;

const int __TVOS_14_1 = 140100;

const int __TVOS_14_2 = 140200;

const int __TVOS_14_3 = 140300;

const int __TVOS_14_5 = 140500;

const int __TVOS_14_6 = 140600;

const int __TVOS_14_7 = 140700;

const int __TVOS_15_0 = 150000;

const int __TVOS_15_1 = 150100;

const int __TVOS_15_2 = 150200;

const int __TVOS_15_3 = 150300;

const int __TVOS_15_4 = 150400;

const int __TVOS_16_0 = 160000;

const int __TVOS_16_1 = 160100;

const int __TVOS_16_2 = 160200;

const int __WATCHOS_1_0 = 10000;

const int __WATCHOS_2_0 = 20000;

const int __WATCHOS_2_1 = 20100;

const int __WATCHOS_2_2 = 20200;

const int __WATCHOS_3_0 = 30000;

const int __WATCHOS_3_1 = 30100;

const int __WATCHOS_3_1_1 = 30101;

const int __WATCHOS_3_2 = 30200;

const int __WATCHOS_4_0 = 40000;

const int __WATCHOS_4_1 = 40100;

const int __WATCHOS_4_2 = 40200;

const int __WATCHOS_4_3 = 40300;

const int __WATCHOS_5_0 = 50000;

const int __WATCHOS_5_1 = 50100;

const int __WATCHOS_5_2 = 50200;

const int __WATCHOS_5_3 = 50300;

const int __WATCHOS_6_0 = 60000;

const int __WATCHOS_6_1 = 60100;

const int __WATCHOS_6_2 = 60200;

const int __WATCHOS_7_0 = 70000;

const int __WATCHOS_7_1 = 70100;

const int __WATCHOS_7_2 = 70200;

const int __WATCHOS_7_3 = 70300;

const int __WATCHOS_7_4 = 70400;

const int __WATCHOS_7_5 = 70500;

const int __WATCHOS_7_6 = 70600;

const int __WATCHOS_8_0 = 80000;

const int __WATCHOS_8_1 = 80100;

const int __WATCHOS_8_3 = 80300;

const int __WATCHOS_8_4 = 80400;

const int __WATCHOS_8_5 = 80500;

const int __WATCHOS_9_0 = 90000;

const int __WATCHOS_9_1 = 90100;

const int __WATCHOS_9_2 = 90200;

const int MAC_OS_X_VERSION_10_0 = 1000;

const int MAC_OS_X_VERSION_10_1 = 1010;

const int MAC_OS_X_VERSION_10_2 = 1020;

const int MAC_OS_X_VERSION_10_3 = 1030;

const int MAC_OS_X_VERSION_10_4 = 1040;

const int MAC_OS_X_VERSION_10_5 = 1050;

const int MAC_OS_X_VERSION_10_6 = 1060;

const int MAC_OS_X_VERSION_10_7 = 1070;

const int MAC_OS_X_VERSION_10_8 = 1080;

const int MAC_OS_X_VERSION_10_9 = 1090;

const int MAC_OS_X_VERSION_10_10 = 101000;

const int MAC_OS_X_VERSION_10_10_2 = 101002;

const int MAC_OS_X_VERSION_10_10_3 = 101003;

const int MAC_OS_X_VERSION_10_11 = 101100;

const int MAC_OS_X_VERSION_10_11_2 = 101102;

const int MAC_OS_X_VERSION_10_11_3 = 101103;

const int MAC_OS_X_VERSION_10_11_4 = 101104;

const int MAC_OS_X_VERSION_10_12 = 101200;

const int MAC_OS_X_VERSION_10_12_1 = 101201;

const int MAC_OS_X_VERSION_10_12_2 = 101202;

const int MAC_OS_X_VERSION_10_12_4 = 101204;

const int MAC_OS_X_VERSION_10_13 = 101300;

const int MAC_OS_X_VERSION_10_13_1 = 101301;

const int MAC_OS_X_VERSION_10_13_2 = 101302;

const int MAC_OS_X_VERSION_10_13_4 = 101304;

const int MAC_OS_X_VERSION_10_14 = 101400;

const int MAC_OS_X_VERSION_10_14_1 = 101401;

const int MAC_OS_X_VERSION_10_14_4 = 101404;

const int MAC_OS_X_VERSION_10_14_6 = 101406;

const int MAC_OS_X_VERSION_10_15 = 101500;

const int MAC_OS_X_VERSION_10_15_1 = 101501;

const int MAC_OS_X_VERSION_10_16 = 101600;

const int MAC_OS_VERSION_11_0 = 110000;

const int MAC_OS_VERSION_12_0 = 120000;

const int MAC_OS_VERSION_13_0 = 130000;

const int __DRIVERKIT_19_0 = 190000;

const int __DRIVERKIT_20_0 = 200000;

const int __DRIVERKIT_21_0 = 210000;

const int __MAC_OS_X_VERSION_MIN_REQUIRED = 130000;

const int __MAC_OS_X_VERSION_MAX_ALLOWED = 130100;

const int __ENABLE_LEGACY_MAC_AVAILABILITY = 1;

const int __DARWIN_WCHAR_MAX = 2147483647;

const int __DARWIN_WCHAR_MIN = -2147483648;

const int _FORTIFY_SOURCE = 2;

const int __DARWIN_NSIG = 32;

const int NSIG = 32;

const int _ARM_SIGNAL_ = 1;

const int SIGHUP = 1;

const int SIGINT = 2;

const int SIGQUIT = 3;

const int SIGILL = 4;

const int SIGTRAP = 5;

const int SIGABRT = 6;

const int SIGIOT = 6;

const int SIGEMT = 7;

const int SIGFPE = 8;

const int SIGKILL = 9;

const int SIGBUS = 10;

const int SIGSEGV = 11;

const int SIGSYS = 12;

const int SIGPIPE = 13;

const int SIGALRM = 14;

const int SIGTERM = 15;

const int SIGURG = 16;

const int SIGSTOP = 17;

const int SIGTSTP = 18;

const int SIGCONT = 19;

const int SIGCHLD = 20;

const int SIGTTIN = 21;

const int SIGTTOU = 22;

const int SIGIO = 23;

const int SIGXCPU = 24;

const int SIGXFSZ = 25;

const int SIGVTALRM = 26;

const int SIGPROF = 27;

const int SIGWINCH = 28;

const int SIGINFO = 29;

const int SIGUSR1 = 30;

const int SIGUSR2 = 31;

const int __DARWIN_OPAQUE_ARM_THREAD_STATE64 = 0;

const int SIGEV_NONE = 0;

const int SIGEV_SIGNAL = 1;

const int SIGEV_THREAD = 3;

const int ILL_NOOP = 0;

const int ILL_ILLOPC = 1;

const int ILL_ILLTRP = 2;

const int ILL_PRVOPC = 3;

const int ILL_ILLOPN = 4;

const int ILL_ILLADR = 5;

const int ILL_PRVREG = 6;

const int ILL_COPROC = 7;

const int ILL_BADSTK = 8;

const int FPE_NOOP = 0;

const int FPE_FLTDIV = 1;

const int FPE_FLTOVF = 2;

const int FPE_FLTUND = 3;

const int FPE_FLTRES = 4;

const int FPE_FLTINV = 5;

const int FPE_FLTSUB = 6;

const int FPE_INTDIV = 7;

const int FPE_INTOVF = 8;

const int SEGV_NOOP = 0;

const int SEGV_MAPERR = 1;

const int SEGV_ACCERR = 2;

const int BUS_NOOP = 0;

const int BUS_ADRALN = 1;

const int BUS_ADRERR = 2;

const int BUS_OBJERR = 3;

const int TRAP_BRKPT = 1;

const int TRAP_TRACE = 2;

const int CLD_NOOP = 0;

const int CLD_EXITED = 1;

const int CLD_KILLED = 2;

const int CLD_DUMPED = 3;

const int CLD_TRAPPED = 4;

const int CLD_STOPPED = 5;

const int CLD_CONTINUED = 6;

const int POLL_IN = 1;

const int POLL_OUT = 2;

const int POLL_MSG = 3;

const int POLL_ERR = 4;

const int POLL_PRI = 5;

const int POLL_HUP = 6;

const int SA_ONSTACK = 1;

const int SA_RESTART = 2;

const int SA_RESETHAND = 4;

const int SA_NOCLDSTOP = 8;

const int SA_NODEFER = 16;

const int SA_NOCLDWAIT = 32;

const int SA_SIGINFO = 64;

const int SA_USERTRAMP = 256;

const int SA_64REGSET = 512;

const int SA_USERSPACE_MASK = 127;

const int SIG_BLOCK = 1;

const int SIG_UNBLOCK = 2;

const int SIG_SETMASK = 3;

const int SI_USER = 65537;

const int SI_QUEUE = 65538;

const int SI_TIMER = 65539;

const int SI_ASYNCIO = 65540;

const int SI_MESGQ = 65541;

const int SS_ONSTACK = 1;

const int SS_DISABLE = 4;

const int MINSIGSTKSZ = 32768;

const int SIGSTKSZ = 131072;

const int SV_ONSTACK = 1;

const int SV_INTERRUPT = 2;

const int SV_RESETHAND = 4;

const int SV_NODEFER = 16;

const int SV_NOCLDSTOP = 8;

const int SV_SIGINFO = 64;

const int PRIO_PROCESS = 0;

const int PRIO_PGRP = 1;

const int PRIO_USER = 2;

const int PRIO_DARWIN_THREAD = 3;

const int PRIO_DARWIN_PROCESS = 4;

const int PRIO_MIN = -20;

const int PRIO_MAX = 20;

const int PRIO_DARWIN_BG = 4096;

const int PRIO_DARWIN_NONUI = 4097;

const int RUSAGE_SELF = 0;

const int RUSAGE_CHILDREN = -1;

const int RUSAGE_INFO_V0 = 0;

const int RUSAGE_INFO_V1 = 1;

const int RUSAGE_INFO_V2 = 2;

const int RUSAGE_INFO_V3 = 3;

const int RUSAGE_INFO_V4 = 4;

const int RUSAGE_INFO_V5 = 5;

const int RUSAGE_INFO_V6 = 6;

const int RUSAGE_INFO_CURRENT = 6;

const int RU_PROC_RUNS_RESLIDE = 1;

const int RLIMIT_CPU = 0;

const int RLIMIT_FSIZE = 1;

const int RLIMIT_DATA = 2;

const int RLIMIT_STACK = 3;

const int RLIMIT_CORE = 4;

const int RLIMIT_AS = 5;

const int RLIMIT_RSS = 5;

const int RLIMIT_MEMLOCK = 6;

const int RLIMIT_NPROC = 7;

const int RLIMIT_NOFILE = 8;

const int RLIM_NLIMITS = 9;

const int _RLIMIT_POSIX_FLAG = 4096;

const int RLIMIT_WAKEUPS_MONITOR = 1;

const int RLIMIT_CPU_USAGE_MONITOR = 2;

const int RLIMIT_THREAD_CPULIMITS = 3;

const int RLIMIT_FOOTPRINT_INTERVAL = 4;

const int WAKEMON_ENABLE = 1;

const int WAKEMON_DISABLE = 2;

const int WAKEMON_GET_PARAMS = 4;

const int WAKEMON_SET_DEFAULTS = 8;

const int WAKEMON_MAKE_FATAL = 16;

const int CPUMON_MAKE_FATAL = 4096;

const int FOOTPRINT_INTERVAL_RESET = 1;

const int IOPOL_TYPE_DISK = 0;

const int IOPOL_TYPE_VFS_ATIME_UPDATES = 2;

const int IOPOL_TYPE_VFS_MATERIALIZE_DATALESS_FILES = 3;

const int IOPOL_TYPE_VFS_STATFS_NO_DATA_VOLUME = 4;

const int IOPOL_TYPE_VFS_TRIGGER_RESOLVE = 5;

const int IOPOL_TYPE_VFS_IGNORE_CONTENT_PROTECTION = 6;

const int IOPOL_TYPE_VFS_IGNORE_PERMISSIONS = 7;

const int IOPOL_TYPE_VFS_SKIP_MTIME_UPDATE = 8;

const int IOPOL_TYPE_VFS_ALLOW_LOW_SPACE_WRITES = 9;

const int IOPOL_TYPE_VFS_DISALLOW_RW_FOR_O_EVTONLY = 10;

const int IOPOL_SCOPE_PROCESS = 0;

const int IOPOL_SCOPE_THREAD = 1;

const int IOPOL_SCOPE_DARWIN_BG = 2;

const int IOPOL_DEFAULT = 0;

const int IOPOL_IMPORTANT = 1;

const int IOPOL_PASSIVE = 2;

const int IOPOL_THROTTLE = 3;

const int IOPOL_UTILITY = 4;

const int IOPOL_STANDARD = 5;

const int IOPOL_APPLICATION = 5;

const int IOPOL_NORMAL = 1;

const int IOPOL_ATIME_UPDATES_DEFAULT = 0;

const int IOPOL_ATIME_UPDATES_OFF = 1;

const int IOPOL_MATERIALIZE_DATALESS_FILES_DEFAULT = 0;

const int IOPOL_MATERIALIZE_DATALESS_FILES_OFF = 1;

const int IOPOL_MATERIALIZE_DATALESS_FILES_ON = 2;

const int IOPOL_VFS_STATFS_NO_DATA_VOLUME_DEFAULT = 0;

const int IOPOL_VFS_STATFS_FORCE_NO_DATA_VOLUME = 1;

const int IOPOL_VFS_TRIGGER_RESOLVE_DEFAULT = 0;

const int IOPOL_VFS_TRIGGER_RESOLVE_OFF = 1;

const int IOPOL_VFS_CONTENT_PROTECTION_DEFAULT = 0;

const int IOPOL_VFS_CONTENT_PROTECTION_IGNORE = 1;

const int IOPOL_VFS_IGNORE_PERMISSIONS_OFF = 0;

const int IOPOL_VFS_IGNORE_PERMISSIONS_ON = 1;

const int IOPOL_VFS_SKIP_MTIME_UPDATE_OFF = 0;

const int IOPOL_VFS_SKIP_MTIME_UPDATE_ON = 1;

const int IOPOL_VFS_ALLOW_LOW_SPACE_WRITES_OFF = 0;

const int IOPOL_VFS_ALLOW_LOW_SPACE_WRITES_ON = 1;

const int IOPOL_VFS_DISALLOW_RW_FOR_O_EVTONLY_DEFAULT = 0;

const int IOPOL_VFS_DISALLOW_RW_FOR_O_EVTONLY_ON = 1;

const int WNOHANG = 1;

const int WUNTRACED = 2;

const int WCOREFLAG = 128;

const int _WSTOPPED = 127;

const int WEXITED = 4;

const int WSTOPPED = 8;

const int WCONTINUED = 16;

const int WNOWAIT = 32;

const int WAIT_ANY = -1;

const int WAIT_MYPGRP = 0;

const int _QUAD_HIGHWORD = 1;

const int _QUAD_LOWWORD = 0;

const int __DARWIN_LITTLE_ENDIAN = 1234;

const int __DARWIN_BIG_ENDIAN = 4321;

const int __DARWIN_PDP_ENDIAN = 3412;

const int __DARWIN_BYTE_ORDER = 1234;

const int LITTLE_ENDIAN = 1234;

const int BIG_ENDIAN = 4321;

const int PDP_ENDIAN = 3412;

const int BYTE_ORDER = 1234;

const int NULL = 0;

const int EXIT_FAILURE = 1;

const int EXIT_SUCCESS = 0;

const int RAND_MAX = 2147483647;

const int kTfLiteOptionalTensor = -1;
